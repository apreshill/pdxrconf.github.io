<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <title>rOpenSci | New rOpenSci Packages for Text Processing in R</title>

     
    <script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
    <script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/r.min.js"></script>

    <script type="text/javascript">
    hljs.configure({languages: []});
    hljs.initHighlightingOnLoad();
    </script>
    <link rel="stylesheet" type="text/css" href="/css/style-new.css" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#4b8add">
<meta name="theme-color" content="#4b8add">


    <meta name="viewport" content="width=device-width, initial-scale=1">

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-462421-6', 'auto');
ga('send', 'pageview');
</script>

</head>
<body>

    
    <div id="header">
        <div class="container">
            <div class="row center-m">
                
                <div class="col-1">
                    <a href="/index.html"><img src="/img/icon_lettering_white.svg" /></a>
                </div>
                
                
                <nav class="col-6 col-offset-4 top-3">
                    <ul class="row between">
						<li><a href="/about/">About</a></li>
                        <li><a href="/blog/">Blog</a></li>
                        <li><a href="/packages/">Packages</a></li>
                        <li><a href="/community/">Community</a></li>
                        <li><a href="http://discuss.ropensci.org/" target="_blank">Discuss</a></li>

                    </ul>
                </nav>
                
            </div>
        </div>
    </div>


<article>
    <div class="container">
        <div class="row">
            <div class="col-2 sidebar top-5">
                <ul class="autoSidebar"></ul>
            </div> 
        </div>
        <div class="row">
            <div class="col-offset-2 col-8 top-20">
                <h2 style="text-align: center;">New rOpenSci Packages for Text Processing in R</h2>
            </div>
        </div>
        <div class="row">
            <div class="col-offset-2 col-8 top-10 bottom-5" style="font-size: 20px; text-align: center;">
                <p class="authors" style="text-align: center;">
                    
                        
                          <a href="/about/#team"> Jeroen Ooms </a>&nbsp;
                        
                    
                </p>
                <br>
                <div style="font-size: 20px; color: #2C3E50; margin-top: 15px;">June 13, 2017</div>
            </div>
            <div class="col-offset-2 col-8 top-2">

                

                

<p>Textual data and natural language processing are still a niche domain within the R ecosytstem. The <a href="https://cran.r-project.org/view=NaturalLanguageProcessing">NLP task view</a> gives an overview of existing work however a lot of basic infrastructure is still missing.
At the rOpenSci <a href="https://ropensci.org/blog/blog/2017/05/03/textworkshop17">text workshop</a> in April we discussed many ideas for improving text processing in R which revealed several core areas that need improvement:</p>

<ul>
<li>Reading: better tools for extracing text and metadata from documents in various formats (doc, rtf, pdf, etc).</li>
<li>Encoding: many text packages work well for ascii text but rapidly break down when text contains Hungarian, Korean or emojis.</li>
<li>Interchange: packages don&rsquo;t work well together due to lack of data classes or conventions for textual data (see also <a href="https://github.com/ropensci/tif">ropensci/tif</a>)</li>
</ul>

<p>Participants also had many good suggestions for C/C++ libraries that text researchers in R might benefit from. Over the past weeks I was able to look into these suggestions and work on a few packages for reading and analyzing text. Below is an update on new and improved rOpenSci tools for text processsing in R!</p>

<h2 id="google-language-detector-2-and-3">Google language detector 2 and 3</h2>

<p>New packages <code>cld2</code> and <code>cld3</code> are wrappers C++ libraries by Google for language identification. <a href="https://github.com/cld2owners/cld2#internals">CLD2</a> is a Naïve Bayesian classifier, whereas <a href="https://github.com/google/cld3#model">CLD3</a> uses a neural network model. I found <code>cld2</code> to give better results for short text.</p>

<pre><code class="language-r"># Get the latest versions
install.packages(c(&quot;cld2&quot;, &quot;cld3&quot;))

# Vectorized function
text &lt;- c(&quot;À chaque fou plaît sa marotte.&quot;, &quot;猿も木から落ちる&quot;,
	&quot;Алты́нного во́ра ве́шают, а полти́нного че́ствуют.&quot;, &quot;Nou breekt mijn klomp!&quot;)

cld2::detect_language(text)
# [1] &quot;fr&quot; &quot;ja&quot; &quot;ru&quot; &quot;nl&quot;
</code></pre>

<p><a href="https://maelle.github.io">Maëlle</a> has written a <a href="http://www.masalmon.eu/2017/06/10/rolandgarros/">cool post</a> comparing language classification methods using 18000 <code>&quot;#RolandGarros2017&quot;</code> tweets and <a href="https://www.stat.auckland.ac.nz/people/tlum005">Thomas</a> <a href="http://notstatschat.tumblr.com/post/161449071226/stupid-word-games">reminds us</a> that algorithms can easily be fooled. Still I found the accuracy on real text quite astonishing given the relatively small size of these libraries.</p>

<p>Note that the algorithm for CLD3 is still under development and the engineers at Google have recently <a href="https://github.com/google/cld3/issues">opened</a> their Github issues page for feedback.</p>

<h2 id="anti-word-and-un-rtf">(anti) word and (un)rtf</h2>

<p>Many archived documents are only available in legacy formats such as <code>.doc</code> and <code>.rtf</code>. The only tools available for extracting text from these documents were difficult to install and could not be imported from packages and scripts.</p>

<p>To make this a little easier we have packaged up utilities <a href="http://www.winfield.demon.nl/">antiword</a> and <a href="https://www.gnu.org/software/unrtf/">UnRTF</a> to read MS <code>doc</code> and <code>rtf</code> files respectively.</p>

<pre><code class="language-r"># Get the latest versions
install.packages(c(&quot;antiword&quot;, &quot;unrtf&quot;))

# Extract text from 'rtf' file
text &lt;- unrtf::unrtf(&quot;https://jeroen.github.io/files/sample.rtf&quot;, format = &quot;text&quot;)
cat(text)
### Lots of text...

# Extract text from 'doc' file
text &lt;- antiword::antiword(&quot;https://jeroen.github.io/files/UDHR-english.doc&quot;)
cat(text)
### Lots of text...
</code></pre>

<p>Also have a look at meta packages <code>readtext</code> or <code>textreadr</code> which wrap these and other packages for automatically reading text in many different formats.</p>

<h2 id="pdf-utilities">pdf utilities</h2>

<p>Our <a href="https://cran.r-project.org/web/packages/pdftools/index.html">pdftools</a> package now supports reading pdf (extracting text or metadata) and rendering pdf to png, jpeg, tiff, or raw vectors on all platforms (incl. Windows).</p>

<pre><code class="language-r"># Read some text
text &lt;- pdftools::pdf_text('https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf')
cat(text[1])
# An Introduction to R
#             Notes on R: A Programming Environment for Data Analysis and Graphics
#                                                        Version 3.4.0 (2017-04-21)
# W. N. Venables, D. M. Smith
# and the R Core Team

# Read meta data
pdftools::pdf_info('https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf')
# $version
# [1] &quot;1.5&quot;
#
# $pages
# [1] 105
#
# .... much more :)
</code></pre>

<p>You can use either render a page into a raw bitmap array, or directly to an image format such as png, jpeg or tiff.</p>

<pre><code class="language-r">files &lt;- pdftools::pdf_convert('https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf', format = &quot;png&quot;, pages = 1:5)
# Converting page 1 to R-intro_1.png... done!
# Converting page 2 to R-intro_2.png... done!
# Converting page 3 to R-intro_3.png... done!
# Converting page 4 to R-intro_4.png... done!
# Converting page 5 to R-intro_5.png... done!
</code></pre>

<p>To extract text from scanned images, also check out our <a href="https://cran.r-project.org/web/packages/tesseract/index.html">tesseract</a> package which wraps Google&rsquo;s powerful OCR engine.</p>

<h2 id="stemming-tokenizing-and-spell-checking">Stemming, tokenizing and spell checking</h2>

<p>Our <a href="https://cran.r-project.org/web/packages/hunspell/index.html">hunspell</a> package has had a few updates recently as well. The package is a wrapper for <a href="http://hunspell.github.io/">libhunspell</a> which is a popular library for spell checking:</p>

<pre><code class="language-r"># Extract incorrect from a piece of text
bad &lt;- hunspell(&quot;spell checkers are not neccessairy for langauge ninja's&quot;)
print(bad[[1]])
# [1] &quot;neccessairy&quot; &quot;langauge&quot;
hunspell_suggest(bad[[1]])
# [[1]]
# [1] &quot;necessary&quot;    &quot;necessarily&quot;  &quot;necessaries&quot;  &quot;recessionary&quot; &quot;accessory&quot;    &quot;incarcerate&quot;
#
# [[2]]
# [1] &quot;language&quot;  &quot;Langeland&quot; &quot;Lagrange&quot;  &quot;Lange&quot;     &quot;gaugeable&quot; &quot;linkage&quot;   &quot;Langland&quot;
</code></pre>

<p>The package is also used by <code>devtools</code> to spell-check manual pages in R packages:</p>

<pre><code class="language-r">devtools::spell_check()
#   WORD          FOUND IN
# alltogether   pdftools.Rd:36
# cairo         pdf_render_page.Rd:42
# jpeg          pdf_render_page.Rd:40
# libpoppler    pdf_render_page.Rd:42, pdftools.Rd:30, description:1
# png           pdf_render_page.Rd:40
# Poppler       pdftools.Rd:34
</code></pre>

<p>Finally hunspell also exposes the underlying methods needed for spell checking such as stemming words:</p>

<pre><code class="language-r"># Find possible stems for each word
words &lt;- c(&quot;loving&quot;, &quot;loved&quot;, &quot;lover&quot;, &quot;lovely&quot;, &quot;love&quot;)
hunspell_analyze(words)
# [[1]]
# [1] &quot; st:loving&quot;    &quot; st:love fl:G&quot;
#
# [[2]]
# [1] &quot; st:loved&quot;     &quot; st:love fl:D&quot;
#
# [[3]]
# [1] &quot; st:lover&quot;     &quot; st:love fl:R&quot;
#
# [[4]]
# [1] &quot; st:lovely&quot;    &quot; st:love fl:Y&quot;
#
# [[5]]
# [1] &quot; st:love&quot;
</code></pre>

<p>Hunspell also suppors tokenizing words from html, latex, man, or plain text. For more advanced word extraction, check out the rOpenSci <a href="https://github.com/ropensci/tokenizers#readme">tokenizers</a> package.</p>

            </div>
            <br>
            <div class="col-offset-2 col-8 top-4 labels">
                
                    <a href="/tags/r"><span class="label">r</span></a>
                
                    <a href="/tags/packages"><span class="label">packages</span></a>
                
                    <a href="/tags/software"><span class="label">software</span></a>
                
                    <a href="/tags/opendata"><span class="label">opendata</span></a>
                
                    <a href="/tags/pdf"><span class="label">pdf</span></a>
                
            </div>

            
            
            <div class="col-offset-2 col-8 top-4">
                <div id='discourse-comments'></div>
                <script type="text/javascript">
                DiscourseEmbed = { discourseUrl: 'https://discuss.ropensci.org/',
                                   topicId:  746  };
                (function() {
                  var d = document.createElement('script'); d.type = 'text/javascript'; d.async = true;
                  d.src = DiscourseEmbed.discourseUrl + 'javascripts/embed.js';
                  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(d);
                })();
                </script>
            </div>
            
        </div>
        <br>
    </div>
</article>





    <div id="footer">
        <div class="container">
            <div class="row start">
                <div class="col-1 col-1-3 top-8">
                    <img src="/img/icon_short_white.svg" />
                </div>

                <div class="col-9 col-offset-2 top-10 bottom-8">
                    <div class="row between">
                        <div class="col-2 col-1-3">
                            <a href="http://github.com/ropensci" target="_blank"><div class="icon icon-github"></div></a>
                            <a href="http://twitter.com/ropensci" target="_blank"><div class="icon icon-twitter"></div></a>
                            <a href="http://vimeo.com/ropensci" target="_blank"><div class="icon icon-vimeo"></div></a>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-2 col-1-3 top-8 bottom-8">
                            <ul>
                                <h5 class="bottom-2">Info</h5>
                                <li><a href="/about">Mission</a></li>
                                <li><a href="/about#team">Team</a></li>
                                <li><a href="/about#collaborators">Collaborators</a></li>
                                <li><a href="/careers">Careers</a></li>

                            </ul>
                        </div>

                        <div class="col-2 col-1-3 top-8 bottom-8">
                            <ul>
                                <h5 class="bottom-2">Work</h5>
                                <li><a href="/packages/">Packages</a></li>
                                <li><a href="/blog/">Blog</a></li>
                                <li><a href="/technotes/">Tech Notes</a></li>
                                <li><a href="/tutorials/">Tutorials</a></li>
                                <li><a href="/usecases/">Use Cases</a></li>
                                <li><a href="/resources/">More Resources</a></li>
                            </ul>
                        </div>
                        <div class="col-2 col-1-3 top-8 bottom-8">
                            <ul>
                                <h5 class="bottom-2">Participate</h5>
                                <li><a href="/contact.html">Contact us</a></li>
                                <li><a href="/community/">Community</a></li>
                                <li><a href="http://onboarding.ropensci.org/">Contribute software</a></li>
                                <li><a href="http://unconf17.ropensci.org/">Unconference</a></li>
                                <li><a href="/coc">Code of conduct</a></li>
                                <li><a href="/donate/">Donate</a></li>
                            </ul>
                        </div>
                        <div class="col-4 top-8 bottom-8">
                            <h5 class="bottom-2"></h5>

                            <p>rOpenSci is a fiscally sponsored project of <a href="http://numfocus.org" target="_blank">NumFOCUS</a></p>
                            <a href="http://numfocus.org" target="_blank"><img src="img/numfocus.png"></a>
                            <br>

                        </div>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-12 top-8 bottom-9 divider">
                    <p class="top-9">Except where otherwise noted, content on this site is licensed under the <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC-BY license</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>



</body>
</html>




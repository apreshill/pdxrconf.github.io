<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data on rOpenSci - open tools for open science</title>
    <link>https://ropensci.org/tags/data/</link>
    <description>Recent content in Data on rOpenSci - open tools for open science</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 12 Dec 2017 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://ropensci.org/tags/data/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>fulltext v0.3: x, y, and z</title>
      <link>https://ropensci.org/technotes/2017/12/12/fulltext-update/</link>
      <pubDate>Tue, 12 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/technotes/2017/12/12/fulltext-update/</guid>
      <description>
        
        

&lt;p&gt;Text-mining - the art of answering questions by extracting patterns, data, etc. out of the published literature - is not easy. It&amp;rsquo;s made incredibly difficult because of publishers. Novels, etc. by writers are one thing - but it&amp;rsquo;s hard to swallow the fact that the vast majority of publicly funded research across the globe is published in paywall journals. That is, taxpayers pay twice for research: once for the grant to fund the work, then again to be able to read it.&lt;/p&gt;

&lt;p&gt;Text-mining use cases run from determining the change in use of words through time [ref], to XYZ.&lt;/p&gt;

&lt;h2 id=&#34;the-fulltext-package&#34;&gt;the fulltext package&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;fulltext&lt;/code&gt; is a package to help R users get published literature from the web in it&amp;rsquo;s many forms, and across thousands upon thousands of publishers.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;fulltext&lt;/code&gt; tries to make the following use cases as easy as possible:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Search for articles&lt;/li&gt;
&lt;li&gt;Fetch abstracts&lt;/li&gt;
&lt;li&gt;Fetch full text articles&lt;/li&gt;
&lt;li&gt;Get links for full text articles (xml, pdf)&lt;/li&gt;
&lt;li&gt;Extract text from articles / convert formats&lt;/li&gt;
&lt;li&gt;Collect sections of articles that you actually need (e.g., titles)&lt;/li&gt;
&lt;li&gt;Download supplementary materials&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;fulltext&lt;/code&gt; organizes funvctions around use cases, then provides flexiblity to query many data sources within that use case (i.e. function). For example &lt;code&gt;fulltext::ft_search&lt;/code&gt; searches for articles - you can choose among one or more of many data sources to search, passing options to each source as needed.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;what-does-a-workflow-with-fulltext-look-like&#34;&gt;What does a workflow with fulltext look like?&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Search for articles with &lt;code&gt;ft_search()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fetch articles with &lt;code&gt;ft_get()&lt;/code&gt; using the output of the previous step&lt;/li&gt;
&lt;li&gt;Extract sections of articles needed with &lt;code&gt;chunks()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Do some further processing with &lt;code&gt;tm&lt;/code&gt; or &lt;code&gt;?????&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;

&lt;p&gt;Install &lt;code&gt;fulltext&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;fulltext&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or get the development version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&amp;quot;ropensci/fulltext&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(fulltext)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;search-ft-search&#34;&gt;Search: ft_search&lt;/h2&gt;

&lt;p&gt;With &lt;code&gt;ft_search&lt;/code&gt; you can search&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;PLOS&lt;/li&gt;
&lt;li&gt;BMC&lt;/li&gt;
&lt;li&gt;Crossref&lt;/li&gt;
&lt;li&gt;Entrez&lt;/li&gt;
&lt;li&gt;arxiv&lt;/li&gt;
&lt;li&gt;biorxiv&lt;/li&gt;
&lt;li&gt;Euro&lt;/li&gt;
&lt;li&gt;Scopus&lt;/li&gt;
&lt;li&gt;Microsoft&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- ft_search(query=&#39;ecology&#39;, from=&#39;plos&#39;)
res
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Query:
##   [ecology] 
## Found:
##   [PLoS: 40969; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0; Europe PMC: 0; Scopus: 0; Microsoft: 0] 
## Returned:
##   [PLoS: 10; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0; Europe PMC: 0; Scopus: 0; Microsoft: 0]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After running &lt;code&gt;ft_search&lt;/code&gt; you can index to each source that you
selected in the &lt;code&gt;from&lt;/code&gt; parameter.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res$plos
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Query: [ecology] 
## Records found, returned: [40969, 10] 
## License: [CC-BY] 
##                              id
## 1  10.1371/journal.pone.0001248
## 2  10.1371/journal.pone.0059813
## 3  10.1371/journal.pone.0155019
## 4  10.1371/journal.pone.0080763
## 5  10.1371/journal.pone.0150648
## 6  10.1371/journal.pcbi.1003594
## 7  10.1371/journal.pone.0102437
## 8  10.1371/journal.pone.0175014
## 9  10.1371/journal.pone.0166559
## 10 10.1371/journal.pone.0054689
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you give many values for the &lt;code&gt;from&lt;/code&gt; parameter you&amp;rsquo;ll get many results, for
example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- ft_search(query=&#39;ecology&#39;, from=c(&#39;plos&#39;, &#39;crossref&#39;))
res$plos
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Query: [ecology] 
## Records found, returned: [40969, 10] 
## License: [CC-BY] 
##                              id
## 1  10.1371/journal.pone.0001248
## 2  10.1371/journal.pone.0059813
## 3  10.1371/journal.pone.0155019
## 4  10.1371/journal.pone.0080763
## 5  10.1371/journal.pone.0150648
## 6  10.1371/journal.pcbi.1003594
## 7  10.1371/journal.pone.0102437
## 8  10.1371/journal.pone.0175014
## 9  10.1371/journal.pone.0166559
## 10 10.1371/journal.pone.0054689
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res$crossref
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Query: [ecology] 
## Records found, returned: [142207, 10] 
## License: [variable, see individual records] 
##                  container.title    created  deposited
## 1                        Ecology 2006-05-03 2017-04-14
## 2                        Ecology 2006-05-03 2016-03-07
## 3                        Ecology 2006-05-03 2016-03-07
## 4                        Ecology 2006-05-03 2016-03-07
## 5                        Ecology 2006-05-03 2017-04-15
## 6                        Ecology 2006-05-03 2017-04-15
## 7                        Ecology 2006-05-09 2016-03-07
## 8                        Ecology 2017-04-26 2017-07-11
## 9  Trends in Ecology &amp;amp; Evolution 2002-07-25 2017-06-14
## 10 Journal of Industrial Ecology 2017-10-05 2017-11-14
## Variables not shown: doi (chr), indexed (chr), issn (chr), issue (chr),
##      issued (chr), license_date (chr), license_url (chr),
##      license_delay.in.days (chr), license_content.version (chr), member
##      (chr), page (chr), prefix (chr), publisher (chr), reference.count
##      (chr), score (chr), source (chr), subject (chr), title (chr), type
##      (chr), url (chr), volume (chr), author (list), link (list), archive
##      (chr), alternative.id (chr), subtitle (chr)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;fetch-abstracts-ft-abstract&#34;&gt;Fetch abstracts: ft_abstract&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;PLOS&lt;/li&gt;
&lt;li&gt;Scopus&lt;/li&gt;
&lt;li&gt;Microsoft&lt;/li&gt;
&lt;li&gt;Crossref&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(res &amp;lt;- ft_search(query = &#39;biology&#39;, from = &#39;plos&#39;, limit = 10, 
   plosopts = list(fq = list(&#39;doc_type:full&#39;, &#39;-article_type:correction&#39;,
                  &#39;-article_type:viewpoints&#39;))))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Query:
##   [biology] 
## Found:
##   [PLoS: 170852; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0; Europe PMC: 0; Scopus: 0; Microsoft: 0] 
## Returned:
##   [PLoS: 10; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0; Europe PMC: 0; Scopus: 0; Microsoft: 0]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(out &amp;lt;- ft_abstract(x = res$plos$data$id, from = &amp;quot;plos&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &amp;lt;fulltext abstracts&amp;gt;
## Found:
##   [PLOS: 84; Scopus: 0; Microsoft: 0; Crossref: 0]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;fetch-articles-ft-get&#34;&gt;Fetch articles: ft_get&lt;/h2&gt;

&lt;p&gt;The function &lt;code&gt;ft_get&lt;/code&gt; is the workhorse for getting the namesake of the package:
full text articles.&lt;/p&gt;

&lt;p&gt;Beware that using this function can be tricky depending on where you want to
get articles from. While searching (&lt;code&gt;ft_search&lt;/code&gt;) usually doesn&amp;rsquo;t present any
barriers or stumbling blocks, &lt;code&gt;ft_get&lt;/code&gt; can get frustrating because so many
publishers paywall their articles. The combination of paywalls and their
patchwork of who gets to get through them means that we can&amp;rsquo;t easily predict
who will run into problems with Elsevier, Wiley, etc.&lt;/p&gt;

&lt;p&gt;With this version we&amp;rsquo;ve tried to bulk up the documentation as much as possible
to make jumping over these barriers as easy as possible.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ft_get()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Error in stop(&amp;quot;no &#39;ft_get&#39; method for &amp;quot;, class(x), call. = FALSE): argument &amp;quot;x&amp;quot; is missing, with no default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;get-full-text-links-ft-links&#34;&gt;Get full text links: ft_links&lt;/h2&gt;

&lt;p&gt;In case you want to sort out full text links yourself, and have those links for whatever purpose, &lt;code&gt;ft_links&lt;/code&gt; is your friend. It grabs data from PLOS, Crossref, Entrez, and BMC.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(res2 &amp;lt;- ft_search(query=&#39;ecology&#39;, from=&#39;crossref&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Query:
##   [ecology] 
## Found:
##   [PLoS: 0; BMC: 0; Crossref: 142207; Entrez: 0; arxiv: 0; biorxiv: 0; Europe PMC: 0; Scopus: 0; Microsoft: 0] 
## Returned:
##   [PLoS: 0; BMC: 0; Crossref: 10; Entrez: 0; arxiv: 0; biorxiv: 0; Europe PMC: 0; Scopus: 0; Microsoft: 0]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(out &amp;lt;- ft_links(res2))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &amp;lt;fulltext links&amp;gt;
## [Found] 10 
## [IDs] 10.2307/1929908 10.2307/1931096 10.2307/1934287 10.2307/1943146
##      10.2307/1930158 10.2307/1928969 10.2307/1935066 10.1002/ecy.1807
##      10.1016/s0169-5347(97)89918-1 10.1111/jiec.12669 ...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out$crossref
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $found
## [1] 10
## 
## $ids
##  [1] &amp;quot;10.2307/1929908&amp;quot;               &amp;quot;10.2307/1931096&amp;quot;              
##  [3] &amp;quot;10.2307/1934287&amp;quot;               &amp;quot;10.2307/1943146&amp;quot;              
##  [5] &amp;quot;10.2307/1930158&amp;quot;               &amp;quot;10.2307/1928969&amp;quot;              
##  [7] &amp;quot;10.2307/1935066&amp;quot;               &amp;quot;10.1002/ecy.1807&amp;quot;             
##  [9] &amp;quot;10.1016/s0169-5347(97)89918-1&amp;quot; &amp;quot;10.1111/jiec.12669&amp;quot;           
## 
## $data
## $data$`10.2307/1929908`
##                                                                     url
## 1 https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.2307%2F1929908
##               doi        type member
## 1 10.2307/1929908 unspecified    311
## 
## $data$`10.2307/1931096`
##                                                                    url
## 1 http://api.wiley.com/onlinelibrary/tdm/v1/articles/10.2307%2F1931096
##               doi        type member
## 1 10.2307/1931096 unspecified    311
## 
## $data$`10.2307/1934287`
##                                                                    url
## 1 http://api.wiley.com/onlinelibrary/tdm/v1/articles/10.2307%2F1934287
##               doi        type member
## 1 10.2307/1934287 unspecified    311
## 
## $data$`10.2307/1943146`
##                                                                    url
## 1 http://api.wiley.com/onlinelibrary/tdm/v1/articles/10.2307%2F1943146
##               doi        type member
## 1 10.2307/1943146 unspecified    311
## 
## $data$`10.2307/1930158`
##                                                                     url
## 1  http://api.wiley.com/onlinelibrary/tdm/v1/articles/10.2307%2F1930158
## 2 https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.2307%2F1930158
##               doi        type member
## 1 10.2307/1930158         pdf    311
## 2 10.2307/1930158 unspecified    311
## 
## $data$`10.2307/1928969`
##                                                                     url
## 1  http://api.wiley.com/onlinelibrary/tdm/v1/articles/10.2307%2F1928969
## 2 https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.2307%2F1928969
##               doi        type member
## 1 10.2307/1928969         pdf    311
## 2 10.2307/1928969 unspecified    311
## 
## $data$`10.2307/1935066`
##                                                                    url
## 1 http://api.wiley.com/onlinelibrary/tdm/v1/articles/10.2307%2F1935066
##               doi        type member
## 1 10.2307/1935066 unspecified    311
## 
## $data$`10.1002/ecy.1807`
##                                                                      url
## 1 https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.1002%2Fecy.1807
## 2       http://onlinelibrary.wiley.com/wol1/doi/10.1002/ecy.1807/fullpdf
##                doi        type member
## 1 10.1002/ecy.1807         pdf    311
## 2 10.1002/ecy.1807 unspecified    311
## 
## $data$`10.1016/s0169-5347(97)89918-1`
##                                                                                    url
## 1   https://api.elsevier.com/content/article/PII:S0169534797899181?httpAccept=text/xml
## 2 https://api.elsevier.com/content/article/PII:S0169534797899181?httpAccept=text/plain
##                             doi  type member
## 1 10.1016/s0169-5347(97)89918-1   xml     78
## 2 10.1016/s0169-5347(97)89918-1 plain     78
## 
## $data$`10.1111/jiec.12669`
##                                                                        url
## 1 https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.1111%2Fjiec.12669
## 2       http://onlinelibrary.wiley.com/wol1/doi/10.1111/jiec.12669/fullpdf
##                  doi        type member
## 1 10.1111/jiec.12669         pdf    311
## 2 10.1111/jiec.12669 unspecified    311
## 
## 
## $opts
## list()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out$crossref$data[[1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##                                                                     url
## 1 https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.2307%2F1929908
##               doi        type member
## 1 10.2307/1929908 unspecified    311
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;extract-text-ft-extract&#34;&gt;Extract text: ft_extract&lt;/h2&gt;

&lt;p&gt;This is a simple wrapper around the &lt;a href=&#34;https://github.com/ropensci/pdftools&#34;&gt;pdftools&lt;/a&gt; package - when dealing with
xml or plain text data, there&amp;rsquo;s no need to parse what you get from &lt;code&gt;ft_get&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;path &amp;lt;- system.file(&amp;quot;examples&amp;quot;, &amp;quot;example1.pdf&amp;quot;, package = &amp;quot;fulltext&amp;quot;)
(res &amp;lt;- ft_extract(path))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &amp;lt;document&amp;gt;/Library/Frameworks/R.framework/Versions/3.4/Resources/library/fulltext/examples/example1.pdf
##   Title: Suffering and mental health among older people living in nursing homes---a mixed-methods study
##   Producer: pdfTeX-1.40.10
##   Creation date: 2015-07-17
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that &lt;code&gt;ft_extract&lt;/code&gt; can now handle both a file path to a pdf file, or
raw bytes.&lt;/p&gt;

&lt;h2 id=&#34;extract-parts-of-documents-you-want-chunk&#34;&gt;Extract parts of documents you want: chunk&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;chunk()&lt;/code&gt; helps you quickly extract sections of articles you want aross many articles and many publishers. This only handles XML (there&amp;rsquo;s no structure in plain text and pdf text) We have internal scripts targeting specific publishers so that we can handle variation in how publishers structure their XML.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;rplos&amp;quot;)
(dois &amp;lt;- searchplos(q=&amp;quot;*:*&amp;quot;, fl=&#39;id&#39;,
   fq=list(&#39;doc_type:full&#39;,&amp;quot;article_type:\&amp;quot;research article\&amp;quot;&amp;quot;),
     limit=5)$data$id)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;10.1371/journal.pone.0074173&amp;quot; &amp;quot;10.1371/journal.pone.0060168&amp;quot;
## [3] &amp;quot;10.1371/journal.pone.0170933&amp;quot; &amp;quot;10.1371/journal.pone.0170932&amp;quot;
## [5] &amp;quot;10.1371/journal.pone.0187293&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- ft_get(dois, from = &amp;quot;plos&amp;quot;)
x %&amp;gt;% chunks(c(&amp;quot;doi&amp;quot;,&amp;quot;history&amp;quot;)) %&amp;gt;% tabularize()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $plos
##                            doi history.received history.accepted
## 1 10.1371/journal.pone.0074173       2013-04-04       2013-07-27
## 2 10.1371/journal.pone.0060168       2012-09-18       2013-02-25
## 3 10.1371/journal.pone.0170933       2016-10-05       2017-01-12
## 4 10.1371/journal.pone.0170932       2016-09-27       2017-01-12
## 5 10.1371/journal.pone.0187293       2016-12-16       2017-10-17
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;notes&#34;&gt;Notes&lt;/h2&gt;

&lt;h3 id=&#34;xxx&#34;&gt;xxx&lt;/h3&gt;

&lt;p&gt;xxx&lt;/p&gt;

&lt;h3 id=&#34;feedback&#34;&gt;Feedback!&lt;/h3&gt;

&lt;p&gt;Please do upgrade/install &lt;code&gt;fulltext&lt;/code&gt;  &lt;code&gt;v0.3&lt;/code&gt; and let us know what you think.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>solrium 1.0: Working with Solr from R</title>
      <link>https://ropensci.org/technotes/2017/11/08/solrium-solr-r/</link>
      <pubDate>Wed, 08 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/technotes/2017/11/08/solrium-solr-r/</guid>
      <description>
        
        

&lt;p&gt;Nearly 4 years ago I wrote on this blog about an R package &lt;a href=&#34;https://github.com/ropensci/solr&#34;&gt;solr&lt;/a&gt; for working with the database &lt;a href=&#34;https://lucene.apache.org/solr/&#34;&gt;Solr&lt;/a&gt;. Since then we&amp;rsquo;ve created a refresh of that package in the &lt;a href=&#34;https://github.com/ropensci/solrium&#34;&gt;solrium&lt;/a&gt; package. Since &lt;code&gt;solrium&lt;/code&gt; first hit CRAN about two years ago, users have raised a number of issues that required breaking changes. Thus, this blog post is about a major version bump in &lt;code&gt;solrium&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;what-is-solr&#34;&gt;What is Solr?&lt;/h2&gt;

&lt;p&gt;Solr is a &amp;ldquo;search platform&amp;rdquo; - a NoSQL database - data is organized by so called documents that are xml/json/etc blobs of text. Documents are nested within either collections or cores (depending on the mode you start Solr in). Solr makes it easy to search for documents, with a huge variety of parameters, and a number of different data formats (json/xml/csv). Solr is similar to &lt;a href=&#34;https://www.elastic.co/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt; (see our Elasticsearch client &lt;a href=&#34;https://github.com/ropensci/elastic&#34;&gt;elastic&lt;/a&gt;) - and was around before it. Solr in my opinion is harder to setup than Elasticsearch, but I don&amp;rsquo;t claim to be an expert on either.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;vignettes&#34;&gt;Vignettes&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/solrium/vignettes/search.html&#34;&gt;Solr Search with solrium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/solrium/vignettes/local_setup.html&#34;&gt;Local Solr setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/solrium/vignettes/document_management.html&#34;&gt;Document management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/solrium/vignettes/cores_collections.html&#34;&gt;Cores/collections management&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;noteable-features&#34;&gt;Noteable features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Added in v1, you can now work with many connection objects to different Solr instances.&lt;/li&gt;
&lt;li&gt;Methods for the major search functionalities: search, highlight, stats, mlt, group, and facet. In addition, a catch all function &lt;code&gt;all&lt;/code&gt; to combine all of those.&lt;/li&gt;
&lt;li&gt;Comprehensive coverage of the Solr HTTP API&lt;/li&gt;
&lt;li&gt;Can coerce data from Solr API into data.frame&amp;rsquo;s when possible&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;

&lt;p&gt;Install &lt;code&gt;solrium&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;solrium&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or get the development version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&amp;quot;ropensci/solrium&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(solrium)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;initialize-a-client&#34;&gt;Initialize a client&lt;/h2&gt;

&lt;p&gt;A big change in &lt;code&gt;v1&lt;/code&gt; of &lt;code&gt;solrium&lt;/code&gt; is &lt;code&gt;solr_connect&lt;/code&gt; has been replaced by &lt;code&gt;SolrClient&lt;/code&gt;. Now you create an &lt;code&gt;R6&lt;/code&gt; connection object with &lt;code&gt;SolrClient&lt;/code&gt;, then you can call methods on that &lt;code&gt;R6&lt;/code&gt; object, &lt;strong&gt;OR&lt;/strong&gt; you can pass the connection object to functions.&lt;/p&gt;

&lt;p&gt;By default, &lt;code&gt;SolrClient$new()&lt;/code&gt; sets connections details for a Solr instance that&amp;rsquo;s running on &lt;code&gt;localhost&lt;/code&gt;, and on port &lt;code&gt;8983&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(conn &amp;lt;- SolrClient$new())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; &amp;lt;Solr Client&amp;gt;
#&amp;gt;   host: 127.0.0.1
#&amp;gt;   path: 
#&amp;gt;   port: 8983
#&amp;gt;   scheme: http
#&amp;gt;   errors: simple
#&amp;gt;   proxy:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On instantiation, it does not check that the Solr instance is up, but merely sets connection details. You can check if the instance is up by doing for example (assuming you have a collection named &lt;code&gt;gettingstarted&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;conn$ping(&amp;quot;gettingstarted&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; $responseHeader
#&amp;gt; $responseHeader$zkConnected
#&amp;gt; [1] TRUE
#&amp;gt; 
#&amp;gt; $responseHeader$status
#&amp;gt; [1] 0
#&amp;gt; 
#&amp;gt; $responseHeader$QTime
#&amp;gt; [1] 163
#&amp;gt; 
#&amp;gt; $responseHeader$params
#&amp;gt; $responseHeader$params$q
#&amp;gt; [1] &amp;quot;{!lucene}*:*&amp;quot;
#&amp;gt; 
#&amp;gt; $responseHeader$params$distrib
#&amp;gt; [1] &amp;quot;false&amp;quot;
#&amp;gt; 
#&amp;gt; $responseHeader$params$df
#&amp;gt; [1] &amp;quot;_text_&amp;quot;
#&amp;gt; 
#&amp;gt; $responseHeader$params$rows
#&amp;gt; [1] &amp;quot;10&amp;quot;
#&amp;gt; 
#&amp;gt; $responseHeader$params$wt
#&amp;gt; [1] &amp;quot;json&amp;quot;
#&amp;gt; 
#&amp;gt; $responseHeader$params$echoParams
#&amp;gt; [1] &amp;quot;all&amp;quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $status
#&amp;gt; [1] &amp;quot;OK&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A good hint when connecting to a publicly exposed Solr instance is that you likely don&amp;rsquo;t need to specify a port, so a pattern like this should work to connect to a URL like &lt;code&gt;http://foobar.com/search&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;SolrClient$new(host = &amp;quot;foobar.com&amp;quot;, path = &amp;quot;search&amp;quot;, port = NULL)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the instance uses SSL, simply specify that like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;SolrClient$new(host = &amp;quot;foobar.com&amp;quot;, path = &amp;quot;search&amp;quot;, port = NULL, scheme = &amp;quot;https&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;query-and-body-parameters&#34;&gt;Query and body parameters&lt;/h2&gt;

&lt;p&gt;Another big change in the package is that we wanted to make it easy to determine whether your Solr query gets passed as query parameters in a &lt;code&gt;GET&lt;/code&gt; request or as body in a &lt;code&gt;POST&lt;/code&gt; request. Solr clients in some other languages do this, and it made sense to port over that idea here. Now you pass your key-value pairs to either &lt;code&gt;params&lt;/code&gt; or &lt;code&gt;body&lt;/code&gt;. If nothing is passed to &lt;code&gt;body&lt;/code&gt;, we do a &lt;code&gt;GET&lt;/code&gt; request. If something is passed to &lt;code&gt;body&lt;/code&gt; we do a &lt;code&gt;POST&lt;/code&gt; request, even if there&amp;rsquo;s also key-value pairs passed to &lt;code&gt;params&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This change does break the interface we had in the old version, but we think it&amp;rsquo;s worth it.&lt;/p&gt;

&lt;p&gt;For example, to do a search you have to pass the collection name and a list of named parameters:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;conn$search(name = &amp;quot;gettingstarted&amp;quot;, params = list(q = &amp;quot;*:*&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 5 x 5
#&amp;gt;      id   title title_str  `_version_` price
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
#&amp;gt; 1    10 adfadsf   adfadsf 1.582913e+18    NA
#&amp;gt; 2    12  though    though 1.582913e+18    NA
#&amp;gt; 3    14 animals   animals 1.582913e+18    NA
#&amp;gt; 4     1    &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt; 1.582913e+18   100
#&amp;gt; 5     2    &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt; 1.582913e+18   500
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can instead pass the connection object to &lt;code&gt;solr_search&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_search(conn, name = &amp;quot;gettingstarted&amp;quot;, params = list(q = &amp;quot;*:*&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 5 x 5
#&amp;gt;      id   title title_str  `_version_` price
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
#&amp;gt; 1    10 adfadsf   adfadsf 1.582913e+18    NA
#&amp;gt; 2    12  though    though 1.582913e+18    NA
#&amp;gt; 3    14 animals   animals 1.582913e+18    NA
#&amp;gt; 4     1    &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt; 1.582913e+18   100
#&amp;gt; 5     2    &amp;lt;NA&amp;gt;      &amp;lt;NA&amp;gt; 1.582913e+18   500
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And the same pattern applies for the other functions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;solr_facet&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solr_group&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solr_mlt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solr_highlight&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solr_stats&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;solr_all&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;new-functions-for-atomic-updates&#34;&gt;New functions for atomic updates&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ropensci/solrium/issues/97&#34;&gt;A user requested&lt;/a&gt; the ability to do &lt;a href=&#34;https://lucene.apache.org/solr/guide/7_0/updating-parts-of-documents.html&#34;&gt;atomic updates&lt;/a&gt; - partial updates to documents without having to re-index the entire document.&lt;/p&gt;

&lt;p&gt;Two functions were added: &lt;code&gt;update_atomic_json&lt;/code&gt; and &lt;code&gt;update_atomic_xml&lt;/code&gt; for JSON and XML based updates. Check out their help pages for usage.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;search-results-as-attributes&#34;&gt;Search results as attributes&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;solr_search&lt;/code&gt; and &lt;code&gt;solr_all&lt;/code&gt; in &lt;code&gt;v1&lt;/code&gt; gain attributes that include &lt;code&gt;numFound&lt;/code&gt;, &lt;code&gt;start&lt;/code&gt;, and &lt;code&gt;maxScore&lt;/code&gt;. That is, you can get to these three values after data is returned. Note that some Solr instances may not return all three values.&lt;/p&gt;

&lt;p&gt;For example, let&amp;rsquo;s use the Public Library of Science Solr search instance at &lt;a href=&#34;http://api.plos.org/search&#34;&gt;http://api.plos.org/search&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plos &amp;lt;- SolrClient$new(host = &amp;quot;api.plos.org&amp;quot;, path = &amp;quot;search&amp;quot;, port = NULL)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Search&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- plos$search(params = list(q = &amp;quot;*:*&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get attributes&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;attr(res, &amp;quot;numFound&amp;quot;)
#&amp;gt; [1] 1902279
attr(res, &amp;quot;start&amp;quot;)
#&amp;gt; [1] 0
attr(res, &amp;quot;maxScore&amp;quot;)
#&amp;gt; [1] 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;automatically-adjust-rows-parameter&#34;&gt;Automatically adjust rows parameter&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ropensci/solrium/pull/102&#34;&gt;A user higlighted&lt;/a&gt; that &lt;a href=&#34;https://wiki.apache.org/solr/SolrPerformanceProblems#Asking_for_too_many_rows&#34;&gt;there&amp;rsquo;s a performance penalty when asking for too many rows&lt;/a&gt;. The resulting change in &lt;code&gt;solrium&lt;/code&gt; is that in some search functions we automatically adjust the &lt;code&gt;rows&lt;/code&gt; parameter to avoid the performance penalty.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;usage-in-other-packages&#34;&gt;Usage in other packages&lt;/h2&gt;

&lt;p&gt;I maintain 4 other packages that use &lt;code&gt;solrium&lt;/code&gt;: &lt;a href=&#34;https://github.com/ropensci/rplos&#34;&gt;rplos&lt;/a&gt;, &lt;a href=&#34;https://github.com/ropensci/ritis&#34;&gt;ritis&lt;/a&gt;, &lt;a href=&#34;https://github.com/ropensci/rdatacite&#34;&gt;rdatacite&lt;/a&gt;, and &lt;a href=&#34;https://github.com/ropensci/rdryad&#34;&gt;rdryad&lt;/a&gt;. If you are interested in using &lt;code&gt;solrium&lt;/code&gt; in your package, looking at any of those four packages will give a good sense of how to do it.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;notes&#34;&gt;Notes&lt;/h2&gt;

&lt;h3 id=&#34;solr-pkg&#34;&gt;solr pkg&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;solr&lt;/code&gt; package will soon be archived on CRAN. We&amp;rsquo;ve moved all packages depending on it to &lt;code&gt;solrium&lt;/code&gt;. Let me know ASAP if you have any complaints about archiving it on CRAN.&lt;/p&gt;

&lt;h3 id=&#34;feedback&#34;&gt;Feedback!&lt;/h3&gt;

&lt;p&gt;Please do upgrade/install &lt;code&gt;solrium&lt;/code&gt;  &lt;code&gt;v1&lt;/code&gt; and let us know what you think.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>elastic - Elasticsearch for R</title>
      <link>https://ropensci.org/technotes/2017/08/02/elasticsearch-client/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/technotes/2017/08/02/elasticsearch-client/</guid>
      <description>
        
        

&lt;p&gt;&lt;strong&gt;elastic&lt;/strong&gt; is an R client for &lt;a href=&#34;https://www.elastic.co/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;elastic&lt;/code&gt; has been around since 2013, with the first commit in &lt;a href=&#34;https://github.com/ropensci/elastic/commit/f7b04589b2cb711a21223bb4f20b34bc9330ef8d&#34;&gt;November, 2013&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;sidebar - &amp;lsquo;elastic&amp;rsquo; was picked as a package named before the company now known as Elastic
changed their name to Elastic.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;what-is-elasticsearch&#34;&gt;What is Elasticsearch?&lt;/h3&gt;

&lt;p&gt;If you aren&amp;rsquo;t familiar with Elasticsearch, it is a distributed, RESTful search and analytics engine.
It&amp;rsquo;s similar to &lt;a href=&#34;https://lucene.apache.org/solr/&#34;&gt;Solr&lt;/a&gt;. It falls in the NoSQL bin of databases, holding data in JSON documents, instead
of rows and columns. Elasticsearch has a concept of &lt;strong&gt;index&lt;/strong&gt;, similar to a database in SQL-land.
You can hold many documents of similar type within a single index. There is powerful search
capabilities, including lots of different types of queries that can be done separately
or combined. And best of all it&amp;rsquo;s super fast.&lt;/p&gt;

&lt;h3 id=&#34;other-clients&#34;&gt;Other clients&lt;/h3&gt;

&lt;p&gt;The Elastic company maintains some official clients, including the Python client
&lt;a href=&#34;http://elasticsearch-py.readthedocs.io/en/master/&#34;&gt;elasticsearch-py&lt;/a&gt;, and it&amp;rsquo;s higher
level DSL client &lt;a href=&#34;https://elasticsearch-dsl.readthedocs.io/en/latest/&#34;&gt;elasticsearch-dsl&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I won&amp;rsquo;t talk much about it, but we have slowly been working on an R equivalent of the
Python DSL client, called &lt;a href=&#34;https://github.com/ropensci/elasticdsl&#34;&gt;elasticdsl&lt;/a&gt;, for
a human friendly way to compose Elasticsearch queries.&lt;/p&gt;

&lt;h3 id=&#34;vignettes&#34;&gt;Vignettes&lt;/h3&gt;

&lt;p&gt;Check out the &lt;a href=&#34;https://cran.rstudio.com/web/packages/elastic/vignettes/elastic_intro.html&#34;&gt;elastic introduction vignette&lt;/a&gt;
and the &lt;a href=&#34;https://cran.rstudio.com/web/packages/elastic/vignettes/search.html&#34;&gt;search vignette&lt;/a&gt; to get started.&lt;/p&gt;

&lt;h3 id=&#34;noteable-features&#34;&gt;Noteable features&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;elastic&lt;/code&gt; has nearly complete coverage of the Elasticsearch HTTP API. If there&amp;rsquo;s
anything missing you need in this client, let us know! Check out the
&lt;a href=&#34;https://github.com/ropensci/elastic/issues?q=is%3Aissue+is%3Aopen+label%3Afeatures&#34;&gt;features label&lt;/a&gt;
for features we plan to add to the package.&lt;/li&gt;
&lt;li&gt;We fail well. This is important to us. We allow the user to choose simple errors
to just give e.g., 404 HTTP error, or complex errors, including full stack trace
from Elasticsearch in addition to the HTTP errror. We strive to fail well when
users give the wrong type of input, etc. as well. Let us know if &lt;code&gt;elastic&lt;/code&gt; is not
failing well!&lt;/li&gt;
&lt;li&gt;We strive to allow R centric ways of interacting with Elasticsearch. For example,
in the function &lt;code&gt;docs_bulk&lt;/code&gt;, our interface to the Elasticsearch &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html&#34;&gt;bulk API&lt;/a&gt;
we make it easy to create documents in your Elasticsearch instance from R lists,
data.frame&amp;rsquo;s and from bulk format files on disk.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;elastic&lt;/code&gt; works with most versions of Elasticsearch. We run the test suite on 11
versions of Elasticsearch, from &lt;code&gt;v1.0.0&lt;/code&gt; up to &lt;code&gt;v5.5.0&lt;/code&gt;. We strive to fail well
with useful messages when there is a feature no longer available or one that is
a new feature and not available in previous Elasticsearch versions.&lt;/li&gt;
&lt;li&gt;Search inputs are flexible: lists and JSON strings both work.&lt;/li&gt;
&lt;li&gt;Arguably, a noteable feature is that this client has been around nearly 4 years,
so we&amp;rsquo;ve surfaced and squashed many bugs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;getting-help&#34;&gt;Getting help&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;If you have a bug or a feature request, post it in the repo at &lt;a href=&#34;https://github.com/ropensci/elastic/issues&#34;&gt;https://github.com/ropensci/elastic/issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Stackoverflow: Check out combination of the tags &lt;code&gt;[elasticsearch]&lt;/code&gt; and &lt;code&gt;[r]&lt;/code&gt; &lt;a href=&#34;https://stackoverflow.com/questions/tagged/elasticsearch+r&#34;&gt;https://stackoverflow.com/questions/tagged/elasticsearch+r&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Reach out to me on Twitter at &lt;a href=&#34;https://twitter.com/sckottie&#34;&gt;@sckottie&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Post question/problem in the &lt;a href=&#34;https://discuss.ropensci.org/&#34;&gt;rOpenSci discussion forum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Email me &lt;a href=&#34;mailto:myrmecocystus@gmail.com&#34;&gt;directly&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;

&lt;p&gt;Install &lt;code&gt;elastic&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;elastic&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or get the development version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&amp;quot;ropensci/elastic&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(elastic)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;m running Elasticsearch version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ping()$version$number
#&amp;gt; [1] &amp;quot;5.4.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;

&lt;h4 id=&#34;initialize-a-client&#34;&gt;Initialize a client&lt;/h4&gt;

&lt;p&gt;Using &lt;code&gt;connect()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;elastic::connect()
#&amp;gt; transport:  http
#&amp;gt; host:       127.0.0.1
#&amp;gt; port:       9200
#&amp;gt; path:       NULL
#&amp;gt; username:   NULL
#&amp;gt; password:   &amp;lt;secret&amp;gt;
#&amp;gt; errors:     simple
#&amp;gt; headers (names):  NULL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default, you connect to &lt;code&gt;localhost&lt;/code&gt; and port &lt;code&gt;9200&lt;/code&gt;. There&amp;rsquo;s paramaters
for setting transport schema, username, password, and base search path (e.g.,
&lt;code&gt;_search&lt;/code&gt; or something else).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;See bottom of post about possible changes in connections.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;get-some-data&#34;&gt;Get some data&lt;/h4&gt;

&lt;p&gt;Elasticsearch has a bulk load API to load data in fast. The format is pretty weird
though. It&amp;rsquo;s sort of JSON, but would pass no JSON linter. I include a few data
sets in &lt;code&gt;elastic&lt;/code&gt; so it&amp;rsquo;s easy to get up and running, and so when you run examples
in this package they&amp;rsquo;ll actually run the same way (hopefully).&lt;/p&gt;

&lt;h4 id=&#34;public-library-of-science-plos-data&#34;&gt;Public Library of Science (PLOS) data&lt;/h4&gt;

&lt;p&gt;A dataset inluded in the &lt;code&gt;elastic&lt;/code&gt; package is metadata for PLOS scholarly articles.
Get the file path, then load:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plosdat &amp;lt;- system.file(&amp;quot;examples&amp;quot;, &amp;quot;plos_data.json&amp;quot;, package = &amp;quot;elastic&amp;quot;)
invisible(docs_bulk(plosdat))
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;search&#34;&gt;Search&lt;/h4&gt;

&lt;p&gt;The main search function is &lt;code&gt;Search()&lt;/code&gt;. Running it without any inputs searches
across all indices - in this case only the &lt;code&gt;plos&lt;/code&gt; index.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Search()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; $took
#&amp;gt; [1] 1
#&amp;gt;
#&amp;gt; $timed_out
#&amp;gt; [1] FALSE
#&amp;gt;
#&amp;gt; $`_shards`
#&amp;gt; $`_shards`$total
#&amp;gt; [1] 5
#&amp;gt;
#&amp;gt; $`_shards`$successful
#&amp;gt; [1] 5
#&amp;gt;
#&amp;gt; $`_shards`$failed
#&amp;gt; [1] 0
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Search just the &lt;code&gt;plos&lt;/code&gt; index and only return 1 result&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Search(index = &amp;quot;plos&amp;quot;, size = 1)$hits$hits
#&amp;gt; [[1]]
#&amp;gt; [[1]]$`_index`
#&amp;gt; [1] &amp;quot;plos&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_type`
#&amp;gt; [1] &amp;quot;article&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_id`
#&amp;gt; [1] &amp;quot;0&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_score`
#&amp;gt; [1] 1
#&amp;gt;
#&amp;gt; [[1]]$`_source`
#&amp;gt; [[1]]$`_source`$id
#&amp;gt; [1] &amp;quot;10.1371/journal.pone.0007737&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_source`$title
#&amp;gt; [1] &amp;quot;Phospholipase C-β4 Is Essential for the Progression of the Normal Sleep Sequence and Ultradian Body Temperature Rhythms in Mice&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Search the &lt;code&gt;plos&lt;/code&gt; index, and the &lt;code&gt;article&lt;/code&gt; document type, sort by title, and query for &lt;em&gt;antibody&lt;/em&gt;, limit to 1 result.&lt;/p&gt;

&lt;p&gt;First, with Elasticsearch &lt;code&gt;v5&lt;/code&gt; and greater, we need to set &lt;code&gt;fielddata = true&lt;/code&gt; if we want to search on or sort on a text field.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mapping_create(&amp;quot;plos&amp;quot;, &amp;quot;article&amp;quot;, update_all_types = TRUE, body = &#39;{
   &amp;quot;properties&amp;quot;: {
     &amp;quot;title&amp;quot;: {
     &amp;quot;type&amp;quot;:     &amp;quot;text&amp;quot;,
     &amp;quot;fielddata&amp;quot;: true
   }
 }
}&#39;)
#&amp;gt; $acknowledged
#&amp;gt; [1] TRUE
Search(index = &amp;quot;plos&amp;quot;, type = &amp;quot;article&amp;quot;, sort = &amp;quot;title&amp;quot;, q = &amp;quot;antibody&amp;quot;, size = 1)$hits$hits
#&amp;gt; [[1]]
#&amp;gt; [[1]]$`_index`
#&amp;gt; [1] &amp;quot;plos&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_type`
#&amp;gt; [1] &amp;quot;article&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_id`
#&amp;gt; [1] &amp;quot;568&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_score`
#&amp;gt; NULL
#&amp;gt;
#&amp;gt; [[1]]$`_source`
#&amp;gt; [[1]]$`_source`$id
#&amp;gt; [1] &amp;quot;10.1371/journal.pone.0085002&amp;quot;
#&amp;gt;
#&amp;gt; [[1]]$`_source`$title
#&amp;gt; [1] &amp;quot;Evaluation of 131I-Anti-Angiotensin II Type 1 Receptor Monoclonal Antibody as a Reporter for Hepatocellular Carcinoma&amp;quot;
#&amp;gt;
#&amp;gt;
#&amp;gt; [[1]]$sort
#&amp;gt; [[1]]$sort[[1]]
#&amp;gt; [1] &amp;quot;1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;get-documents&#34;&gt;Get documents&lt;/h4&gt;

&lt;p&gt;Get document with &lt;code&gt;id=1&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;docs_get(index = &#39;plos&#39;, type = &#39;article&#39;, id = 1)
#&amp;gt; $`_index`
#&amp;gt; [1] &amp;quot;plos&amp;quot;
#&amp;gt;
#&amp;gt; $`_type`
#&amp;gt; [1] &amp;quot;article&amp;quot;
#&amp;gt;
#&amp;gt; $`_id`
#&amp;gt; [1] &amp;quot;1&amp;quot;
#&amp;gt;
#&amp;gt; $`_version`
#&amp;gt; [1] 1
#&amp;gt;
#&amp;gt; $found
#&amp;gt; [1] TRUE
#&amp;gt;
#&amp;gt; $`_source`
#&amp;gt; $`_source`$id
#&amp;gt; [1] &amp;quot;10.1371/journal.pone.0098602&amp;quot;
#&amp;gt;
#&amp;gt; $`_source`$title
#&amp;gt; [1] &amp;quot;Population Genetic Structure of a Sandstone Specialist and a Generalist Heath Species at Two Levels of Sandstone Patchiness across the Strait of Gibraltar&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get certain fields&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;docs_get(index = &#39;plos&#39;, type = &#39;article&#39;, id = 1, fields = &#39;id&#39;)
#&amp;gt; $`_index`
#&amp;gt; [1] &amp;quot;plos&amp;quot;
#&amp;gt;
#&amp;gt; $`_type`
#&amp;gt; [1] &amp;quot;article&amp;quot;
#&amp;gt;
#&amp;gt; $`_id`
#&amp;gt; [1] &amp;quot;1&amp;quot;
#&amp;gt;
#&amp;gt; $`_version`
#&amp;gt; [1] 1
#&amp;gt;
#&amp;gt; $found
#&amp;gt; [1] TRUE
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;raw-json-data&#34;&gt;Raw JSON data&lt;/h4&gt;

&lt;p&gt;You can optionally get back raw JSON from many functions by setting parameter &lt;code&gt;raw=TRUE&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For example, get raw JSON, then parse with &lt;code&gt;jsonlite&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(out &amp;lt;- docs_mget(index = &amp;quot;plos&amp;quot;, type = &amp;quot;article&amp;quot;, id = 5:6, raw = TRUE))
#&amp;gt; [1] &amp;quot;{\&amp;quot;docs\&amp;quot;:[{\&amp;quot;_index\&amp;quot;:\&amp;quot;plos\&amp;quot;,\&amp;quot;_type\&amp;quot;:\&amp;quot;article\&amp;quot;,\&amp;quot;_id\&amp;quot;:\&amp;quot;5\&amp;quot;,\&amp;quot;_version\&amp;quot;:1,\&amp;quot;found\&amp;quot;:true,\&amp;quot;_source\&amp;quot;:{\&amp;quot;id\&amp;quot;:\&amp;quot;10.1371/journal.pone.0085123\&amp;quot;,\&amp;quot;title\&amp;quot;:\&amp;quot;MiR-21 Is under Control of STAT5 but Is Dispensable for Mammary Development and Lactation\&amp;quot;}},{\&amp;quot;_index\&amp;quot;:\&amp;quot;plos\&amp;quot;,\&amp;quot;_type\&amp;quot;:\&amp;quot;article\&amp;quot;,\&amp;quot;_id\&amp;quot;:\&amp;quot;6\&amp;quot;,\&amp;quot;_version\&amp;quot;:1,\&amp;quot;found\&amp;quot;:true,\&amp;quot;_source\&amp;quot;:{\&amp;quot;id\&amp;quot;:\&amp;quot;10.1371/journal.pone.0098600\&amp;quot;,\&amp;quot;title\&amp;quot;:\&amp;quot;Correction: Designing Mixed Species Tree Plantations for the Tropics: Balancing Ecological Attributes of Species with Landholder Preferences in the Philippines\&amp;quot;}}]}&amp;quot;
#&amp;gt; attr(,&amp;quot;class&amp;quot;)
#&amp;gt; [1] &amp;quot;elastic_mget&amp;quot;
jsonlite::fromJSON(out)
#&amp;gt; $docs
#&amp;gt;   _index   _type _id _version found                   _source.id
#&amp;gt; 1   plos article   5        1  TRUE 10.1371/journal.pone.0085123
#&amp;gt; 2   plos article   6        1  TRUE 10.1371/journal.pone.0098600
#&amp;gt;                                                                                                                                                     _source.title
#&amp;gt; 1                                                                       MiR-21 Is under Control of STAT5 but Is Dispensable for Mammary Development and Lactation
#&amp;gt; 2 Correction: Designing Mixed Species Tree Plantations for the Tropics: Balancing Ecological Attributes of Species with Landholder Preferences in the Philippines
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;aggregation-search&#34;&gt;Aggregation search&lt;/h4&gt;

&lt;p&gt;Here, we&amp;rsquo;ll use another dataset that comes with the package on Shakespeare plays.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gbifdat &amp;lt;- system.file(&amp;quot;examples&amp;quot;, &amp;quot;gbif_data.json&amp;quot;, package = &amp;quot;elastic&amp;quot;)
invisible(docs_bulk(gbifdat))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Define an aggregation query:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;aggs &amp;lt;- &#39;{
    &amp;quot;aggs&amp;quot;: {
        &amp;quot;latbuckets&amp;quot; : {
           &amp;quot;histogram&amp;quot; : {
               &amp;quot;field&amp;quot; : &amp;quot;decimalLatitude&amp;quot;,
               &amp;quot;interval&amp;quot; : 5
           }
        }
    }
}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Search the &lt;code&gt;gbif&lt;/code&gt; index&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- Search(index = &amp;quot;gbif&amp;quot;, body = aggs, size = 0)$aggregations$latbuckets$buckets
do.call(&amp;quot;rbind.data.frame&amp;quot;, res)
#&amp;gt;    key doc_count
#&amp;gt; 2  -35         1
#&amp;gt; 22 -30         0
#&amp;gt; 3  -25         0
#&amp;gt; 4  -20         0
#&amp;gt; 5  -15         0
#&amp;gt; 6  -10         0
#&amp;gt; 7   -5         1
#&amp;gt; 8    0         0
#&amp;gt; 9    5         0
#&amp;gt; 10  10         0
#&amp;gt; 11  15         0
#&amp;gt; 12  20         0
#&amp;gt; 13  25         4
#&amp;gt; 14  30         2
#&amp;gt; 15  35         3
#&amp;gt; 16  40         2
#&amp;gt; 17  45        66
#&amp;gt; 18  50       183
#&amp;gt; 19  55       487
#&amp;gt; 20  60       130
#&amp;gt; 21  65        20
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;scrolling-search-instead-of-paging&#34;&gt;Scrolling search - instead of paging&lt;/h4&gt;

&lt;p&gt;When you want all the documents, your best bet is likely to be &lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html&#34;&gt;scrolling search&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s an example. First, use &lt;code&gt;Search()&lt;/code&gt;, setting a value for the &lt;code&gt;scroll&lt;/code&gt; parameter.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res1 &amp;lt;- Search(index = &#39;shakespeare&#39;, scroll = &amp;quot;1m&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You get a scroll ID back when setting the &lt;code&gt;scroll&lt;/code&gt; parameter&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res1$`_scroll_id`
#&amp;gt; [1] &amp;quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAElFnZ2X3FJVWEyUU1HQjl2cFpWUFl0cXcAAAAAAAABJBZ2dl9xSVVhMlFNR0I5dnBaVlBZdHF3AAAAAAAAAScWdnZfcUlVYTJRTUdCOXZwWlZQWXRxdwAAAAAAAAEmFnZ2X3FJVWEyUU1HQjl2cFpWUFl0cXcAAAAAAAABIxZ2dl9xSVVhMlFNR0I5dnBaVlBZdHF3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Use a while loop to get all results&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out1 &amp;lt;- list()
hits &amp;lt;- 1
while (hits != 0) {
  tmp1 &amp;lt;- scroll(scroll_id = res1$`_scroll_id`)
  hits &amp;lt;- length(tmp1$hits$hits)
  if (hits &amp;gt; 0) {
   out1 &amp;lt;- c(out1, tmp1$hits$hits)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Woohoo! Collected all 1 documents in very little time.&lt;/p&gt;

&lt;p&gt;Now, get &lt;code&gt;_source&lt;/code&gt; from each document:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;docs &amp;lt;- lapply(out1, &amp;quot;[[&amp;quot;, &amp;quot;_source&amp;quot;)
length(docs)
#&amp;gt; [1] 4988
vapply(docs[1:10], &amp;quot;[[&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;text_entry&amp;quot;)
#&amp;gt;  [1] &amp;quot;Without much shame retold or spoken of.&amp;quot;
#&amp;gt;  [2] &amp;quot;For more uneven and unwelcome news&amp;quot;
#&amp;gt;  [3] &amp;quot;And shape of likelihood, the news was told;&amp;quot;
#&amp;gt;  [4] &amp;quot;Mordake the Earl of Fife, and eldest son&amp;quot;
#&amp;gt;  [5] &amp;quot;It is a conquest for a prince to boast of.&amp;quot;
#&amp;gt;  [6] &amp;quot;Amongst a grove, the very straightest plant;&amp;quot;
#&amp;gt;  [7] &amp;quot;That some night-tripping fairy had exchanged&amp;quot;
#&amp;gt;  [8] &amp;quot;Then would I have his Harry, and he mine.&amp;quot;
#&amp;gt;  [9] &amp;quot;This is his uncles teaching; this is Worcester,&amp;quot;
#&amp;gt; [10] &amp;quot;Malevolent to you in all aspects;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;bulk-documents&#34;&gt;Bulk documents&lt;/h4&gt;

&lt;p&gt;You&amp;rsquo;ve already seen the bulk docs API in action above. Above though, we were
using &lt;code&gt;docs_bulk.character&lt;/code&gt; - where the input is a character string that&amp;rsquo;s a
file path.&lt;/p&gt;

&lt;p&gt;Here, I&amp;rsquo;ll describe briefly how you can insert any data.frame as documents in your
Elasticsearch instance. We&amp;rsquo;ll use the diamonds dataset from the ~54K row &lt;code&gt;ggplot2&lt;/code&gt;
package.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; $acknowledged
#&amp;gt; [1] TRUE
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
invisible(docs_bulk(diamonds, &amp;quot;diam&amp;quot;))
#&amp;gt; |==================================| 100%
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Search(&amp;quot;diam&amp;quot;)$hits$total
#&amp;gt; [1] 47375
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s pretty easy! This function is used a lot, particularly with data.frame&amp;rsquo;s - so
we get many questions/feedback on this so it will just keep getting better/faster.&lt;/p&gt;

&lt;h3 id=&#34;to-do&#34;&gt;TO DO&lt;/h3&gt;

&lt;h4 id=&#34;connections&#34;&gt;Connections&lt;/h4&gt;

&lt;p&gt;We&amp;rsquo;re planning to roll out changes in how you connect to Elasticsearch from &lt;code&gt;elastic&lt;/code&gt;.
Right now, you can only connect to one Elasticsearch instance per R session -
your details are set and then recalled internally in each function. We plan to change
this to instantiate a client and then you either call functions on the client
(e.g., using &lt;code&gt;R6&lt;/code&gt;) or pass the client object onto functions.&lt;/p&gt;

&lt;p&gt;Checkout &lt;a href=&#34;https://github.com/ropensci/elastic/issues/87&#34;&gt;issue #87&lt;/a&gt; to follow
progress or discuss.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h4 id=&#34;move-to-using-crul-for-http&#34;&gt;Move to using crul for http&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;crul&lt;/code&gt; is a relatively new R http client - and has async baked in - as well as mocking.
Development should be easier with it as I can mock requests for test suites, and
allow users to toggle async more easily.&lt;/p&gt;

&lt;h3 id=&#34;call-to-action&#34;&gt;Call to action&lt;/h3&gt;

&lt;p&gt;We can use your help! Elasticsearch development moves pretty fast - we&amp;rsquo;d love this client to
work with every single Elasticsearch version to the extent possible - and we&amp;rsquo;d love to
squash every bug and solve every feature request fast.&lt;/p&gt;

&lt;p&gt;If you need to use Elasticsearch from R, please try out &lt;code&gt;elastic&lt;/code&gt;!&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Report bugs!&lt;/li&gt;
&lt;li&gt;File feature requests!&lt;/li&gt;
&lt;li&gt;Send PR&amp;rsquo;s!&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>All the fake data that&#39;s fit to print</title>
      <link>https://ropensci.org/technotes/2017/06/22/charlatan/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/technotes/2017/06/22/charlatan/</guid>
      <description>
        
        

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;charlatan&lt;/strong&gt; makes fake data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Excited to annonunce a new package called &lt;code&gt;charlatan&lt;/code&gt;. While perusing
packages from other programming languages, I saw a neat Python library
called &lt;code&gt;faker&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;charlatan&lt;/code&gt; is inspired from and ports many things from Python&amp;rsquo;s
&lt;a href=&#34;https://github.com/joke2k/faker&#34;&gt;https://github.com/joke2k/faker&lt;/a&gt; library. In turn, &lt;code&gt;faker&lt;/code&gt; was inspired from
&lt;a href=&#34;https://github.com/fzaninotto/Faker&#34;&gt;PHP&amp;rsquo;s faker&lt;/a&gt;,
&lt;a href=&#34;http://search.cpan.org/~jasonk/Data-Faker-0.07/&#34;&gt;Perl&amp;rsquo;s Faker&lt;/a&gt;, and
&lt;a href=&#34;https://rubygems.org/gems/faker&#34;&gt;Ruby&amp;rsquo;s faker&lt;/a&gt;. It appears that the PHP
library was the original - nice work PHP.&lt;/p&gt;

&lt;h2 id=&#34;use-cases&#34;&gt;Use cases&lt;/h2&gt;

&lt;p&gt;What could you do with this package? Here&amp;rsquo;s some use cases:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Students in a classroom setting learning any task that needs a dataset.&lt;/li&gt;
&lt;li&gt;People doing simulations/modeling that need some fake data&lt;/li&gt;
&lt;li&gt;Generate fake dataset of users for a database before actual users exist&lt;/li&gt;
&lt;li&gt;Complete missing spots in a dataset&lt;/li&gt;
&lt;li&gt;Generate fake data to replace sensitive real data with before public release&lt;/li&gt;
&lt;li&gt;Create a random set of colors for visualization&lt;/li&gt;
&lt;li&gt;Generate random coordinates for a map&lt;/li&gt;
&lt;li&gt;Get a set of randomly generated DOIs (Digial Object Identifiers) to
assign to fake scholarly artifacts&lt;/li&gt;
&lt;li&gt;Generate fake taxonomic names for a biological dataset&lt;/li&gt;
&lt;li&gt;Get a set of fake sequences to use to test code/software that uses
sequence data&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Language support: A huge selling point of &lt;code&gt;charlatan&lt;/code&gt; is language support.
Of course for some data types (numbers), languages don&amp;rsquo;t come into play, but
for many they do. That means you can create fake datasets specific to a
language, or a dataset with a mix of languages, etc. For the variables
in this package, we have not yet ported over all languages for those
variables that Python&amp;rsquo;s &lt;code&gt;faker&lt;/code&gt; has.&lt;/li&gt;
&lt;li&gt;Lite weight: We&amp;rsquo;ve tried to make this package as lite as possible so
that it&amp;rsquo;s just generally easy to install, but also can be used in
other packages or workflows while bringing along as little baggage
as possible.&lt;/li&gt;
&lt;li&gt;Reviewed: it&amp;rsquo;s been reviewed! See reviews by &lt;a href=&#34;reviewba&#34;&gt;Brooke Anderson&lt;/a&gt; and
&lt;a href=&#34;(https://github.com/ropensci/onboarding/issues/94#issuecomment-283799109)&#34;&gt;Tristan Mahr&lt;/a&gt;, and handling editor &lt;a href=&#34;https://github.com/noamross&#34;&gt;Noam Ross&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R specific features such as methods to create data.frame&amp;rsquo;s (so the
user doesn’t have to do the extra step of putting vectors together)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;status&#34;&gt;Status&lt;/h2&gt;

&lt;p&gt;We have not ported every variable, or every language yet in those variables.
We have added some variables to &lt;code&gt;charlatan&lt;/code&gt; that are not in &lt;code&gt;faker&lt;/code&gt; (e.g.,
taxonomy, gene sequences). Check out the &lt;a href=&#34;https://github.com/ropensci/charlatan/issues&#34;&gt;issues&lt;/a&gt;
to follow progress.&lt;/p&gt;

&lt;h2 id=&#34;package-api&#34;&gt;Package API&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ch_generate&lt;/code&gt;: generate a data.frame with fake data&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fraudster&lt;/code&gt;: single interface to all fake data methods&lt;/li&gt;
&lt;li&gt;High level interfaces: There are high level functions prefixed with
&lt;code&gt;ch_&lt;/code&gt; that wrap low level interfaces, and are meant to be easier
to use and provide easy way to make many instances of a thing.&lt;/li&gt;
&lt;li&gt;Low level interfaces: All of these are R6 objects that a user can
initialize and then call methods on the them.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;other-r-work-in-this-space&#34;&gt;Other R work in this space:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/paulhendricks/generator&#34;&gt;generator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/fakeR/&#34;&gt;fakeR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/karthik/randNames&#34;&gt;randNames&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;vignette&#34;&gt;Vignette&lt;/h2&gt;

&lt;p&gt;Check out the &lt;a href=&#34;https://cran.rstudio.com/web/packages/charlatan/vignettes/charlatan_vignette.html&#34;&gt;package vignette&lt;/a&gt; to get started.&lt;/p&gt;

&lt;h2 id=&#34;setup&#34;&gt;setup&lt;/h2&gt;

&lt;p&gt;Install &lt;code&gt;charlatan&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;charlatan&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or get the development version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&amp;quot;ropensci/charlatan&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(charlatan)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;

&lt;h3 id=&#34;high-level-interface&#34;&gt;high level interface&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;fraudster&lt;/code&gt; is an interface for all fake data variables (and locales):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- fraudster()
x$job()
#&amp;gt; [1] &amp;quot;Textile designer&amp;quot;
x$name()
#&amp;gt; [1] &amp;quot;Cris Johnston-Tremblay&amp;quot;
x$job()
#&amp;gt; [1] &amp;quot;Database administrator&amp;quot;
x$color_name()
#&amp;gt; [1] &amp;quot;SaddleBrown&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you want to set locale, do so like &lt;code&gt;fraudster(locale = &amp;quot;{locale}&amp;quot;)&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;locale-support&#34;&gt;locale support&lt;/h3&gt;

&lt;p&gt;The locales that are supported vary by data variable. We&amp;rsquo;re adding more
locales through time, so do check in from time to time - or even better,
send a pull request adding support for the locale you want for the
variable(s) you want.&lt;/p&gt;

&lt;p&gt;As an example, you can set locale for job data to any number of supported
locales.&lt;/p&gt;

&lt;p&gt;For jobs:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_job(locale = &amp;quot;en_US&amp;quot;, n = 3)
#&amp;gt; [1] &amp;quot;Charity officer&amp;quot;   &amp;quot;Financial adviser&amp;quot; &amp;quot;Buyer, industrial&amp;quot;
ch_job(locale = &amp;quot;fr_FR&amp;quot;, n = 3)
#&amp;gt; [1] &amp;quot;Illustrateur&amp;quot;                 &amp;quot;Guichetier&amp;quot;
#&amp;gt; [3] &amp;quot;Responsable d&#39;ordonnancement&amp;quot;
ch_job(locale = &amp;quot;hr_HR&amp;quot;, n = 3)
#&amp;gt; [1] &amp;quot;Pomoćnik strojovođe&amp;quot;
#&amp;gt; [2] &amp;quot;Pećar&amp;quot;
#&amp;gt; [3] &amp;quot;Konzervator – restaurator savjetnik&amp;quot;
ch_job(locale = &amp;quot;uk_UA&amp;quot;, n = 3)
#&amp;gt; [1] &amp;quot;Фрілансер&amp;quot;  &amp;quot;Астрофізик&amp;quot; &amp;quot;Доцент&amp;quot;
ch_job(locale = &amp;quot;zh_TW&amp;quot;, n = 3)
#&amp;gt; [1] &amp;quot;包裝設計&amp;quot;         &amp;quot;空調冷凍技術人員&amp;quot; &amp;quot;鍋爐操作技術人員&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For colors:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_color_name(locale = &amp;quot;en_US&amp;quot;, n = 3)
#&amp;gt; [1] &amp;quot;DarkMagenta&amp;quot; &amp;quot;Navy&amp;quot;        &amp;quot;LightGray&amp;quot;
ch_color_name(locale = &amp;quot;uk_UA&amp;quot;, n = 3)
#&amp;gt; [1] &amp;quot;Синій ВПС&amp;quot;          &amp;quot;Темно-зелений хакі&amp;quot; &amp;quot;Берлінська лазур&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;charlatan&lt;/code&gt; will tell you when a locale is not supported&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_job(locale = &amp;quot;cv_MN&amp;quot;)
#&amp;gt; Error: cv_MN not in set of available locales
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;generate-a-dataset&#34;&gt;generate a dataset&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;ch_generate()&lt;/code&gt; helps you create data.frame&amp;rsquo;s with whatever variables
you want that &lt;code&gt;charlatan&lt;/code&gt; supports. Then you&amp;rsquo;re ready to use the
data.frame immediately in whatever your application is.&lt;/p&gt;

&lt;p&gt;By default, you get back a certain set of variables. Right now, that is:
&lt;code&gt;name&lt;/code&gt;, &lt;code&gt;job&lt;/code&gt;, and &lt;code&gt;phone_number&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_generate()
#&amp;gt; # A tibble: 10 x 3
#&amp;gt;                          name                       job
#&amp;gt;                         &amp;lt;chr&amp;gt;                     &amp;lt;chr&amp;gt;
#&amp;gt;  1                  Coy Davis     Geneticist, molecular
#&amp;gt;  2               Artis Senger                 Press sub
#&amp;gt;  3                 Tal Rogahn              Town planner
#&amp;gt;  4             Nikolas Carter         Barrister&#39;s clerk
#&amp;gt;  5            Sharlene Kemmer Insurance account manager
#&amp;gt;  6            Babyboy Volkman           Quality manager
#&amp;gt;  7 Dr. Josephus Marquardt DVM                  Best boy
#&amp;gt;  8                Vernal Dare            Engineer, site
#&amp;gt;  9              Emilia Hessel       Administrator, arts
#&amp;gt; 10              Urijah Beatty     Editor, commissioning
#&amp;gt; # ... with 1 more variables: phone_number &amp;lt;chr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can select just the variables you want:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_generate(&#39;job&#39;, &#39;phone_number&#39;, n = 30)
#&amp;gt; # A tibble: 30 x 2
#&amp;gt;                           job         phone_number
#&amp;gt;                         &amp;lt;chr&amp;gt;                &amp;lt;chr&amp;gt;
#&amp;gt;  1        Call centre manager  1-670-715-3079x9104
#&amp;gt;  2 Nurse, learning disability 1-502-781-3386x33524
#&amp;gt;  3           Network engineer       1-692-089-3060
#&amp;gt;  4           Industrial buyer       1-517-855-8517
#&amp;gt;  5     Database administrator  (999)474-9975x89650
#&amp;gt;  6       Operations geologist          06150655769
#&amp;gt;  7             Engineer, land     360-043-3630x592
#&amp;gt;  8     Pension scheme manager        (374)429-6821
#&amp;gt;  9          Personnel officer   1-189-574-3348x338
#&amp;gt; 10         Editor, film/video       1-698-135-1664
#&amp;gt; # ... with 20 more rows
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;data-types&#34;&gt;Data types&lt;/h3&gt;

&lt;p&gt;A sampling of the data types available in &lt;code&gt;charlatan&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;person name&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_name()
#&amp;gt; [1] &amp;quot;Jefferey West-O&#39;Connell&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_name(10)
#&amp;gt;  [1] &amp;quot;Dylon Hintz&amp;quot;          &amp;quot;Dr. Billy Willms DDS&amp;quot; &amp;quot;Captain Bednar III&amp;quot;
#&amp;gt;  [4] &amp;quot;Carli Torp&amp;quot;           &amp;quot;Price Strosin III&amp;quot;    &amp;quot;Grady Mayert&amp;quot;
#&amp;gt;  [7] &amp;quot;Nat Herman-Kuvalis&amp;quot;   &amp;quot;Noelle Funk&amp;quot;          &amp;quot;Dr. Jaycie Herzog MD&amp;quot;
#&amp;gt; [10] &amp;quot;Ms. Andrea Zemlak&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;phone number&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_phone_number()
#&amp;gt; [1] &amp;quot;643.993.1958&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_phone_number(10)
#&amp;gt;  [1] &amp;quot;+06(6)6080789632&amp;quot;    &amp;quot;05108334280&amp;quot;         &amp;quot;447-126-9775&amp;quot;
#&amp;gt;  [4] &amp;quot;+96(7)2112213020&amp;quot;    &amp;quot;495-425-1506&amp;quot;        &amp;quot;1-210-372-3188x514&amp;quot;
#&amp;gt;  [7] &amp;quot;(300)951-5115&amp;quot;       &amp;quot;680.567.5321&amp;quot;        &amp;quot;1-947-805-4758x8167&amp;quot;
#&amp;gt; [10] &amp;quot;888-998-5511x554&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;job&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_job()
#&amp;gt; [1] &amp;quot;Scientist, water quality&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_job(10)
#&amp;gt;  [1] &amp;quot;Engineer, production&amp;quot;
#&amp;gt;  [2] &amp;quot;Architect&amp;quot;
#&amp;gt;  [3] &amp;quot;Exhibitions officer, museum/gallery&amp;quot;
#&amp;gt;  [4] &amp;quot;Patent attorney&amp;quot;
#&amp;gt;  [5] &amp;quot;Surveyor, minerals&amp;quot;
#&amp;gt;  [6] &amp;quot;Electronics engineer&amp;quot;
#&amp;gt;  [7] &amp;quot;Secondary school teacher&amp;quot;
#&amp;gt;  [8] &amp;quot;Intelligence analyst&amp;quot;
#&amp;gt;  [9] &amp;quot;Nutritional therapist&amp;quot;
#&amp;gt; [10] &amp;quot;Information officer&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;messy-data&#34;&gt;Messy data&lt;/h3&gt;

&lt;p&gt;Real data is messy!  &lt;code&gt;charlatan&lt;/code&gt; makes it easy to create
messy data. This is still in the early stages so is not available
across most data types and languages, but we&amp;rsquo;re working on it.&lt;/p&gt;

&lt;p&gt;For example, create messy names:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ch_name(50, messy = TRUE)
#&amp;gt;  [1] &amp;quot;Mr. Vernell Hoppe Jr.&amp;quot;     &amp;quot;Annika Considine d.d.s.&amp;quot;
#&amp;gt;  [3] &amp;quot;Dr. Jose Kunde DDS&amp;quot;        &amp;quot;Karol Leuschke-Runte&amp;quot;
#&amp;gt;  [5] &amp;quot;Kayleen Kutch-Hintz&amp;quot;       &amp;quot;Jahir Green&amp;quot;
#&amp;gt;  [7] &amp;quot;Stuart Emmerich&amp;quot;           &amp;quot;Hillard Schaden&amp;quot;
#&amp;gt;  [9] &amp;quot;Mr. Caden Braun&amp;quot;           &amp;quot;Willie Ebert&amp;quot;
#&amp;gt; [11] &amp;quot;Meg Abbott PhD&amp;quot;            &amp;quot;Dr Rahn Huel&amp;quot;
#&amp;gt; [13] &amp;quot;Kristina Crooks d.d.s.&amp;quot;    &amp;quot;Lizbeth Hansen&amp;quot;
#&amp;gt; [15] &amp;quot;Mrs. Peyton Kuhn&amp;quot;          &amp;quot;Hayley Bernier&amp;quot;
#&amp;gt; [17] &amp;quot;Dr. Lavon Schimmel d.d.s.&amp;quot; &amp;quot;Iridian Murray&amp;quot;
#&amp;gt; [19] &amp;quot;Cary Romaguera&amp;quot;            &amp;quot;Tristan Windler&amp;quot;
#&amp;gt; [21] &amp;quot;Marlana Schroeder md&amp;quot;      &amp;quot;Mr. Treyton Nitzsche&amp;quot;
#&amp;gt; [23] &amp;quot;Hilmer Nitzsche-Glover&amp;quot;    &amp;quot;Marius Dietrich md&amp;quot;
#&amp;gt; [25] &amp;quot;Len Mertz&amp;quot;                 &amp;quot;Mrs Adyson Wunsch DVM&amp;quot;
#&amp;gt; [27] &amp;quot;Dr. Clytie Feest DDS&amp;quot;      &amp;quot;Mr. Wong Lebsack I&amp;quot;
#&amp;gt; [29] &amp;quot;Arland Kessler&amp;quot;            &amp;quot;Mrs Billy O&#39;Connell m.d.&amp;quot;
#&amp;gt; [31] &amp;quot;Stephen Gerlach&amp;quot;           &amp;quot;Jolette Lueilwitz&amp;quot;
#&amp;gt; [33] &amp;quot;Mrs Torie Green d.d.s.&amp;quot;    &amp;quot;Mona Denesik&amp;quot;
#&amp;gt; [35] &amp;quot;Mitchell Auer&amp;quot;             &amp;quot;Miss. Fae Price m.d.&amp;quot;
#&amp;gt; [37] &amp;quot;Todd Lehner&amp;quot;               &amp;quot;Elva Lesch&amp;quot;
#&amp;gt; [39] &amp;quot;Miss. Gustie Rempel DVM&amp;quot;   &amp;quot;Lexie Parisian-Stark&amp;quot;
#&amp;gt; [41] &amp;quot;Beaulah Cremin-Rice&amp;quot;       &amp;quot;Parrish Schinner&amp;quot;
#&amp;gt; [43] &amp;quot;Latrell Beier&amp;quot;             &amp;quot;Garry Wolff Sr&amp;quot;
#&amp;gt; [45] &amp;quot;Bernhard Vandervort&amp;quot;       &amp;quot;Stevie Johnston&amp;quot;
#&amp;gt; [47] &amp;quot;Dawson Gaylord&amp;quot;            &amp;quot;Ivie Labadie&amp;quot;
#&amp;gt; [49] &amp;quot;Ronal Parker&amp;quot;              &amp;quot;Mr Willy O&#39;Conner Sr.&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Right now only suffixes and prefixes for names in &lt;code&gt;en_US&lt;/code&gt; locale
are supported. Notice above some variation in prefixes and suffixes.&lt;/p&gt;

&lt;h3 id=&#34;to-do&#34;&gt;TO DO&lt;/h3&gt;

&lt;p&gt;We have lots ot do still. Some of those things include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Locales: For existing data variables in the package, we need to fill in
locales for which Python&amp;rsquo;s &lt;code&gt;faker&lt;/code&gt; has the data, but we need to port it over
still.&lt;/li&gt;
&lt;li&gt;Data variables: there&amp;rsquo;s more we can port over from Python&amp;rsquo;s &lt;code&gt;faker&lt;/code&gt;.
In addition, we may find inspiration from faker libraries in other
programming languages.&lt;/li&gt;
&lt;li&gt;Messy data: we want to make messy data support more available throughout
the package. Watch &lt;a href=&#34;https://github.com/ropensci/charlatan/issues/41&#34;&gt;issue #41&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If you have ideas for potential data variables, &lt;a href=&#34;https://github.com/ropensci/charlatan/issues/11&#34;&gt;issue #11&lt;/a&gt; is a good place for those.
Or open a new issue, either way.&lt;/li&gt;
&lt;li&gt;One reviewer brought up whether data should be within bounds of reality (
see &lt;a href=&#34;https://github.com/ropensci/charlatan/issues/40&#34;&gt;issue #40&lt;/a&gt;). The first
question for me is should we do this - if the answer is yes or at least sometimes,
then we can explore how. It&amp;rsquo;s not yet clear if it&amp;rsquo;s the right thing to do.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Growth of open data in biology</title>
      <link>https://ropensci.org/blog/2014/11/10/open-data-growth/</link>
      <pubDate>Mon, 10 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/11/10/open-data-growth/</guid>
      <description>
        
        

&lt;h2 id=&#34;why-open-data-growth&#34;&gt;Why open data growth&lt;/h2&gt;

&lt;p&gt;At rOpenSci we try to make it easier for people to use open data and contribute open data to the community. The question often arises: How much open data do we have? Another angle on this topic is: How much is open data growing?&lt;/p&gt;

&lt;p&gt;We provide access to dozens of data respositories through our various packages. We asked many of them to share numbers on the amount of data they have, and if possible, growth of their data holdings through time. Many of our partners came through with some data. Note that the below is biased towards those data sources we were able to get data from, and those that we were able to get growth through time data. In addition, note that much of the data we use below was from fall of 2013 (last year) - so the below is based on somewhat old data, but surely the trends are likely still the same now.&lt;/p&gt;

&lt;p&gt;We collated data from the different sources, and made some pretty graphs using the data. Here&amp;rsquo;s what we learned (see last section on how to reproduce this analysis):&lt;/p&gt;

&lt;h2 id=&#34;size-of-open-data&#34;&gt;Size of open data&lt;/h2&gt;

&lt;p&gt;Of the data sources we have data for, how much data is there? The expression of size of data is somewhat different for different sources, so the below is a bit heterogeous, but nonetheless coveys that there is a lot of open data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rbind(df1, df2) %&amp;gt;%
  mutate(
    type = c(&#39;Phenology records&#39;,&#39;Phylogenetic trees&#39;,&#39;Taxonomic names&#39;,&#39;Checklist records&#39;,&#39;Observations&#39;,&#39;Taxonomic names&#39;,&#39;Source databases&#39;,&#39;Titles&#39;,&#39;Items&#39;,&#39;Names&#39;,&#39;Pages&#39;,&#39;Species occurrence records&#39;,&#39;Data publishers&#39;,&#39;Taxonomic names&#39;,&#39;Data records&#39;,&#39;Datasets&#39;,&#39;Articles&#39;,&#39;Data packages&#39;,&#39;SNPs&#39;,&#39;Users&#39;,&#39;Genotypes&#39;,&#39;Data records&#39;),
    source = c(&#39;NPN&#39;,&#39;Treebase&#39;,&#39;ITIS&#39;,&#39;eBird&#39;,&#39;eBird&#39;,&#39;COL&#39;,&#39;COL&#39;,&#39;BHL&#39;,&#39;BHL&#39;,&#39;BHL&#39;,&#39;BHL&#39;,&#39;GBIF&#39;,&#39;GBIF&#39;,&#39;Neotoma&#39;,&#39;Neotoma&#39;,&#39;Neotoma&#39;,&#39;PLOS&#39;,&#39;Dryad&#39;,&#39;OpenSNP&#39;,&#39;OpenSNP&#39;,&#39;OpenSNP&#39;,&#39;DataCite&#39;)
  ) %&amp;gt;%
  arrange(type, desc(value)) %&amp;gt;%
  kable(format = &amp;quot;html&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;table class=&#34;table table-bordered table-striped&#34;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; source &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; value &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; type &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; PLOS &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 137358 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Articles &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; eBird &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 205970 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Checklist records &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Dryad &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4186 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Data packages &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; GBIF &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 578 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Data publishers &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; DataCite &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3618096 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Data records &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Neotoma &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2202656 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Data records &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Neotoma &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 11617 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Datasets &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; OpenSNP &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 589 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Genotypes &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; BHL &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 139561 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Items &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; BHL &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 155891133 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Names &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; eBird &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2923886 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Observations &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; BHL &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 43968949 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Pages &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; NPN &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2537095 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Phenology records &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Treebase &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1515 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Phylogenetic trees &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; OpenSNP &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2140939 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; SNPs &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; COL &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 132 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Source databases &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; GBIF &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 420222471 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Species occurrence records &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; COL &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1352112 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Taxonomic names &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; ITIS &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 624282 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Taxonomic names &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Neotoma &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 20152 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Taxonomic names &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; BHL &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 77258 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Titles &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; OpenSNP &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1230 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; Users &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;growth-in-open-data&#34;&gt;Growth in open data&lt;/h2&gt;

&lt;p&gt;First, we have to convert all the date-like fields to proper date classes. The work is not shown - look at &lt;a href=&#34;https://github.com/ropensci/dbgrowth&#34;&gt;the code&lt;/a&gt; if you want the details.&lt;/p&gt;

&lt;h2 id=&#34;run-down-of-each-data-source&#34;&gt;Run down of each data source&lt;/h2&gt;

&lt;h3 id=&#34;dryad&#34;&gt;Dryad&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;http://datadryad.org/&#34;&gt;http://datadryad.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;rdryad&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dryad is a repository of datasets associated with published papers. We do have an R package on CRAN (&lt;code&gt;rdryad&lt;/code&gt;), but it is waiting on an update for the new API services being built by the Dryad folks. We did recently add in access to their Solr endpoint - &lt;a href=&#34;https://github.com/ropensci/rdryad/blob/master/R/dryad_solr.r#L8-L41&#34;&gt;check it out&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dryad %&amp;gt;% sort_count %&amp;gt;% gp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-7-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-7&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;opensnp&#34;&gt;OpenSNP&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;https://opensnp.org/&#34;&gt;https://opensnp.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;rsnps&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;OpenSNP is a collator of SNP datasets that individuals donate to the site/database. They&amp;rsquo;re an awesome group, and they even won the PLOS/Mendeley code contest a few years back.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;opensnp_genotypes &amp;lt;- opensnp_genotypes %&amp;gt;% mutate(type = &amp;quot;genotyptes&amp;quot;) %&amp;gt;% sort_count
opensnp_phenotypes &amp;lt;- opensnp_phenotypes %&amp;gt;% mutate(type = &amp;quot;phenotyptes&amp;quot;) %&amp;gt;% sort_count
opensnp_snps &amp;lt;- opensnp_snps %&amp;gt;% mutate(type = &amp;quot;snps&amp;quot;) %&amp;gt;% sort_count
opensnp_users &amp;lt;- opensnp_users %&amp;gt;% mutate(type = &amp;quot;users&amp;quot;) %&amp;gt;% sort_count
os_all &amp;lt;- rbind(opensnp_genotypes, opensnp_phenotypes, opensnp_snps, opensnp_users)
os_all %&amp;gt;%
  ggplot(aes(date, log10(count), color=type)) +
    geom_line() +
    theme_grey(base_size = 18) +
    theme(legend.position = &amp;quot;top&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-8-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-8&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;datacite&#34;&gt;Datacite&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;https://www.datacite.org/&#34;&gt;https://www.datacite.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;rdatacite&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DataCite mints DOIs for datasets, and holds metadata for those datasets provided by data publishers. They have&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dcite %&amp;gt;% sort_count %&amp;gt;% gp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-9-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-9&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;us-national-phenology-network-usnpn-or-npn&#34;&gt;US National Phenology Network (USNPN or NPN)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;https://www.usanpn.org/&#34;&gt;https://www.usanpn.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;rnpn&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The US National Phenology Network is a project under the USGS. They collect phenology observations across both plants and animals.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;npn %&amp;gt;% arrange(date) %&amp;gt;% mutate(count = cumsum(Number_Records)) %&amp;gt;% gp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-10-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-10&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;treebase&#34;&gt;TreeBASE&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;http://treebase.org/&#34;&gt;http://treebase.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;treebase&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;TreeBASE is a database of phylogenetic trees, had a total of 1515 new trees added in 2013, and has been growing at a good pace. Note that these aren&amp;rsquo;t numbers of total phylogenetic trees, but &lt;em&gt;new trees added each year&lt;/em&gt; - we couldn&amp;rsquo;t get our hands on total number of trees by year. The current number of total trees as of 2015-03-10 is 12,817.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;treebase %&amp;gt;% arrange(date) %&amp;gt;% rename(count = New.Trees.Added) %&amp;gt;% gp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-11-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-11&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;integrated-taxonomic-information-service-itis&#34;&gt;Integrated Taxonomic Information Service (ITIS)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;http://www.itis.gov/&#34;&gt;http://www.itis.gov/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;taxize&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The ITIS database is under the USGS, and holds taxonomic names for mostly North American species. This dataset is interesting, because data goes back to 1977, when they had 16000 names. As of Aug 2013 they had 624282 names.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;itis %&amp;gt;% arrange(date) %&amp;gt;% rename(count = total_names) %&amp;gt;% gp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-12-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-12&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;ebird&#34;&gt;eBird&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;http://www.catalogueoflife.org/&#34;&gt;http://www.catalogueoflife.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;taxize&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;eBird is a database of bird occurence records. They don&amp;rsquo;t give access to all the data they have, but some recent data. Data growth goes up and down through time because we don&amp;rsquo;t have access to all data on each data request, but the overall trend is increasing.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ebird_observations %&amp;gt;% arrange(date) %&amp;gt;% mutate(count = cumsum(COUNT.OBS_ID.)) %&amp;gt;% gp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-13-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-13&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;catalogue-of-life-col&#34;&gt;Catalogue of Life (COL)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;https://www.datacite.org/&#34;&gt;https://www.datacite.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;rdatacite&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;COL is a database of taxonomic names, similar to ITIS, uBio, or Tropicos. The number of species (1352112) has continually increased (the slight level off is because we got data in Oct last year before the year was over), but number of data sources (1352112) was still growing as of 2013.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Number of species&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;col %&amp;gt;% arrange(date) %&amp;gt;% rename(count = species) %&amp;gt;% gp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-14-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-14&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Number of data sources&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;col %&amp;gt;% arrange(date) %&amp;gt;% rename(count = source_databases) %&amp;gt;% gp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-15-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-15&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;public-library-of-science-plos&#34;&gt;Public Library of Science (PLOS)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;http://www.plos.org/&#34;&gt;http://www.plos.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;rplos&lt;/code&gt;, &lt;code&gt;fulltext&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PLOS has had tremendous growth, with a very steep hockey stick growth curve. This year (2014) is left out because the year is not over yet.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plos_years %&amp;gt;%
  arrange(date) %&amp;gt;%
  filter(date &amp;lt; as.Date(&amp;quot;2014-01-01&amp;quot;)) %&amp;gt;%
  mutate(count = cumsum(articles)) %&amp;gt;%
  gp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-16-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-16&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;biodiversity-heritage-library-bhl&#34;&gt;Biodiversity Heritage Library (BHL)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;http://www.biodiversitylibrary.org/&#34;&gt;http://www.biodiversitylibrary.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;rbhl&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;BHL has grown tremendously, with 155891133 names, 43650663 pages, 139003 items, and 77169 titles.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;bhl_titles &amp;lt;- bhl_titles %&amp;gt;% mutate(type = &amp;quot;titles&amp;quot;) %&amp;gt;% arrange(date) %&amp;gt;% mutate(count = cumsum(Titles))
bhl_items &amp;lt;- bhl_items %&amp;gt;% mutate(type = &amp;quot;items&amp;quot;) %&amp;gt;% arrange(date) %&amp;gt;%  mutate(count = cumsum(Items))
bhl_pages &amp;lt;- bhl_pages %&amp;gt;% mutate(type = &amp;quot;pages&amp;quot;) %&amp;gt;% arrange(date) %&amp;gt;%  mutate(count = cumsum(Pages))
bhl_names &amp;lt;- bhl_names %&amp;gt;% mutate(type = &amp;quot;names&amp;quot;) %&amp;gt;% arrange(date) %&amp;gt;%  mutate(count = cumsum(Names))
bhl_all &amp;lt;- rbind(bhl_titles[,-c(1:4)], bhl_items[,-c(1:4)], bhl_pages[,-c(1:4)], bhl_names[,-c(1:4)])
bhl_all %&amp;gt;%
  ggplot(aes(date, count)) +
    geom_line(size=2.1) +
    theme_grey(base_size = 18) +
    facet_wrap(~ type, scales = &amp;quot;free&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-17-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-17&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;global-biodiversity-information-facility-gbif&#34;&gt;Global Biodiversity Information Facility (GBIF)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;http://www.gbif.org/&#34;&gt;http://www.gbif.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;rgbif&lt;/code&gt;, &lt;code&gt;spocc&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GBIF is the largest warehouse of biodiversity occurrence records, pulling in data from 578, and 420 million occurrence records as of Oct. 2013. Growth through time has been dramatic.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Number of records&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gbif_data %&amp;gt;%
  arrange(date) %&amp;gt;%
  rename(count = V2) %&amp;gt;%
  gp + labs(y=&amp;quot;Millions of biodiversity records in GBIF&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-18-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-18&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Number of data publishers&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gbif_publishers %&amp;gt;%
  arrange(date) %&amp;gt;%
  rename(count = V2) %&amp;gt;%
  gp + labs(y=&amp;quot;Number of GBIF data publishers&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-19-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-19&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;neotoma&#34;&gt;Neotoma&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Website: &lt;a href=&#34;http://www.neotomadb.org/&#34;&gt;http://www.neotomadb.org/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R package: &lt;code&gt;neotoma&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Neotoma database holds paleoecology records of various kinds, including pollen and fossil records. The R package &lt;code&gt;neotoma&lt;/code&gt; allows access to data from Neotoma.  Data and datasets have grown rather dramatically, while number of taxa has flattened off recently.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rbind(neotoma_data %&amp;gt;% mutate(type = &amp;quot;data&amp;quot;) %&amp;gt;% arrange(date),
      neotoma_datasets %&amp;gt;% mutate(type = &amp;quot;datasets&amp;quot;) %&amp;gt;% arrange(date),
      neotoma_taxa %&amp;gt;% mutate(type = &amp;quot;taxa&amp;quot;) %&amp;gt;% arrange(date)) %&amp;gt;%
  rename(count = RunningCount) %&amp;gt;%
  gp + facet_grid(type ~ ., scales=&amp;quot;free&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-11-10-open-data-growth/unnamed-chunk-20-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-20&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;so-what&#34;&gt;So what?&lt;/h2&gt;

&lt;p&gt;Okay, so a lot of data isn&amp;rsquo;t that meaningful in itself. But, this is open data that can be used to do science, which means there is an increasingly vast amount of open data as the basis for new research, to supplement field based research, etc. The killer feature of all this open data is that it&amp;rsquo;s all available programatically through R packages produced in the rOpenSci community, meaning you can easily and quickly do reproducible science with this data.&lt;/p&gt;

&lt;h2 id=&#34;reproduce-this-analysis&#34;&gt;Reproduce this analysis&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Option 1: If you are comfortable with git, simply clone the &lt;a href=&#34;https://github.com/ropensci/dbgrowth&#34;&gt;dbgrowth repository&lt;/a&gt; to your machine, uncompress the compressed file, &lt;code&gt;cd&lt;/code&gt; to the directory, and run &lt;code&gt;R&lt;/code&gt;. Running R should enter &lt;em&gt;packrat mode&lt;/em&gt;, which will install packages from within the directory, after which point you can reproduce what we have done above.&lt;/li&gt;
&lt;li&gt;Option 2: Install the &lt;code&gt;packrat&lt;/code&gt; R package if you don&amp;rsquo;t have it already. Download &lt;a href=&#34;https://www.dropbox.com/s/226onvf8zw06r0f/dbgrowth-2014-11-10.tar.gz?dl=0&#34;&gt;this compressed file&lt;/a&gt; (a &lt;em&gt;packrat bundle&lt;/em&gt;), then in R, run &lt;code&gt;packrat::unbundle(&amp;quot;&amp;lt;path to tar.gz&amp;gt;&amp;quot;, &amp;quot;&amp;lt;path to put the contents&amp;gt;&amp;quot;)&lt;/code&gt;, which will uncompress the file, and install packages, and you&amp;rsquo;re ready to go.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once you have the files, you should be able to run &lt;code&gt;knitr::knit(&amp;quot;dbgrowth.Rmd&amp;quot;)&lt;/code&gt; to reproduce this post.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Make your ggplots shareable, collaborative, and with D3</title>
      <link>https://ropensci.org/blog/2014/04/17/plotly/</link>
      <pubDate>Thu, 17 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/04/17/plotly/</guid>
      <description>
        
        

&lt;p&gt;&lt;em&gt;Editor&amp;rsquo;s note: This is a guest post by Matt Sundquist from &lt;a href=&#34;https://plot.ly/&#34;&gt;Plot.ly&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You can access the source code for this post at &lt;a href=&#34;https://gist.github.com/sckott/10991885&#34;&gt;https://gist.github.com/sckott/10991885&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ropensci/plotly&#34;&gt;Ggplotly&lt;/a&gt; and &lt;a href=&#34;https://plot.ly/api/r&#34;&gt;Plotly&amp;rsquo;s R API&lt;/a&gt; let you make ggplot2 plots, add &lt;code&gt;py$ggplotly()&lt;/code&gt;, and make your plots interactive, online, and drawn with D3. Let&amp;rsquo;s make some.&lt;/p&gt;

&lt;h2 id=&#34;1-getting-started-and-examples&#34;&gt;1. Getting Started and Examples&lt;/h2&gt;

&lt;p&gt;Here is Fisher&amp;rsquo;s iris data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;ggplot2&amp;quot;)
ggiris &amp;lt;- qplot(Petal.Width, Sepal.Length, data = iris, color = Species)
print(ggiris)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-04-17-plotly/unnamed-chunk-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s make it in Plotly. Install:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;devtools&amp;quot;)
library(&amp;quot;devtools&amp;quot;)
install_github(&amp;quot;plotly&amp;quot;, &amp;quot;ropensci&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Load.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;plotly&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: RCurl
## Loading required package: bitops
## Loading required package: RJSONIO
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sign up &lt;a href=&#34;https://plot.ly&#34;&gt;online&lt;/a&gt;, use our public keys below, or sign up like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;signup(&amp;quot;new_username&amp;quot;, &amp;quot;your_email@domain.com&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That should have responded with your new key. Use that to create a plotly interface object, or use ours:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;py &amp;lt;- plotly(&amp;quot;RgraphingAPI&amp;quot;, &amp;quot;ektgzomjbx&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It just works.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;py$ggplotly(ggiris)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/554&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;The call opens a browser tab. Or in an &lt;code&gt;.Rmd&lt;/code&gt; document, the plot is embedded if you specify the &lt;code&gt;plotly=TRUE&lt;/code&gt; chunk option (see &lt;a href=&#34;https://gist.github.com/sckott/10991885&#34;&gt;source&lt;/a&gt;). If you&amp;rsquo;re running this from the source, it makes all the graphs at once in your browser. Reaction my first time: here be dragons.&lt;/p&gt;

&lt;p&gt;If you click the &lt;em&gt;data and graph&lt;/em&gt; link in the embed, it takes you to Plotly&amp;rsquo;s GUI, where you can edit the graph, see the data, and share your plot with collaborators.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-2-maps&#34;&gt;1.2 Maps&lt;/h3&gt;

&lt;p&gt;Next: Maps!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(canada.cities, package=&amp;quot;maps&amp;quot;)
viz &amp;lt;- ggplot(canada.cities, aes(long, lat)) +
  borders(regions=&amp;quot;canada&amp;quot;, name=&amp;quot;borders&amp;quot;) +
  coord_equal() +
  geom_point(aes(text=name, size=pop), colour=&amp;quot;red&amp;quot;, alpha=1/2, name=&amp;quot;cities&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Call Plotly.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;py$ggplotly(viz)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/555&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-3-scatter&#34;&gt;1.3 Scatter&lt;/h3&gt;

&lt;p&gt;Want to make a scatter and add a &lt;a href=&#34;http://docs.ggplot2.org/current/geom_smooth.html&#34;&gt;smoothed conditional mean&lt;/a&gt;? Here&amp;rsquo;s how to do it in Plotly. For the rest of the plots, we&amp;rsquo;ll just print the Plotly version to save space. You can hover on text to get data, or click and drag across a section to zoom in.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model &amp;lt;- lm(mpg ~ wt + factor(cyl), data=mtcars)
grid &amp;lt;- with(mtcars, expand.grid(
  wt = seq(min(wt), max(wt), length = 20),
  cyl = levels(factor(cyl))
))

grid$mpg &amp;lt;- stats::predict(model, newdata=grid)

viz2 &amp;lt;- qplot(wt, mpg, data=mtcars, colour=factor(cyl)) + geom_line(data=grid)
py$ggplotly(viz2)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/556&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-4-lines&#34;&gt;1.4 Lines&lt;/h3&gt;

&lt;p&gt;Or, take &lt;code&gt;ggplotly&lt;/code&gt; for a spin with the orange dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;orange &amp;lt;- qplot(age, circumference, data = Orange, colour = Tree, geom = &amp;quot;line&amp;quot;)
py$ggplotly(orange)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/557&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-5-alpha-blend&#34;&gt;1.5 Alpha blend&lt;/h3&gt;

&lt;p&gt;Or, make plots &lt;a href=&#34;http://mandymejia.wordpress.com/2013/11/13/10-reasons-to-switch-to-ggplot-7/&#34;&gt;beautiful&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;prettyPlot &amp;lt;- ggplot(data=diamonds, aes(x=carat, y=price, colour=clarity))
prettyPlot &amp;lt;- prettyPlot + geom_point(alpha = 1/10)
py$ggplotly(prettyPlot)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/558&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-6-functions&#34;&gt;1.6 Functions&lt;/h3&gt;

&lt;p&gt;Want to &lt;a href=&#34;http://stackoverflow.com/questions/1853703/plotting-functions-in-r&#34;&gt;draw functions&lt;/a&gt; with a &lt;code&gt;curve&lt;/code&gt;?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;eq &amp;lt;- function(x) {x*x}
tmp &amp;lt;- data.frame(x=1:50, y=eq(1:50))

# Make plot object
p &amp;lt;- qplot(x, y, data=tmp, xlab=&amp;quot;X-axis&amp;quot;, ylab=&amp;quot;Y-axis&amp;quot;)
c &amp;lt;- stat_function(fun=eq)

py$ggplotly(p + c)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/559&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;2-a-github-for-data-and-graphs&#34;&gt;2. A GitHub for data and graphs&lt;/h2&gt;

&lt;p&gt;Like we might work together on code on GitHub or a project in a Google Doc, we can edit graphs and data together on Plotly. Here&amp;rsquo;s how it works:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Your URL is shareable.&lt;/li&gt;
&lt;li&gt;Public use is free.&lt;/li&gt;
&lt;li&gt;You can set &lt;a href=&#34;http://plot.ly/api/r/docs/privacy&#34;&gt;the privacy&lt;/a&gt; of your graph.&lt;/li&gt;
&lt;li&gt;You can edit and add to plots from our GUI or with R or &lt;a href=&#34;https://plot.ly/api&#34;&gt;APIs&lt;/a&gt; for Python, MATLA, Julia, Perl, Arduino, Raspberry Pi, and REST.&lt;/li&gt;
&lt;li&gt;You get a profile of graphs, like &lt;a href=&#34;https://plot.ly/~RhettAllain/&#34;&gt;Rhett Allain&lt;/a&gt; from Wired Science.&lt;/li&gt;
&lt;li&gt;You can &lt;a href=&#34;http://plot.ly/api/r/docs/iframes&#34;&gt;embed interactive graphs in iframes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-1-inspiration-and-team&#34;&gt;2.1 Inspiration and team&lt;/h3&gt;

&lt;p&gt;Plotly&amp;rsquo;s API is part of &lt;code&gt;rOpenSci&lt;/code&gt; and being developed by the brilliant &lt;a href=&#34;http://cbio.ensmp.fr/~thocking/&#34;&gt;Toby Hocking&lt;/a&gt; and Plotly&amp;rsquo;s own &lt;a href=&#34;https://github.com/chriddyp&#34;&gt;Chris Parmer&lt;/a&gt;. You can find it on &lt;a href=&#34;https://github.com/ropensci/plotly&#34;&gt;GitHub&lt;/a&gt;. Your thoughts, issues, and pull requests are welcome. Right now, you can make scatter and line plots; let us know what you&amp;rsquo;d like to see next.&lt;/p&gt;

&lt;p&gt;The project was inspired by &lt;a href=&#34;https://github.com/hadley/&#34;&gt;Hadley Wickham&lt;/a&gt; and the elegance and precision of &lt;a href=&#34;http://ggplot2.org/&#34;&gt;&lt;code&gt;ggplot2&lt;/code&gt;&lt;/a&gt;. Thanks to &lt;a href=&#34;http://scottchamberlain.info/&#34;&gt;Scott Chamberlain&lt;/a&gt;, &lt;a href=&#34;https://github.com/jcheng5&#34;&gt;Joe Cheng&lt;/a&gt;, and &lt;a href=&#34;https://twitter.com/efvmw&#34;&gt;Elizabeth Morrison-Wells&lt;/a&gt; for their help.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;3-ggthemes-and-plotly&#34;&gt;3. ggthemes and Plotly&lt;/h2&gt;

&lt;p&gt;Using &lt;a href=&#34;https://github.com/jrnold/ggthemes&#34;&gt;&lt;code&gt;ggthemes&lt;/code&gt;&lt;/a&gt; opens up another set of custom graph filters for styling your graphs. To get started, you&amp;rsquo;ll want to install &lt;code&gt;ggthemes&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;devtools&amp;quot;)
install_github(&amp;quot;ggthemes&amp;quot;, &amp;quot;jrnold&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and load your data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;ggplot2&amp;quot;)
library(&amp;quot;ggthemes&amp;quot;)
dsamp &amp;lt;- diamonds[sample(nrow(diamonds), 1000), ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;
Inverse gray.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gray &amp;lt;- (qplot(carat, price, data = dsamp, colour = cut) +
           theme_igray())
py$ggplotly(gray)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/560&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;
The Tableau scale.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tableau &amp;lt;- (qplot(carat, price, data = dsamp, colour = cut) +
              theme_igray() +
              scale_colour_tableau())
py$ggplotly(tableau)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/561&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;
&lt;a href=&#34;http://www.perceptualedge.com/articles/visual_business_intelligence/rules_for_using_color.pdf&#34;&gt;Stephen Few&amp;rsquo;s&lt;/a&gt; scale.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;few &amp;lt;- (qplot(carat, price, data = dsamp, colour = cut) +
          theme_few() +
          scale_colour_few())
py$ggplotly(few)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/562&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

      </description>
    </item>
    
    <item>
      <title>dvn - Sharing Reproducible Research from R</title>
      <link>https://ropensci.org/blog/2014/02/20/dvn-dataverse-network/</link>
      <pubDate>Thu, 20 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/02/20/dvn-dataverse-network/</guid>
      <description>
        
        

&lt;p&gt;Reproducible research involves the careful, annotated preservation of data, analysis code, and associated files, such that statistical procedures, output, and published results can be directly and fully replicated. As the push for reproducible research has grown, the R community has responded with an increasingly large set of tools for engaging in reproducible research practices (see, for example, the &lt;a href=&#34;http://cran.r-project.org/web/views/ReproducibleResearch.html&#34;&gt;ReproducibleResearch Task View&lt;/a&gt; on CRAN). Most of these tools focus on improving one&amp;rsquo;s own workflow through closer integration of data analysis and report generation. But reproducible research also requires the persistent - and perhaps indefinite - storage of research files so that they can be used to recreate or modify future analyses and reports.&lt;/p&gt;

&lt;p&gt;It is therefore critical that R include functionality for the persistent storage of reproducible research files. And I&amp;rsquo;m pleased to announce here that the &lt;strong&gt;dvn&lt;/strong&gt; package (&lt;a href=&#34;http://cran.r-project.org/web/packages/dvn/index.html&#34;&gt;CRAN&lt;/a&gt;, &lt;a href=&#34;http://ropensci.org/dvn.html&#34;&gt;GitHub&lt;/a&gt;) has now been integrated into the rOpenSci project. &lt;strong&gt;dvn&lt;/strong&gt; provides simple, programmatic access to &lt;a href=&#34;http://thedata.org/&#34;&gt;The Dataverse Network Project&lt;/a&gt;, an open-source data archive project created by Harvard University&amp;rsquo;s &lt;a href=&#34;http://www.iq.harvard.edu/&#34;&gt;Institute for Quantitative Social Science&lt;/a&gt;. Full details about &lt;strong&gt;dvn&lt;/strong&gt; are forthcoming in &lt;a href=&#34;http://journal.r-project.org/&#34;&gt;The R Journal&lt;/a&gt;, and this post provides a basic overview of the package&amp;rsquo;s core functionality.&lt;/p&gt;

&lt;p&gt;Note that rOpenSci has already created the rFigShare package (&lt;a href=&#34;http://cran.r-project.org/web/packages/rfigshare/index.html&#34;&gt;CRAN&lt;/a&gt;, &lt;a href=&#34;http://ropensci.org/rfigshare.html&#34;&gt;GitHub&lt;/a&gt;), which allows users to upload files to &lt;a href=&#34;http://figshare.com/&#34;&gt;fishare&lt;/a&gt;. Together, these packages give R users an array of tools to enhance the reproducible research workflow and extend it publicly and permanently for the benefit of future scientists.&lt;/p&gt;

&lt;h2 id=&#34;installing-the-package&#34;&gt;Installing the package&lt;/h2&gt;

&lt;p&gt;A stable version of the package (0.3.3) is now available on CRAN.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;dvn&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or you can install the latest development version from GitHub:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;devtools&amp;quot;)
install_github(&amp;quot;ropensci/dvn&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;creating-a-dataverse-and-archiving-files&#34;&gt;Creating a dataverse and archiving files&lt;/h2&gt;

&lt;p&gt;Creating a Dataverse Network account is simple. Just visit a Dataverse Network, such as &lt;a href=&#34;http://thedata.harvard.edu/dvn/&#34;&gt;The Harvard Dataverse Network&lt;/a&gt;, click &amp;ldquo;Create Account,&amp;rdquo; and open a personal dataverse. From there, one can easily create studies, populate them with metadata and files, and release them to the public.&lt;/p&gt;

&lt;p&gt;To get started, simply load &lt;strong&gt;dvn&lt;/strong&gt;, pick a Dataverse Network (the one you created an account through), and load your username and password.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;dvn&amp;quot;)
options(dvn = &#39;https://thedata.harvard.edu/dvn/&#39;)
options(dvn.user = &amp;quot;username&amp;quot;)
options(dvn.pwd = &amp;quot;password&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Creating a study requires supplying basic metadata that will allow users to find the study. At a minimum, this includes the title for the study, but many other fields are allowed (see &lt;code&gt;? dvBuildMetadata&lt;/code&gt;). The metadata need to be written in Dublin Core XML, so a helper function &lt;code&gt;dvBuildMetadata&lt;/code&gt; can be used to easily write metadata fields to an appropriate format:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m &amp;lt;- dvBuildMetadata(title = &amp;quot;My Study&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This metadata can then be used to create a new study within a named dataverse. When you initially create an account, you only have a personal dataverse but you can also create additional dataverses (through the web interface) for specific projects or institutions. Thus &lt;code&gt;dvCreateStudy&lt;/code&gt; requires you to supply the name of the dataverse where you want to create a study:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;s &amp;lt;- dvCreateStudy(&amp;quot;mydataverse&amp;quot;, m)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once a study is created, you simply need to add files, such as code, data, etc. using &lt;code&gt;dvAddFile&lt;/code&gt;. This can be done in a number of ways, including uploading all files in a .zip directory, uploading a vector of named files, or even uploading a dataframe that is currently open in R. An optional &lt;code&gt;category&lt;/code&gt; argument can be used to organize the uploaded files into categories.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# add files and release study using `objectid`
dvAddFile(s, &amp;quot;mydata.zip&amp;quot;, category=&amp;quot;Data&amp;quot;)

# or add multiple files:
dvAddFile(s, c(&amp;quot;analysis1.R&amp;quot;, &amp;quot;analysis2.R&amp;quot;), category=&amp;quot;Code&amp;quot;)

# or add R dataframes as files:
mydf &amp;lt;- data.frame(x = 1:10, y = 11:20)
dvAddFile(s, dataframe = &amp;quot;mydf&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With files uploaded, making the study publicly available is as easy as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dvReleaseStudy(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before releasing a study, it is possible to add (&lt;code&gt;dvAddFile&lt;/code&gt;) or delete files (&lt;code&gt;dvDeleteFile&lt;/code&gt;) or change the metadata associated with the file using &lt;code&gt;dvEditStudy&lt;/code&gt;. You can also delete the entire study using &lt;code&gt;dvDeleteStudy&lt;/code&gt;. Once released, the study is version-controlled. Any changes made after a release put the study in &amp;ldquo;DRAFT&amp;rdquo; mode and the study needs to be released again for those changes to be publicly visible. A released study cannot be deleted but public access to its contents can be revoked using &lt;code&gt;dvDeleteStudy&lt;/code&gt; (its DOI will point to a page noting the study was deaccessioned).&lt;/p&gt;

&lt;p&gt;At any point in the process, &lt;code&gt;dvStudyStatement&lt;/code&gt; can be used to retrieve a quick overview of the study&amp;rsquo;s status, metadata, and contents:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dvStudyStatement(&#39;hdl:1902.1/17864&#39;)
Study author:  James Druckman (Northwestern University); Jordan Fein (Northwestern University); Thomas Leeper (Northwestern University)
Study title:   Replication data for: A Source of Bias in Public Opinion Stability
ObjectId:      hdl:1902.1/17864
Study URI:     https://thedata.harvard.edu/dvn/api/data-deposit/v1/swordv2/edit/study/hdl:1902.1/17864
Last updated:  2013-07-27T10:54:30.200Z
Status:        RELEASED
Locked?        false
Files:
  src
1 https://thedata.harvard.edu/dvn/api/data-deposit/v1/swordv2/edit-media/file/2340116/Codebook2011-05-04.doc
2 https://thedata.harvard.edu/dvn/api/data-deposit/v1/swordv2/edit-media/file/2309028/Data.tab
3 https://thedata.harvard.edu/dvn/api/data-deposit/v1/swordv2/edit-media/file/2341890/Articles.doc
4 https://thedata.harvard.edu/dvn/api/data-deposit/v1/swordv2/edit-media/file/2341891/Questionnaire.doc
  type                      updated                  fileId
1 application/msword        2014-02-19T10:18:53.486Z 2340116
2 text/tab-separated-values 2014-02-19T10:18:53.487Z 2309028
3 application/msword        2014-02-19T10:18:53.488Z 2341890
4 application/msword        2014-02-19T10:18:53.489Z 2341891
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And &lt;code&gt;dvUserStudies&lt;/code&gt; can retrieve a listing of all studies in one&amp;rsquo;s dataverse:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dvUserStudies(&#39;leeper&#39;)
DV Title:      Thomas J. Leeper
DV name:       leeper
Released?      true
Generated by:  http://www.swordapp.org/ 2.0
Studies:
  title
1 Possible R ingest bug
2 Replication data for: A Source of Bias in Public Opinion Stability
3 Replication data for: The Informational Basis for Mass Polarization
4 Replication data for: Self-Interest and Attention to News among Issue Publics
5 Replication data for: Learning More from Political Communication Experiments: The Importance of Pretreatment Effects
6 Replication data for: Doing What Others Do:  Norms, Science, and Collective Action on Global Warming
7 Consequences of Selective Exposure for Political Engagement
  objectId
1 hdl:1902.1/LNEOX
2 hdl:1902.1/17864
3 hdl:1902.1/21964
4 hdl:1902.1/17863
5 hdl:1902.1/17218
6 hdl:1902.1/18249
7 hdl:1902.1/17865
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;search-for-archived-studies&#34;&gt;Search for archived studies&lt;/h2&gt;

&lt;p&gt;In addition to creating and managing dataverse studies, &lt;strong&gt;dvn&lt;/strong&gt; also allows users to search a Dataverse Network for existing studies and download metadata. We can search by a number of metadata fields (the allowed fields are retrievable via &lt;code&gt;dvSearchField&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# specify a Dataverse Network
options(dvn = &#39;https://thedata.harvard.edu/dvn/&#39;)

# search by author name
dvSearch(list(authorName = &amp;quot;leeper&amp;quot;))

# search by title using a boolean OR logic
dvSearch(list(title = &amp;quot;Denmark&amp;quot;, title = &amp;quot;Sweden&amp;quot;), boolean = &amp;quot;OR&amp;quot;)

# search all fields
dvSearch(&amp;quot;Tobacco&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A search returns a list of &lt;code&gt;objectId&lt;/code&gt; values, handles or DOIs that provide a global pointer to a particular study. Using an &lt;code&gt;objectId&lt;/code&gt; one can gather detailed study metadata in Data Documentation Initiative format (the default), Dublin Core, or possibly other formats (the list is exanding). Here&amp;rsquo;s an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# return DDI (by default)
dvMetadata(&amp;quot;hdl:1902.1/21964&amp;quot;)

# return Dublic Core
dvMetadata(&amp;quot;hdl:1902.1/21964&amp;quot;, format.type=&amp;quot;oai_dc&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In either case the result is an XML file, as a single character string. The metadata can be extensive, and are therefore better viewed outside of R. But a few wrapper functions allow one to view critical parts of the metadata, such the listing of files stored in a study:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;files &amp;lt;- dvExtractFileIds(dvMetadata(&amp;quot;hdl:1902.1/21964&amp;quot;))
files[, c(&#39;fileName&#39;, &#39;fileId&#39;)]
                          fileName  fileId
1    study2-replication-analysis.r 2341713
2    study1-replication-analysis.r 2341709
3                      coefpaste.r 2341888
4                     expResults.r 2341889
5            Study 2 Codebook.docx 2341712
6 study2-data-final-2012-06-08.csv 2341711
7 study1-data-final-2012-06-08.csv 2341710
8             Study 2 Webpages.zip 2341714
9             Study 1 Webpages.zip 2341715
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generally, files cannot be directly downloaded into R because of Terms of Use restrictions currently placed on studies. In the future this may change, so &lt;strong&gt;dvn&lt;/strong&gt; provides forward-compatible functions &lt;code&gt;dvDownloadInfo&lt;/code&gt; and &lt;code&gt;dvDownload&lt;/code&gt; to check whether files can be downloaded and to perform the download if allowed, respectively.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>

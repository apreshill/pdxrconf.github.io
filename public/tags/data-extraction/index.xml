<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Extraction on rOpenSci - open tools for open science</title>
    <link>https://ropensci.org/tags/data-extraction/</link>
    <description>Recent content in Data Extraction on rOpenSci - open tools for open science</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 05 Dec 2017 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://ropensci.org/tags/data-extraction/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Exploratory Data Analysis of Ancient Texts with rperseus</title>
      <link>https://ropensci.org/blog/2017/12/05/rperseus/</link>
      <pubDate>Tue, 05 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2017/12/05/rperseus/</guid>
      <description>
        
        

&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;When I was in grad school at Emory, I had a favorite desk in the library. The desk wasn’t particularly cozy or private, but what it lacked in comfort it made up for in real estate. My books and I needed room to operate. Students of the ancient world require many tools, and when jumping between commentaries, lexicons, and interlinears, additional clutter is additional “friction”, i.e., lapses in thought due to frustration. Technical solutions to this clutter exist, but the best ones are proprietary and expensive. Furthermore, they are somewhat inflexible, and you may have to shoehorn your thoughts into their framework. More friction.&lt;/p&gt;

&lt;p&gt;Interfacing with &lt;a href=&#34;http://www.perseus.tufts.edu/hopper/&#34;&gt;the Perseus Digital Library&lt;/a&gt; was a popular online alternative. The library includes a catalog of classical texts, a Greek and Latin lexicon, and a word study tool for appearances and references in other literature. If the university library’s reference copies of BDAG&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; and &lt;em&gt;Synopsis Quattuor Evangeliorum&lt;/em&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; were unavailable, Perseus was our next best thing.&lt;/p&gt;

&lt;p&gt;Fast forward several years, and I’ve abandoned my quest to become a biblical scholar. Much to my father’s dismay, I’ve learned writing code is more fun than writing exegesis papers. Still, I enjoy dabbling with dead languages, and it was the desire to wed my two loves, biblical studies and R, that birthed my latest package, &lt;code&gt;rperseus&lt;/code&gt;. The goal of this package is to furnish classicists with texts of the ancient world and a toolkit to unpack them.&lt;/p&gt;

&lt;h3 id=&#34;exploratory-data-analysis-in-biblical-studies&#34;&gt;Exploratory Data Analysis in Biblical Studies&lt;/h3&gt;

&lt;p&gt;Working with the Perseus Digital Library was already a trip down memory lane, but here’s an example of how I would have leveraged &lt;code&gt;rperseus&lt;/code&gt; many years ago.&lt;/p&gt;

&lt;p&gt;My best papers often sprung from the outer margins of my &lt;a href=&#34;https://en.wikipedia.org/wiki/Novum_Testamentum_Graece&#34;&gt;&lt;em&gt;Nestle-Aland Novum Testamentum Graece.&lt;/em&gt;&lt;/a&gt; Here the editors inserted cross references to parallel vocabulary, themes, and even grammatical constructions. Given the intertextuality of biblical literature, the margins are a rich source of questions: Where else does the author use similar vocabulary? How is the source material used differently? Does the literary context affect our interpretation of a particular word? This is exploratory data analysis in biblical studies.&lt;/p&gt;

&lt;p&gt;Unfortunately the excitement of your questions is incommensurate with the tedium of the process&amp;ndash;EDA continues by flipping back and forth between books, dog-earring pages, and avoiding paper cuts. &lt;code&gt;rperseus&lt;/code&gt; aims to streamline this process with two functions: &lt;code&gt;get_perseus_text&lt;/code&gt; and &lt;code&gt;perseus_parallel&lt;/code&gt;. The former returns a data frame containing the text from any work in the Perseus Digital Library, and the latter renders a parallel in &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Suppose I am writing a paper on different expressions of love in Paul’s letters. Naturally, I start in 1 Corinthians 13, the famed “Love Chapter” often heard at weddings and seen on bumper stickers. I finish the chapter and turn to the margins. In the image below, I see references to Colossians 1:4, 1 Thessalonians 1:3, 5:8, Hebrews 10:22-24, and Romans 8:35-39.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/img/blog-images/2017-12-05-rperseus/nantg.png&#34; alt=&#34;&#34; /&gt;
&lt;em&gt;1 Corinithians 13 in Nestle-Aland Novum Testamentum Graece&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Ignoring that some scholars exclude Colossians from the “authentic” letters, let’s see the references alongside each other:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rperseus) #devtools::install_github(“ropensci/rperseus”)
library(tidyverse)

tribble(
  ~label, ~excerpt,
  &amp;quot;Colossians&amp;quot;, &amp;quot;1.4&amp;quot;,
  &amp;quot;1 Thessalonians&amp;quot;, &amp;quot;1.3&amp;quot;,
  &amp;quot;1 Thessalonians&amp;quot;, &amp;quot;5.8&amp;quot;,
  &amp;quot;Romans&amp;quot;, &amp;quot;8.35-8.39&amp;quot;
  ) %&amp;gt;% 
  left_join(perseus_catalog) %&amp;gt;%
  filter(language == &amp;quot;grc&amp;quot;) %&amp;gt;%
  select(urn, excerpt) %&amp;gt;%
  pmap_df(get_perseus_text) %&amp;gt;%
  perseus_parallel(words_per_row = 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/img/blog-images/2017-12-05-rperseus/Parallel1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A brief explanation: First, I specify the labels and excerpts within a tibble. Second, I join the lazily loaded &lt;code&gt;perseus_catalog&lt;/code&gt; onto the data frame. Third, I filter for the Greek&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; and select the columns containing the arguments required for &lt;code&gt;get_perseus_text&lt;/code&gt;. Fourth, I map over each urn and excerpt, returning another data frame. Finally, I pipe the output into &lt;code&gt;perseus_parallel&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The key word shared by each passage is &lt;em&gt;agape&lt;/em&gt; (“love”). Without going into detail, it might be fruitful to consider the references alongside each other, pondering how the semantic range of &lt;em&gt;agape&lt;/em&gt; expands or contracts within the Pauline corpus. Paul had a penchant for appropriating and recasting old ideas&amp;ndash;often in slippery and unexpected ways&amp;ndash;and your Greek lexicon provides a mere approximation. In other words, how can we move from the dictionary definition of &lt;em&gt;agape&lt;/em&gt; towards Paul&amp;rsquo;s unique vision?&lt;/p&gt;

&lt;p&gt;If your Greek is rusty, you can parse each word with &lt;code&gt;parse_excerpt&lt;/code&gt; by locating the text&amp;rsquo;s urn within the &lt;code&gt;perseus_catalog&lt;/code&gt; object.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;parse_excerpt(urn = &amp;quot;urn:cts:greekLit:tlg0031.tlg012.perseus-grc2&amp;quot;, excerpt = &amp;quot;1.4&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;word&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;form&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;verse&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;part_of_speech&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;person&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;number&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;tense&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;mood&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;voice&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gender&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;case&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;degree&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ἀκούω&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ἀκούσαντες&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;verb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;plural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;aorist&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;participle&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;active&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;masculine&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;nominative&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ὁ&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;τὴν&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;article&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;singular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;feminine&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;accusative&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;πίστις&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;πίστιν&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;noun&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;singular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;feminine&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;accusative&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ὑμός&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ὑμῶν&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;pronoun&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;plural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;masculine&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;genative&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If your Greek is &lt;em&gt;really&lt;/em&gt; rusty, you can also flip the &lt;code&gt;language&lt;/code&gt; filter to “eng” to view an older English translation.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; And if the margin references a text from the Old Testament, you can call the Septuagint as well as the original Hebrew.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tribble(
  ~label, ~excerpt,
  &amp;quot;Genesis&amp;quot;, &amp;quot;32.31&amp;quot;,
  &amp;quot;Genesis, pointed&amp;quot;, &amp;quot;32.31&amp;quot;,
  &amp;quot;Numeri&amp;quot;, &amp;quot;12.8&amp;quot;,
  &amp;quot;Numbers, pointed&amp;quot;, &amp;quot;12.8&amp;quot;
  ) %&amp;gt;% 
  left_join(perseus_catalog) %&amp;gt;%
  filter(language %in% c(&amp;quot;grc&amp;quot;, &amp;quot;hpt&amp;quot;)) %&amp;gt;%
  select(urn, excerpt) %&amp;gt;%
  pmap_df(get_perseus_text) %&amp;gt;%
  perseus_parallel()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/img/blog-images/2017-12-05-rperseus/Parallel2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Admittedly, there is some “friction” here in joining the &lt;code&gt;perseus_catalog&lt;/code&gt; onto the initial tibble. There is a learning curve with getting acquainted with the idiosyncrasies of the catalog object. A later release will aim to streamline this workflow.&lt;/p&gt;

&lt;h3 id=&#34;future-work&#34;&gt;Future Work&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://ropensci.github.io/rperseus/articles/rperseus-vignette.html&#34;&gt;Check the vignette&lt;/a&gt; for a more general overview of &lt;code&gt;rperseus&lt;/code&gt;. In the meantime, I look forward to getting more intimately acquainted with the Perseus Digital Library. Tentative plans to extend &lt;code&gt;rperseus&lt;/code&gt; a Shiny interface to further reduce “friction” and a method of creating a “book” of custom parallels with &lt;code&gt;bookdown&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h3&gt;

&lt;p&gt;I want to thank my two rOpenSci reviewers, &lt;a href=&#34;https://www.ildiczeller.com/&#34;&gt;Ildikó Czeller&lt;/a&gt; and &lt;a href=&#34;https://francoismichonneau.net/&#34;&gt;François Michonneau,&lt;/a&gt; for coaching me through the review process. They were the first two individuals to ever scrutinize my code, and I was lucky to hear their feedback. rOpenSci onboarding is truly a wonderful process.&lt;/p&gt;

&lt;!-- references --&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Bauer, Walter. &lt;em&gt;A Greek-English Lexicon of the New Testament and Other Early Christian Literature.&lt;/em&gt; Edited by Frederick W. Danker. 3rd ed. Chicago: University of Chicago Press, 2000.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Aland, Kurt. &lt;em&gt;Synopsis Quattuor Evangeliorum.&lt;/em&gt; Deutsche Bibelgesellschaft, 1997.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;The Greek text from the Perseus Digital Library is from 1885 standards. The advancement of textual criticism in the 20th century led to a more stable text you would find in current editions of the Greek New Testament.&lt;br /&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;The English translation is from Rainbow Missions, Inc. &lt;em&gt;World English Bible.&lt;/em&gt; Rainbow Missions, Inc.; revision of the American Standard Version of 1901. I’ve toyed with the idea of incorporating more modern translations, but that would require require resources beyond the Perseus Digital Library.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;&amp;ldquo;hpt&amp;rdquo; is the pointed Hebrew text from &lt;em&gt;Codex Leningradensis.&lt;/em&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;

      </description>
    </item>
    
    <item>
      <title>googleLanguageR - Analysing language through the Google Cloud Machine Learning APIs</title>
      <link>https://ropensci.org/blog/2017/10/03/googlelanguager/</link>
      <pubDate>Tue, 03 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2017/10/03/googlelanguager/</guid>
      <description>
        
        

&lt;!-- open source image taken from: https://upload.wikimedia.org/wikipedia/commons/2/21/Bell_System_switchboard.jpg --&gt;

&lt;p&gt;&lt;span&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-10-03-googlelanguager/switchboard.jpg&#34;&gt;&lt;/div&gt;
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;One of the greatest assets human beings possess is the power of speech and language, from which almost all our other accomplishments flow. To be able to analyse communication offers us a chance to gain a greater understanding of one another.&lt;/p&gt;

&lt;p&gt;To help you with this, &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/&#34;&gt;&lt;code&gt;googleLanguageR&lt;/code&gt;&lt;/a&gt; is an R package that allows you to perform speech-to-text transcription, neural net translation and natural language processing via the &lt;a href=&#34;https://cloud.google.com/products/machine-learning/&#34;&gt;Google Cloud machine learning services&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;An introduction to the package is below, but you can find out more details at the &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/&#34;&gt;&lt;code&gt;googleLanguageR&lt;/code&gt; website&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;google-s-bet&#34;&gt;Google&amp;rsquo;s bet&lt;/h3&gt;

&lt;p&gt;Google predicts that machine learning is to be a fundamental feature of business, and so they are looking to become the infrastructure that makes machine learning possible. Metaphorically speaking: If machine learning is electricity, then Google wants to be the pylons carrying it around the country.&lt;/p&gt;

&lt;!-- open source image taken from: https://pixabay.com/en/pylon-sky-electricity-tower-2515429/ --&gt;

&lt;p&gt;&lt;span&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-10-03-googlelanguager/pylon.jpg&#34;&gt;&lt;/div&gt;
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Google may not be the only company with such ambitions, but one advantage Google has is the amount of data it possesses. Twenty years of web crawling has given it an unprecedented corpus to train its models.  In addition, its recent moves into voice and video gives it one of the biggest audio and speech datasets, all of which have been used to help create machine learning applications within its products such as search and Gmail. Further investment in machine learning is shown by Google&amp;rsquo;s purchase of &lt;a href=&#34;https://deepmind.com/&#34;&gt;Deepmind&lt;/a&gt;, a UK based A.I. research firm that recently was in the news for defeating the top Go champion with its neural network trained Go bot.  Google has also taken an open-source route with the creation and publication of &lt;a href=&#34;https://www.tensorflow.org/&#34;&gt;Tensorflow&lt;/a&gt;, a leading machine learning framework.&lt;/p&gt;

&lt;p&gt;Whilst you can create your own machine learning models, for those users who haven&amp;rsquo;t the expertise, data or time to do so, Google also offers an increasing range of machine learning APIs that are pre-trained, such as image and video recognition or job search.  &lt;code&gt;googleLanguageR&lt;/code&gt; wraps the subset of those machine learning APIs that are language flavoured - Cloud Speech, Translation and Natural Language.&lt;/p&gt;

&lt;p&gt;Since they carry complementary outputs that can be used in each other&amp;rsquo;s input, all three of the APIs are included in one package. For example, you can transcribe a recording of someone speaking in Danish, translate that to English and then identify how positive or negative the writer felt about its content (sentiment analysis) then identify the most important concepts and objects within the content (entity analysis).&lt;/p&gt;

&lt;h3 id=&#34;motivations&#34;&gt;Motivations&lt;/h3&gt;

&lt;h4 id=&#34;fake-news&#34;&gt;Fake news&lt;/h4&gt;

&lt;p&gt;One reason why I started looking at this area was the growth of &amp;lsquo;fake news&amp;rsquo;, and its effect on political discourse on social media. I wondered if there was some way to put metrics on how much a news story fuelled one&amp;rsquo;s own bias within your own filter bubble.  The entity API provides a way to perform entity and sentiment analysis at scale on tweets, and by then comparing different users and news sources preferences the hope is to be able to judge how much they are in agreement with your own bias, views and trusted reputation sources.&lt;/p&gt;

&lt;h4 id=&#34;make-your-own-alexa&#34;&gt;Make your own Alexa&lt;/h4&gt;

&lt;p&gt;Another motivating application is the growth of voice commands that will become the primary way of user interface with technology.  Already, &lt;a href=&#34;https://www.thinkwithgoogle.com/data-gallery/detail/google-app-voice-search/&#34;&gt;Google reports up to 20% of search in its app&lt;/a&gt; is via voice search.  I&amp;rsquo;d like to be able to say &amp;ldquo;R, print me out that report for client X&amp;rdquo;.  A Shiny app that records your voice, uploads to the API then parses the return text into actions gives you a chance to create your very own Alexa-like infrastructure.&lt;/p&gt;

&lt;p&gt;&lt;span style=&#34;text-align:center&#34;&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-10-03-googlelanguager/alexa.jpg&#34;&gt;&lt;/div&gt;
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The voice activated internet connected speaker, Amazon&amp;rsquo;s Alexa - image from www.amazon.co.uk&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;translate-everything&#34;&gt;Translate everything&lt;/h4&gt;

&lt;p&gt;Finally, I live and work in Denmark.  As Danish is only spoken by less than 6 million people, applications that work in English may not be available in Danish very quickly, if at all.  The API&amp;rsquo;s translation service is the one that made the news in 2016 for &lt;a href=&#34;https://research.googleblog.com/2016/09/a-neural-network-for-machine.html&#34;&gt;&amp;ldquo;inventing its own language&amp;rdquo;&lt;/a&gt;, and offers much better English to Danish translations that the free web version and may make services available in Denmark sooner.&lt;/p&gt;

&lt;h3 id=&#34;using-the-library&#34;&gt;Using the library&lt;/h3&gt;

&lt;p&gt;To use these APIs within R, you first need to do a one-time setup to create a Google Project, add a credit card and authenticate which is &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/#installation&#34;&gt;detailed on the package website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After that, you feed in the R objects you want to operate upon.  The &lt;a href=&#34;https://github.com/ropensci/onboarding/issues/127&#34;&gt;rOpenSci review&lt;/a&gt; helped to ensure that this can scale up easily, so that you can feed in large character vectors which the library will parse and rate limit as required.  The functions also work within &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidyverse&lt;/a&gt; pipe syntax.&lt;/p&gt;

&lt;h4 id=&#34;speech-to-text&#34;&gt;Speech-to-text&lt;/h4&gt;

&lt;p&gt;The &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/articles/speech.html&#34;&gt;Cloud Speech API&lt;/a&gt; is exposed via the &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/reference/gl_speech.html&#34;&gt;&lt;code&gt;gl_speech&lt;/code&gt;&lt;/a&gt; function.&lt;/p&gt;

&lt;p&gt;It supports multiple audio formats and languages, and you can either feed a sub-60 second audio file directly, or perform asynchrnous requests for longer audio files.&lt;/p&gt;

&lt;p&gt;Example code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(googleLanguageR)

my_audio &amp;lt;- &amp;quot;my_audio_file.wav&amp;quot;
gl_speech(my_audio)
#  A tibble: 1 x 3
#  transcript confidence                 words
#* &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;                &amp;lt;list&amp;gt;
#1 Hello Mum  0.9227779 &amp;lt;data.frame [19 x 3]&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;translation&#34;&gt;Translation&lt;/h4&gt;

&lt;p&gt;The &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/articles/translation.html&#34;&gt;Cloud Translation API&lt;/a&gt; lets you translate text via &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/reference/gl_translate.html&#34;&gt;&lt;code&gt;gl_translate&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As you are charged per character, one tip here if you are working with lots of different languages is to perform detection of language offline first using another rOpenSci package, &lt;a href=&#34;https://github.com/ropensci/cld2&#34;&gt;&lt;code&gt;cld2&lt;/code&gt;&lt;/a&gt;.  That way you can avoid charges for text that is already in your target language i.e. English.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(googleLanguageR)
library(cld2)
library(purrr)

my_text &amp;lt;- c(&amp;quot;Katten sidder på måtten&amp;quot;, &amp;quot;The cat sat on the mat&amp;quot;)

## offline detect language via cld2
detected &amp;lt;- map_chr(my_text, detect_language)
# [1] &amp;quot;DANISH&amp;quot;  &amp;quot;ENGLISH&amp;quot;

## get non-English text
translate_me &amp;lt;- my_text[detected != &amp;quot;ENGLISH&amp;quot;]

## translate
gl_translate(translate_me)
## A tibble: 1 x 3
#                 translatedText detectedSourceLanguage                    text
#*                         &amp;lt;chr&amp;gt;                  &amp;lt;chr&amp;gt;                   &amp;lt;chr&amp;gt;
#1 The cat is sitting on the mat                     da Katten sidder på måtten
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;natural-language-processing&#34;&gt;Natural Language Processing&lt;/h4&gt;

&lt;p&gt;The &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/articles/nlp.html&#34;&gt;Natural Language API&lt;/a&gt; reveals the structure and meaning of text, accessible via the &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/reference/gl_nlp.html&#34;&gt;&lt;code&gt;gl_nlp&lt;/code&gt;&lt;/a&gt; function.&lt;/p&gt;

&lt;p&gt;It returns several analysis:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Entity analysis&lt;/em&gt; - finds named entities (currently proper names and common nouns) in the text along with entity types, salience, mentions for each entity, and other properties. If possible, will also return metadata about that entity such as a Wikipedia URL.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Syntax&lt;/em&gt; - analyzes the syntax of the text and provides sentence boundaries and tokenization along with part of speech tags, dependency trees, and other properties.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Sentiment&lt;/em&gt; - the overall sentiment of the text, represented by a magnitude [0, +inf] and score between -1.0 (negative sentiment) and 1.0 (positive sentiment)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are all useful to get an understanding of the meaning of a sentence, and has potentially the greatest number of applications of the APIs featured.  With entity analysis, auto categorisation of text is possible; the syntax returns let you pull out nouns and verbs for parsing into other actions; and the sentiment analysis allows you to get a feeling for emotion within text.&lt;/p&gt;

&lt;p&gt;A demonstration is below which gives an idea of what output you can generate:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(googleLanguageR)
quote &amp;lt;- &amp;quot;Two things are infinite: the universe and human stupidity; and I&#39;m not sure about the universe.&amp;quot;
nlp &amp;lt;- gl_nlp(quote)

str(nlp)
#List of 6
# $ sentences        :List of 1
#  ..$ :&#39;data.frame&#39;:	1 obs. of  4 variables:
#  .. ..$ content    : chr &amp;quot;Two things are infinite: the universe and human stupidity; and I&#39;m not sure about the universe.&amp;quot;
#  .. ..$ beginOffset: int 0
#  .. ..$ magnitude  : num 0.6
#  .. ..$ score      : num -0.6
# $ tokens           :List of 1
#  ..$ :&#39;data.frame&#39;:	20 obs. of  17 variables:
#  .. ..$ content       : chr [1:20] &amp;quot;Two&amp;quot; &amp;quot;things&amp;quot; &amp;quot;are&amp;quot; &amp;quot;infinite&amp;quot; ...
#  .. ..$ beginOffset   : int [1:20] 0 4 11 15 23 25 29 38 42 48 ...
#  .. ..$ tag           : chr [1:20] &amp;quot;NUM&amp;quot; &amp;quot;NOUN&amp;quot; &amp;quot;VERB&amp;quot; &amp;quot;ADJ&amp;quot; ...
#  .. ..$ aspect        : chr [1:20] &amp;quot;ASPECT_UNKNOWN&amp;quot; &amp;quot;ASPECT_UNKNOWN&amp;quot; &amp;quot;ASPECT_UNKNOWN&amp;quot; &amp;quot;ASPECT_UNKNOWN&amp;quot; ...
#  .. ..$ case          : chr [1:20] &amp;quot;CASE_UNKNOWN&amp;quot; &amp;quot;CASE_UNKNOWN&amp;quot; &amp;quot;CASE_UNKNOWN&amp;quot; &amp;quot;CASE_UNKNOWN&amp;quot; ...
#  .. ..$ form          : chr [1:20] &amp;quot;FORM_UNKNOWN&amp;quot; &amp;quot;FORM_UNKNOWN&amp;quot; &amp;quot;FORM_UNKNOWN&amp;quot; &amp;quot;FORM_UNKNOWN&amp;quot; ...
#  .. ..$ gender        : chr [1:20] &amp;quot;GENDER_UNKNOWN&amp;quot; &amp;quot;GENDER_UNKNOWN&amp;quot; &amp;quot;GENDER_UNKNOWN&amp;quot; &amp;quot;GENDER_UNKNOWN&amp;quot; ...
#  .. ..$ mood          : chr [1:20] &amp;quot;MOOD_UNKNOWN&amp;quot; &amp;quot;MOOD_UNKNOWN&amp;quot; &amp;quot;INDICATIVE&amp;quot; &amp;quot;MOOD_UNKNOWN&amp;quot; ...
#  .. ..$ number        : chr [1:20] &amp;quot;NUMBER_UNKNOWN&amp;quot; &amp;quot;PLURAL&amp;quot; &amp;quot;NUMBER_UNKNOWN&amp;quot; &amp;quot;NUMBER_UNKNOWN&amp;quot; ...
#  .. ..$ person        : chr [1:20] &amp;quot;PERSON_UNKNOWN&amp;quot; &amp;quot;PERSON_UNKNOWN&amp;quot; &amp;quot;PERSON_UNKNOWN&amp;quot; &amp;quot;PERSON_UNKNOWN&amp;quot; ...
#  .. ..$ proper        : chr [1:20] &amp;quot;PROPER_UNKNOWN&amp;quot; &amp;quot;PROPER_UNKNOWN&amp;quot; &amp;quot;PROPER_UNKNOWN&amp;quot; &amp;quot;PROPER_UNKNOWN&amp;quot; ...
#  .. ..$ reciprocity   : chr [1:20] &amp;quot;RECIPROCITY_UNKNOWN&amp;quot; &amp;quot;RECIPROCITY_UNKNOWN&amp;quot; &amp;quot;RECIPROCITY_UNKNOWN&amp;quot; &amp;quot;RECIPROCITY_UNKNOWN&amp;quot; ...
#  .. ..$ tense         : chr [1:20] &amp;quot;TENSE_UNKNOWN&amp;quot; &amp;quot;TENSE_UNKNOWN&amp;quot; &amp;quot;PRESENT&amp;quot; &amp;quot;TENSE_UNKNOWN&amp;quot; ...
#  .. ..$ voice         : chr [1:20] &amp;quot;VOICE_UNKNOWN&amp;quot; &amp;quot;VOICE_UNKNOWN&amp;quot; &amp;quot;VOICE_UNKNOWN&amp;quot; &amp;quot;VOICE_UNKNOWN&amp;quot; ...
#  .. ..$ headTokenIndex: int [1:20] 1 2 2 2 2 6 2 6 9 6 ...
#  .. ..$ label         : chr [1:20] &amp;quot;NUM&amp;quot; &amp;quot;NSUBJ&amp;quot; &amp;quot;ROOT&amp;quot; &amp;quot;ACOMP&amp;quot; ...
#  .. ..$ value         : chr [1:20] &amp;quot;Two&amp;quot; &amp;quot;thing&amp;quot; &amp;quot;be&amp;quot; &amp;quot;infinite&amp;quot; ...
# $ entities         :List of 1
#  ..$ :Classes ‘tbl_df’, ‘tbl’ and &#39;data.frame&#39;:	6 obs. of  9 variables:
#  .. ..$ name         : chr [1:6] &amp;quot;human stupidity&amp;quot; &amp;quot;things&amp;quot; &amp;quot;universe&amp;quot; &amp;quot;universe&amp;quot; ...
#  .. ..$ type         : chr [1:6] &amp;quot;OTHER&amp;quot; &amp;quot;OTHER&amp;quot; &amp;quot;OTHER&amp;quot; &amp;quot;OTHER&amp;quot; ...
#  .. ..$ salience     : num [1:6] 0.1662 0.4771 0.2652 0.2652 0.0915 ...
#  .. ..$ mid          : Factor w/ 0 levels: NA NA NA NA NA NA
#  .. ..$ wikipedia_url: Factor w/ 0 levels: NA NA NA NA NA NA
#  .. ..$ magnitude    : num [1:6] NA NA NA NA NA NA
#  .. ..$ score        : num [1:6] NA NA NA NA NA NA
#  .. ..$ beginOffset  : int [1:6] 42 4 29 86 29 86
#  .. ..$ mention_type : chr [1:6] &amp;quot;COMMON&amp;quot; &amp;quot;COMMON&amp;quot; &amp;quot;COMMON&amp;quot; &amp;quot;COMMON&amp;quot; ...
# $ language         : chr &amp;quot;en&amp;quot;
# $ text             : chr &amp;quot;Two things are infinite: the universe and human stupidity; and I&#39;m not sure about the universe.&amp;quot;
# $ documentSentiment:Classes ‘tbl_df’, ‘tbl’ and &#39;data.frame&#39;:	1 obs. of  2 variables:
#  ..$ magnitude: num 0.6
#  ..$ score    : num -0.6
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h3&gt;

&lt;p&gt;This package is 10 times better due to the efforts of the rOpenSci reviewers &lt;a href=&#34;http://enpiar.com/&#34;&gt;Neal Richardson&lt;/a&gt; and &lt;a href=&#34;http://www.juliagustavsen.com/&#34;&gt;Julia Gustavsen&lt;/a&gt;, who have whipped the documentation, outputs and test cases into the form they are today in &lt;code&gt;0.1.0&lt;/code&gt;.  Many thanks to them.&lt;/p&gt;

&lt;p&gt;Hopefully, this is just the beginning and the package can be further improved by its users - if you do give the package a try and find a potential improvement, &lt;a href=&#34;https://github.com/ropensci/googleLanguageR/issues&#34;&gt;raise an issue on GitHub&lt;/a&gt; and we can try to implement it.  I&amp;rsquo;m excited to see what users can do with these powerful tools.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Release &#39;open&#39; data from their PDF prisons using tabulizer</title>
      <link>https://ropensci.org/blog/2017/04/18/tabulizer/</link>
      <pubDate>Tue, 18 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2017/04/18/tabulizer/</guid>
      <description>
        
        

&lt;p&gt;There is no problem in science quite as frustrating as &lt;em&gt;other peoples&amp;rsquo; data&lt;/em&gt;. Whether it&amp;rsquo;s malformed spreadsheets, disorganized documents, proprietary file formats, data without metadata, or any other data scenario created by someone else, &lt;a href=&#34;https://twitter.com/hashtag/otherpeoplesdata?src=hash&#34;&gt;scientists have taken to Twitter to complain about it&lt;/a&gt;. As a political scientist who regularly encounters so-called &amp;ldquo;open data&amp;rdquo; in PDFs, this problem is particularly irritating. PDFs may have &amp;ldquo;portable&amp;rdquo; in their name, making them display consistently on various platforms, but that portability means any information contained in a PDF is irritatingly difficult to extract computationally. Encountering &amp;ldquo;open data&amp;rdquo; PDFs therefore makes me shout things like this repeatedly:&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;HEY US GOVERNMENT! Tables in PDF documents aren&amp;#39;t &amp;quot;Open Data.&amp;quot; Please provide machine-readable formats or it doesn&amp;#39;t count.&lt;/p&gt;&amp;mdash; Anthony A. Boyles (@AABoyles) &lt;a href=&#34;https://twitter.com/AABoyles/status/776428077123506176&#34;&gt;September 15, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;What can we do about such data other than extract it by hand? One answer is rely on &lt;a href=&#34;https://github.com/ropensci/tabulizer&#34;&gt;&lt;code&gt;tabulizer&lt;/code&gt;&lt;/a&gt; a package I submitted to rOpenSci that reduces some and often all of the hassle of extracting tabular data locked inside PDFs.&lt;/p&gt;

&lt;h2 id=&#34;what-is-tabulizer&#34;&gt;What is &lt;code&gt;tabulizer&lt;/code&gt;?&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;tabulizer&lt;/code&gt; provides R bindings to &lt;a href=&#34;https://github.com/tabulapdf/tabula-java&#34;&gt;the tabula-java library&lt;/a&gt;, the open-source java library that powers &lt;a href=&#34;http://tabula.technology/&#34;&gt;Tabula&lt;/a&gt; (source code on &lt;a href=&#34;https://github.com/tabulapdf/tabula&#34;&gt;GitHub&lt;/a&gt;). What this means is that &lt;code&gt;tabulizer&lt;/code&gt; relies directly on the underlying java classes that power Tabula without the need for system calls or the need to explicitly install Tabula on your system. (A potential downside is the need to handle intricacies of rJava - R&amp;rsquo;s interface to Java, which I discuss in depth below.)&lt;/p&gt;

&lt;p&gt;Tabula is an extremely powerful tool for extracting tabular data locked in PDFs. It&amp;rsquo;s an incredibly valuable tool because the PDF file specification does not have a &amp;ldquo;table&amp;rdquo; representation. Instead, PDFs simply represent tables through the fixed positioning of text into rows and columns. Thus, unlike HTML, Word (.docx), or Open Document (.odt) file formats, there is no easy programmatic way to identify a table in a PDF. Tabula thus implements novel algorithms for identifying rows and columns of data and extracting them. &lt;code&gt;tabulizer&lt;/code&gt; just provides a thin R layer on top of this power Java code.&lt;/p&gt;

&lt;p&gt;Unfortunately, this means that &lt;code&gt;tabulizer&lt;/code&gt; is not a universal solution to data trapped in PDFs. In particular, it can only identify and extract tables that are represented as &lt;em&gt;text&lt;/em&gt; in a PDF:&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Oh no no no no no! Just received &lt;a href=&#34;https://twitter.com/hashtag/otherpeoplesdata?src=hash&#34;&gt;#otherpeoplesdata&lt;/a&gt; as a 276 page set of printed tables scanned in to a PDF&lt;/p&gt;&amp;mdash; Dr Elizabeth Sargent (@esargent184) &lt;a href=&#34;https://twitter.com/esargent184/status/510056437033091074&#34;&gt;September 11, 2014&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;If a PDF is a scan of a document or the table is actually an image embedded in the PDF, tabula - and thus &lt;code&gt;tabulizer&lt;/code&gt; - are useless. In those cases, users might want to check out the OCR functionality of &lt;a href=&#34;https://github.com/ropensci/tesseract&#34;&gt;tesseract&lt;/a&gt;, which Jeroen Ooms developed for rOpenSci and &lt;a href=&#34;https://ropensci.org/blog/blog/2016/11/16/tesseract&#34;&gt;discussed previously on this blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But it does mean that a substantial amount of difficult-to-parse tabular information in PDFs is now readily and quickly accessible via just one &lt;code&gt;tabulizer&lt;/code&gt; function: &lt;code&gt;extract_tables()&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;tabulizer&lt;/code&gt; is not yet on CRAN. (It&amp;rsquo;s CRAN-ready but due to some underlying developments that are ongoing in the tabula-java library, I&amp;rsquo;m waiting for a formal release.) In the meantime, it&amp;rsquo;s possible to install &lt;code&gt;tabulizer&lt;/code&gt; directly from GitHub.&lt;/p&gt;

&lt;p&gt;Before doing that, I would encourage users to make sure they have rJava installed (from CRAN) and that it works correctly on their platform. A lot of users report difficulties installing &lt;code&gt;tabulizer&lt;/code&gt; that ultimately boil down to being Java and rJava issues that need to be resolved first. The &lt;a href=&#34;https://github.com/ropensci/tabulizer#installation&#34;&gt;package README&lt;/a&gt; provides a number of details on installation, which requires a strictly ordered set of steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Install the Java Development Kit, if you don&amp;rsquo;t already have it on your system. (Note that the JDK is different from the Java Runtime Environment (JRE) that you almost certainly already have.) Details of how to do this vary a lot between platforms, so see the &lt;a href=&#34;https://github.com/ropensci/tabulizer#installation&#34;&gt;README&lt;/a&gt; for details.&lt;/li&gt;
&lt;li&gt;Install rJava using &lt;code&gt;install.packages(&amp;quot;rJava&amp;quot;)&lt;/code&gt; and resolve any issues surrounding the &lt;code&gt;JAVA_HOME&lt;/code&gt; environment variable that may need to be set before and/or after installing rJava. Again, see the &lt;a href=&#34;https://github.com/ropensci/tabulizer#installation&#34;&gt;README&lt;/a&gt; or &lt;a href=&#34;http://stackoverflow.com/search?q=%5Br%5D+rjava+install&#34;&gt;various question/answer pairs on StackOverflow&lt;/a&gt; for platform-specific instructions.&lt;/li&gt;
&lt;li&gt;Install &lt;code&gt;tabulizer&lt;/code&gt; and &lt;code&gt;tabulizerjars&lt;/code&gt; (the package containing the tabula java library) using your favorite GitHub package installer:&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;library(&amp;quot;ghit&amp;quot;)
ghit::install_github(c(&amp;quot;ropensci/tabulizerjars&amp;quot;,&amp;quot;ropensci/tabulizer&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This should work. If not, set &lt;code&gt;verbose = TRUE&lt;/code&gt; in &lt;code&gt;ghit::install_github()&lt;/code&gt; to identify the source of any issues. Some common problems are the dependency on the &lt;strong&gt;png&lt;/strong&gt; package, which might need to be installed first. On Windows (depending on your version of R and how it was installed) may require setting &lt;code&gt;INSTALL_opts = &amp;quot;--no-multiarch&amp;quot;&lt;/code&gt; in &lt;code&gt;ghit::install_github()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If none of these steps work, scroll through &lt;a href=&#34;https://github.com/ropensci/tabulizer/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue&#34;&gt;the GitHub issues page&lt;/a&gt; for anyone experiencing a similar problem and, if not resolved in any of those discussions, feel free to open an issue on GitHub describing your problem including the fully verbose output of &lt;code&gt;install_github()&lt;/code&gt; and your &lt;code&gt;sessionInfo()&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;unlocking-elections-data-with-tabulizer&#34;&gt;Unlocking elections data with &lt;code&gt;tabulizer&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Elections data are the bread and butter of a lot of quantitative political science research. Many researchers in my field need to know how many citizens voted and for whom in order to make sense of campaigns, election integrity, partisanship, and so forth. Yet a substantial amount of election-related data is locked in government-produced PDFs. Worse, national, state, and local governments have little to no standardization in the formatting of elections data, meaning even if one could figure out a computational strategy for extracting one kind of data about elections in one year from one state, that computational strategy would likely be useless in the same state in another year or in any other state. Elections provide a fantastic and highly visible example of &amp;ldquo;open&amp;rdquo; government data that&amp;rsquo;s not really open or usable at all.&lt;/p&gt;

&lt;p&gt;As a simple example, &lt;a href=&#34;http://elections.cdn.sos.ca.gov/sov/2016-general/sov/04-historical-voter-reg-participation.pdf&#34;&gt;this PDF from the California Secretary of State&amp;rsquo;s office&lt;/a&gt; contains historical voter registration and turnout data in a well-formatted table. Why this is a PDF nobody knows. But extracting the tables using &lt;code&gt;tabulizer&lt;/code&gt;&amp;rsquo;s &lt;code&gt;extract_tables()&lt;/code&gt; function is a breeze with no need to even download the file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;tabulizer&amp;quot;)
sos_url &amp;lt;- &amp;quot;http://elections.cdn.sos.ca.gov/sov/2016-general/sov/04-historical-voter-reg-participation.pdf&amp;quot;
tab1 &amp;lt;- extract_tables(sos_url)
str(tab1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## List of 2
##  $ : chr [1:58, 1:9] &amp;quot;&amp;quot; &amp;quot;Election Date&amp;quot; &amp;quot;Nov. 8, 1910&amp;quot; &amp;quot;Nov. 5, 1912 P&amp;quot; ...
##  $ : chr [1:6, 1:9] &amp;quot;&amp;quot; &amp;quot;Election Date&amp;quot; &amp;quot;Nov. 2, 2010&amp;quot; &amp;quot;Nov. 6, 2012 P&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The (default) result is a list of two matrices, each containing the tables from pages 1 and 2 of the document, respectively. A couple of quick cleanups and this becomes a well-formatted data frame:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# save header
h &amp;lt;- tab1[[1]][2,]
# remove headers in first table
tab1[[1]] &amp;lt;- tab1[[1]][-c(1,2),]
# remove duplicated header in second table
tab1[[2]] &amp;lt;- tab1[[2]][-c(1,2),]
# merge into one table
tab1df &amp;lt;- setNames(as.data.frame(do.call(&amp;quot;rbind&amp;quot;, tab1), stringsAsFactors = FALSE), h)
str(tab1df)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:	60 obs. of  9 variables:
##  $ Election Date: chr  &amp;quot;Nov. 8, 1910&amp;quot; &amp;quot;Nov. 5, 1912 P&amp;quot; &amp;quot;Nov. 3, 1914&amp;quot; &amp;quot;Nov. 7, 1916 P&amp;quot; ...
##  $ Eligible     : chr  &amp;quot;725,000&amp;quot; &amp;quot;1,569,000&amp;quot; &amp;quot;1,726,000&amp;quot; &amp;quot;1,806,000&amp;quot; ...
##  $ Democratic   : chr  &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; ...
##  $ Republican   : chr  &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; ...
##  $ Other        : chr  &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; ...
##  $ Total        : chr  &amp;quot;*&amp;quot; &amp;quot;987,368&amp;quot; &amp;quot;1,219,345&amp;quot; &amp;quot;1,314,446&amp;quot; ...
##  $ Total Votes  : chr  &amp;quot;393,893&amp;quot; &amp;quot;707,776&amp;quot; &amp;quot;961,868&amp;quot; &amp;quot;1,045,858&amp;quot; ...
##  $ Registered   : chr  &amp;quot;*&amp;quot; &amp;quot;71.68%&amp;quot; &amp;quot;78.88%&amp;quot; &amp;quot;79.57%&amp;quot; ...
##  $ Eligible     : chr  &amp;quot;54.33%&amp;quot; &amp;quot;45.11%&amp;quot; &amp;quot;55.73%&amp;quot; &amp;quot;57.91%&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which is very easy to then quickly turn into a time-series visualization of registration rates:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;ggplot2&amp;quot;)
years &amp;lt;- regexpr(&amp;quot;[[:digit:]]{4}&amp;quot;,tab1df[[&amp;quot;Election Date&amp;quot;]])
tab1df$Year &amp;lt;- as.numeric(regmatches(tab1df[[&amp;quot;Election Date&amp;quot;]], years))
tab1df$RegPerc &amp;lt;- as.numeric(gsub(&amp;quot;%&amp;quot;, &amp;quot;&amp;quot;, tab1df$Registered))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(tab1df, aes(x = Year, y = RegPerc)) +
  geom_line() + ylim(c(0,100)) + ylab(&amp;quot;% Registered&amp;quot;) +
  ggtitle(&amp;quot;California Voter Registration, by Year&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Warning: Removed 1 rows containing missing values (geom_path).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/Gkbc1VO.png&#34; alt=&#34;plot of chunk example1plot&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;optional-arguments&#34;&gt;Optional arguments&lt;/h2&gt;

&lt;p&gt;The &lt;code&gt;extract_tables()&lt;/code&gt; has several arguments that control extraction and the return value of the function. They performed reasonably well here, but it&amp;rsquo;s worth seeing a few of the other options. The &lt;code&gt;method&lt;/code&gt; argument controls the return value. For extremely well-formatted tables, setting this to &amp;ldquo;data.frame&amp;rdquo; can be convenient, though it doesn&amp;rsquo;t work perfectly here:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(tab2 &amp;lt;- extract_tables(sos_url, method = &amp;quot;data.frame&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## List of 2
##  $ :&#39;data.frame&#39;:	57 obs. of  9 variables:
##   ..$ X        : chr [1:57] &amp;quot;Election Date&amp;quot; &amp;quot;Nov. 8, 1910&amp;quot; &amp;quot;Nov. 5, 1912 P&amp;quot; &amp;quot;Nov. 3, 1914&amp;quot; ...
##   ..$ X.1      : chr [1:57] &amp;quot;Eligible&amp;quot; &amp;quot;725,000&amp;quot; &amp;quot;1,569,000&amp;quot; &amp;quot;1,726,000&amp;quot; ...
##   ..$ X.2      : chr [1:57] &amp;quot;Democratic&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; ...
##   ..$ X.3      : chr [1:57] &amp;quot;Republican&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; ...
##   ..$ X.4      : chr [1:57] &amp;quot;Other&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; ...
##   ..$ X.5      : chr [1:57] &amp;quot;Total&amp;quot; &amp;quot;*&amp;quot; &amp;quot;987,368&amp;quot; &amp;quot;1,219,345&amp;quot; ...
##   ..$ X.6      : chr [1:57] &amp;quot;Total Votes&amp;quot; &amp;quot;393,893&amp;quot; &amp;quot;707,776&amp;quot; &amp;quot;961,868&amp;quot; ...
##   ..$ Turnout  : chr [1:57] &amp;quot;Registered&amp;quot; &amp;quot;*&amp;quot; &amp;quot;71.68%&amp;quot; &amp;quot;78.88%&amp;quot; ...
##   ..$ Turnout.1: chr [1:57] &amp;quot;Eligible&amp;quot; &amp;quot;54.33%&amp;quot; &amp;quot;45.11%&amp;quot; &amp;quot;55.73%&amp;quot; ...
##  $ :&#39;data.frame&#39;:	5 obs. of  9 variables:
##   ..$ X        : chr [1:5] &amp;quot;Election Date&amp;quot; &amp;quot;Nov. 2, 2010&amp;quot; &amp;quot;Nov. 6, 2012 P&amp;quot; &amp;quot;Nov. 4, 2014&amp;quot; ...
##   ..$ X.1      : chr [1:5] &amp;quot;Eligible&amp;quot; &amp;quot;23,551,699&amp;quot; &amp;quot;23,802,577&amp;quot; &amp;quot;24,288,145&amp;quot; ...
##   ..$ X.2      : chr [1:5] &amp;quot;Democratic&amp;quot; &amp;quot;7,620,240&amp;quot; &amp;quot;7,966,422&amp;quot; &amp;quot;7,708,683&amp;quot; ...
##   ..$ X.3      : chr [1:5] &amp;quot;Republican&amp;quot; &amp;quot;5,361,875&amp;quot; &amp;quot;5,356,608&amp;quot; &amp;quot;5,005,422&amp;quot; ...
##   ..$ X.4      : chr [1:5] &amp;quot;Other&amp;quot; &amp;quot;4,303,768&amp;quot; &amp;quot;4,922,940&amp;quot; &amp;quot;5,089,718&amp;quot; ...
##   ..$ X.5      : chr [1:5] &amp;quot;Total&amp;quot; &amp;quot;17,285,883&amp;quot; &amp;quot;18,245,970&amp;quot; &amp;quot;17,803,823&amp;quot; ...
##   ..$ X.6      : chr [1:5] &amp;quot;Total Votes&amp;quot; &amp;quot;10,300,392&amp;quot; &amp;quot;13,202,158&amp;quot; &amp;quot;7,513,972&amp;quot; ...
##   ..$ Turnout  : chr [1:5] &amp;quot;Registered&amp;quot; &amp;quot;59.59%&amp;quot; &amp;quot;72.36%&amp;quot; &amp;quot;42.20%&amp;quot; ...
##   ..$ Turnout.1: chr [1:5] &amp;quot;Eligible&amp;quot; &amp;quot;43.74%&amp;quot; &amp;quot;55.47%&amp;quot; &amp;quot;30.94%&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Setting &lt;code&gt;method = &amp;quot;character&amp;quot;&lt;/code&gt; returns a list of character vectors with white space reflecting the positioning of text within the PDF&amp;rsquo;s tabular representation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(tab3 &amp;lt;- extract_tables(sos_url, method = &amp;quot;character&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## List of 2
##  $ : chr &amp;quot;\t\t\t\t\t\t\tTurnout\tTurnout\nElection Date\tEligible\tDemocratic\tRepublican\tOther\tTotal\tTotal Votes\tRegistered\tEligibl&amp;quot;| __truncated__
##  $ : chr &amp;quot;\t\t\t\t\t\t\tTurnout\tTurnout\nElection Date\tEligible\tDemocratic\tRepublican\tOther\tTotal\tTotal Votes\tRegistered\tEligibl&amp;quot;| __truncated__
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This argument can also be set to &lt;code&gt;&amp;quot;csv&amp;quot;&lt;/code&gt;, &lt;code&gt;&amp;quot;tsv&amp;quot;&lt;/code&gt;, or &lt;code&gt;&amp;quot;json&amp;quot;&lt;/code&gt; to use a java-level utility to write the table to files in the working directory but this tends to be inconvenient. (For advanced users, &lt;code&gt;method = &amp;quot;asis&amp;quot;&lt;/code&gt; returns an rJava object reference for those who want to manipulate the Java representation of the table directly.)&lt;/p&gt;

&lt;p&gt;The other most important option to be aware of is &lt;code&gt;guess&lt;/code&gt;, which indicates whether a column-finding algorithm should be used to identify column breaks. This should almost always be &lt;code&gt;TRUE&lt;/code&gt;, setting it to &lt;code&gt;FALSE&lt;/code&gt; will tend to return a less useful structure:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(extract_tables(sos_url, guess = FALSE)[[1]], 10)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##       [,1]
##  [1,] &amp;quot;&amp;quot;
##  [2,] &amp;quot;&amp;quot;
##  [3,] &amp;quot;&amp;quot;
##  [4,] &amp;quot;&amp;quot;
##  [5,] &amp;quot;Election Date&amp;quot;
##  [6,] &amp;quot;Nov. 8, 1910&amp;quot;
##  [7,] &amp;quot;Nov. 5, 1912 P&amp;quot;
##  [8,] &amp;quot;Nov. 3, 1914&amp;quot;
##  [9,] &amp;quot;Nov. 7, 1916 P&amp;quot;
## [10,] &amp;quot;Nov. 5, 1918&amp;quot;
##       [,2]
##  [1,] &amp;quot;HISTORICAL VOTER REGISTRATION AND&amp;quot;
##  [2,] &amp;quot;PARTICIPATION IN STATEWIDE GENERAL ELECTIONS 1910-2016&amp;quot;
##  [3,] &amp;quot;Registration Votes Cast&amp;quot;
##  [4,] &amp;quot;Turnout&amp;quot;
##  [5,] &amp;quot;Eligible Democratic Republican Other Total Total Votes Registered&amp;quot;
##  [6,] &amp;quot;725,000 * * * *393,893*&amp;quot;
##  [7,] &amp;quot;1,569,000 * * * 987,368 707,776 71.68%&amp;quot;
##  [8,] &amp;quot;1,726,000 * * * 1,219,345 961,868 78.88%&amp;quot;
##  [9,] &amp;quot;1,806,000 * * * 1,314,446 1,045,858 79.57%&amp;quot;
## [10,] &amp;quot;1,918,000 * * * 1,203,898 714,525 59.35%&amp;quot;
##       [,3]
##  [1,] &amp;quot;&amp;quot;
##  [2,] &amp;quot;&amp;quot;
##  [3,] &amp;quot;&amp;quot;
##  [4,] &amp;quot;Turnout&amp;quot;
##  [5,] &amp;quot;Eligible&amp;quot;
##  [6,] &amp;quot;54.33%&amp;quot;
##  [7,] &amp;quot;45.11%&amp;quot;
##  [8,] &amp;quot;55.73%&amp;quot;
##  [9,] &amp;quot;57.91%&amp;quot;
## [10,] &amp;quot;37.25%&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, it can be useful if users want to specify the locations of tables manually. The &lt;code&gt;area&lt;/code&gt; argument allows users to specifying a &lt;code&gt;c(top,left,bottom,right)&lt;/code&gt; vector of coordinates for the location of tables on a page (which is useful if pages also contain other non-tabular content); setting &lt;code&gt;columns&lt;/code&gt; with &lt;code&gt;guess = FALSE&lt;/code&gt; indicates where the column breaks are within a table. With a little care in specifying column positions we can successfully separate the &amp;ldquo;P&amp;rdquo; flags specifying Presidential elections that were earlier concatenated with the election dates:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cols &amp;lt;- list(c(76,123,126,203,249,297,342,392,453,498,548))
tab4 &amp;lt;- extract_tables(sos_url, guess = FALSE, columns = cols)

# save header
h &amp;lt;- tab4[[1]][5,-1]
# clean tables
tab4[[1]] &amp;lt;- tab4[[1]][-c(1:5,62),-1]
tab4[[2]] &amp;lt;- tab4[[2]][-c(1:5,10:17),-1]
# merge into one table
tab4df &amp;lt;- setNames(as.data.frame(do.call(&amp;quot;rbind&amp;quot;, tab4), stringsAsFactors = FALSE), h)
str(tab4df)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:	60 obs. of  10 variables:
##  $ Election Date: chr  &amp;quot;Nov. 8, 1910&amp;quot; &amp;quot;Nov. 5, 1912&amp;quot; &amp;quot;Nov. 3, 1914&amp;quot; &amp;quot;Nov. 7, 1916&amp;quot; ...
##  $              : chr  &amp;quot;&amp;quot; &amp;quot;P&amp;quot; &amp;quot;&amp;quot; &amp;quot;P&amp;quot; ...
##  $ Eligible     : chr  &amp;quot;725,000&amp;quot; &amp;quot;1,569,000&amp;quot; &amp;quot;1,726,000&amp;quot; &amp;quot;1,806,000&amp;quot; ...
##  $ Democratic   : chr  &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; ...
##  $ Republican   : chr  &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; ...
##  $ Other        : chr  &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; &amp;quot;*&amp;quot; ...
##  $ Total        : chr  &amp;quot;*&amp;quot; &amp;quot;987,368&amp;quot; &amp;quot;1,219,345&amp;quot; &amp;quot;1,314,446&amp;quot; ...
##  $ Total Votes  : chr  &amp;quot;393,893&amp;quot; &amp;quot;707,776&amp;quot; &amp;quot;961,868&amp;quot; &amp;quot;1,045,858&amp;quot; ...
##  $ Registered   : chr  &amp;quot;*&amp;quot; &amp;quot;71.68%&amp;quot; &amp;quot;78.88%&amp;quot; &amp;quot;79.57%&amp;quot; ...
##  $ Eligible     : chr  &amp;quot;54.33%&amp;quot; &amp;quot;45.11%&amp;quot; &amp;quot;55.73%&amp;quot; &amp;quot;57.91%&amp;quot; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Figuring out columns positions and/or table areas is quite challenging to do by hand, so the &lt;code&gt;locate_areas()&lt;/code&gt; provides an interactive interface for identifying areas. It returns lists of coordinates for specific table areas. A higher-level function, &lt;code&gt;extract_areas()&lt;/code&gt;, connects that GUI directly to &lt;code&gt;extract_tables()&lt;/code&gt; to return the tables within specified areas. Two other functions can be useful in this respect: &lt;code&gt;get_n_pages()&lt;/code&gt; indicates the number of pages in a PDF and &lt;code&gt;get_page_dims()&lt;/code&gt; indicates the dimensions of the pages.&lt;/p&gt;

&lt;h2 id=&#34;some-other-functionality&#34;&gt;Some other functionality&lt;/h2&gt;

&lt;p&gt;In addition to the core functionality around &lt;code&gt;extract_tables()&lt;/code&gt;, &lt;code&gt;tabulizer&lt;/code&gt; also provides some functions for working with PDFs that might be useful to those trapped in other peoples&amp;rsquo; data. We&amp;rsquo;ll download the file first just to save some time:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tmp &amp;lt;- tempfile(fileext = &amp;quot;.pdf&amp;quot;)
download.file(sos_url, destfile = tmp, mode = &amp;quot;wb&amp;quot;, quiet = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;extract_text()&lt;/code&gt; function extracts text content of the PDF, separately by page, as character strings:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;extract_text(tmp)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;4Election Date Eligible Democratic Republican Other         Total Total Votes\r\nTurnout \r\nRegistered\r\nTurnout \r\nEligible\r\nNov. 8, 1910 725,000 * * *             *    393,893              * 54.33%\r\nNov. 5, 1912 P 1,569,000 * * * 987,368 707,776 71.68% 45.11%\r\nNov. 3, 1914 1,726,000 * * * 1,219,345 961,868 78.88% 55.73%\r\nNov. 7, 1916 P 1,806,000 * * * 1,314,446 1,045,858 79.57% 57.91%\r\nNov. 5, 1918 1,918,000 * * * 1,203,898 714,525 59.35% 37.25%\r\nNov. 2, 1920 P 2,090,000 * * * 1,374,184 987,632 71.87% 47.26%\r\nNov. 7, 1922 2,420,000 319,107 968,429 244,848 1,532,384 1,000,997 65.32% 41.36%\r\nNov. 4, 1924 P 2,754,000 397,962 1,183,672 240,723 1,822,357 1,336,598 73.34% 48.53%\r\nNov. 2, 1926 2,989,000 410,290 1,298,062 204,510 1,912,862 1,212,452 63.38% 40.56%\r\nNov. 6, 1928 P 3,240,000 592,161 1,535,751 185,904 2,313,816 1,846,077 79.78% 56.98%\r\nNov. 4, 1930 3,463,000 456,096 1,638,575 150,557 2,245,228 1,444,872 64.35% 41.72%\r\nNov. 8, 1932 P 3,573,000 1,161,482 1,565,264 162,267 2,889,013 2,330,132 80.65% 65.22%\r\nNov. 6, 1934 3,674,000 1,555,705 1,430,198 154,211 3,140,114 2,360,916 75.19% 64.26%\r\nNov. 3, 1936 P 3,844,000 1,882,014 1,244,507 127,300 3,253,821 2,712,342 83.36% 70.56%\r\nNov. 8, 1938 4,035,000 2,144,360 1,293,929 173,127 3,611,416 2,695,904 74.65% 66.81%\r\nNov. 5, 1940 P 4,214,000 2,419,628 1,458,373 174,394 4,052,395 3,300,410 81.44% 78.32%\r\nNov. 3, 1942 4,693,000 2,300,206 1,370,069 150,491 3,820,776 2,264,288 59.26% 48.25%\r\nNov. 7, 1944 P 5,427,000 2,418,965 1,548,395 173,971 4,141,331 3,566,734 86.13% 65.72%\r\nNov. 5, 1946 5,800,000 2,541,720 1,637,246 204,997 4,383,963 2,759,641 62.95% 47.58%\r\nNov. 2, 1948 P 6,106,000 2,892,222 1,908,170 261,605 5,061,997 4,076,981 80.54% 66.77%\r\nNov. 7, 1950 6,458,000 3,062,205 1,944,812 237,820 5,244,837 3,845,757 73.32% 59.55%\r\nNov. 4, 1952 P 7,033,000 3,312,668 2,455,713 229,919 5,998,300 5,209,692 86.85% 74.07%\r\nNov. 2, 1954 7,565,000 3,266,831 2,415,249 203,157 5,885,237 4,101,692 69.69% 54.22%\r\nNov. 6, 1956 P 8,208,000 3,575,635 2,646,249 186,937 6,408,821 5,547,621 86.56% 67.59%\r\nNov. 4, 1958 8,909,000 3,875,630 2,676,565 200,226 6,752,421 5,366,053 79.47% 60.23%\r\nNov. 8, 1960 P 9,587,000 4,295,330 2,926,408 242,888 7,464,626 6,592,591 88.32% 68.77%\r\nNov. 6, 1962 10,305,000 4,289,997 3,002,038 239,176 7,531,211 5,929,602 78.73% 57.54%\r\nNov. 3, 1964 P 10,959,000 4,737,886 3,181,272 264,985 8,184,143 7,233,067 88.38% 66.00%\r\nNov. 8, 1966 11,448,000 4,720,597 3,350,990 269,281 8,340,868 6,605,866 79.20% 57.70%\r\nNov. 5, 1968 P 11,813,000 4,682,661 3,462,131 442,881 8,587,673 7,363,711 85.75% 62.34%\r\nNov. 3, 1970 12,182,000 4,781,282 3,469,046 456,019 8,706,347 6,633,400 76.19% 54.45%\r\nNov. 7, 1972 P 13,322,000 5,864,745 3,840,620 760,850 10,466,215 8,595,950 82.13% 64.52%\r\nNov. 6, 1973 S 13,512,000 5,049,959 3,422,291 617,569 9,089,819 4,329,017 47.62% 32.04%\r\nNov. 5, 1974 13,703,000 5,623,831 3,574,624 729,909 9,928,364 6,364,597 64.11% 46.45%\r\nNov. 2, 1976 P 14,196,000 5,725,718 3,468,439 786,331 9,980,488 8,137,202 81.53% 57.32%\r\nNov. 7, 1978 14,781,000 5,729,959 3,465,384 934,643 10,129,986 7,132,210 70.41% 48.25%\r\nNov. 6, 1979 S 15,083,000 5,594,018 3,406,854 1,006,085 10,006,957 3,740,800 37.38% 24.80%\r\nNov. 4, 1980 P 15,384,000 6,043,262 3,942,768 1,375,593 11,361,623 8,775,459 77.24% 57.04%\r\nNov. 2, 1982 15,984,000 6,150,716 4,029,684 1,378,699 11,559,099 8,064,314 69.78% 50.45%\r\nNov. 6, 1984 P 16,582,000 6,804,263 4,769,129 1,500,238 13,073,630 9,796,375 74.93% 59.08%\r\nNov. 4, 1986 17,561,000 6,524,496 4,912,581 1,396,843 12,833,920 7,617,142 59.35% 43.38%\r\nNov. 8, 1988 P 19,052,000 7,052,368 5,406,127 1,546,378 14,004,873 10,194,539 72.81% 53.51%\r\nNov. 6, 1990 19,245,000 6,671,747 5,290,202 1,516,078 13,478,027 7,899,131 58.61% 41.05%\r\nNov. 3, 1992 P 20,864,000 7,410,914 5,593,555 2,097,004 15,101,473 11,374,565 75.32% 54.52%\r\nNov. 2, 1993 S 20,797,000 7,110,142 5,389,313 2,043,168 14,524,623 5,282,443 36.37% 27.73%\r\nNov. 8, 1994 18,946,000 7,219,635 5,472,391 2,031,758 14,723,784 8,900,593 60.45% 46.98%\r\nNov. 5, 1996 P 19,526,991 7,387,504 5,704,536 2,570,035 15,662,075 10,263,490 65.53% 52.56%\r\nNov. 3, 1998 20,806,462 6,989,006 5,314,912 2,665,267 14,969,185 8,621,121 57.59% 41.43%\r\nNov. 7, 2000 P 21,461,275 7,134,601 5,485,492 3,087,214 15,707,307 11,142,843 70.94% 51.92%\r\nNov. 5, 2002 21,466,274 6,825,400 5,388,895 3,089,174 15,303,469 7,738,821 50.57% 36.05%\r\nOct.  7, 2003 S 21,833,141 6,718,111 5,429,256 3,236,059 15,383,526 9,413,494 61.20% 43.12%\r\nNov. 2, 2004 P 22,075,036 7,120,425 5,745,518 3,691,330 16,557,273 12,589,683 76.04% 57.03%\r\nNov. 8, 2005 S 22,487,768 6,785,188 5,524,609 3,581,685 15,891,482 7,968,757 50.14% 35.44%\r\nNov. 7, 2006 22,652,190 6,727,908 5,436,314 3,672,886 15,837,108 8,899,059 56.19% 39.29%\r\nNov. 4, 2008 P 23,208,710 7,683,495 5,428,052 4,192,544 17,304,091 13,743,177 79.42% 59.22%\r\nMay 19, 2009 S 23,385,819 7,642,108 5,325,558 4,185,346 17,153,012 4,871,945 28.40% 20.80%\r\nHISTORICAL VOTER REGISTRATION AND\r\nPARTICIPATION IN STATEWIDE GENERAL ELECTIONS 1910-2016\r\nVotes CastRegistration\r\n5Election Date Eligible Democratic Republican Other         Total Total Votes\r\nTurnout \r\nRegistered\r\nTurnout \r\nEligible\r\nNov. 2, 2010 23,551,699 7,620,240 5,361,875 4,303,768 17,285,883 10,300,392 59.59% 43.74%\r\nNov. 6, 2012 P 23,802,577 7,966,422 5,356,608 4,922,940 18,245,970 13,202,158 72.36% 55.47%\r\nNov. 4, 2014 24,288,145 7,708,683 5,005,422 5,089,718 17,803,823 7,513,972 42.20% 30.94%\r\nNov. 8, 2016 P 24,875,293 8,720,417 5,048,398 5,642,956 19,411,771 14,610,509 75.27% 58.74%\r\nNotes\r\n* Indicates information not available. \r\nIn 1911, women gained the right to vote in California.\r\nIn 1972, the voting age was lowered from 21 to 18.\r\nRegistration Votes Cast\r\nP indicates a presidential election year.\r\nThe first statewide record of party affiliations was reported in 1922.\r\nHISTORICAL VOTER REGISTRATION AND\r\nPARTICIPATION IN STATEWIDE GENERAL ELECTIONS 1910-2016 (continued)\r\nS indicates a statewide special election.\r\n&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This can be useful for non-tabular content, getting a sense of the document&amp;rsquo;s contents, or troubleshooting the main extraction function (e.g., sometimes there is non-visible text that confuses &lt;code&gt;extract_tables()&lt;/code&gt;). &lt;code&gt;extract_metadata()&lt;/code&gt; returns a list of the PDF&amp;rsquo;s embedded document metadata:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(extract_metadata(tmp))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## List of 10
##  $ pages   : int 2
##  $ title   : chr &amp;quot;Statement of Vote - General Election, November 8, 2016&amp;quot;
##  $ author  : NULL
##  $ subject : chr &amp;quot;Statement of Vote - General Election, November 8, 2016&amp;quot;
##  $ keywords: chr &amp;quot;Statement of Vote - General Election, November 8, 2016&amp;quot;
##  $ creator : chr &amp;quot;Acrobat PDFMaker 11 for Excel&amp;quot;
##  $ producer: chr &amp;quot;Adobe PDF Library 11.0&amp;quot;
##  $ created : chr &amp;quot;Fri Dec 16 18:54:13 GMT 2016&amp;quot;
##  $ modified: chr &amp;quot;Fri Dec 16 18:54:44 GMT 2016&amp;quot;
##  $ trapped : NULL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;make_thumbnails()&lt;/code&gt; function produces images (by default PNG) of pages, which can also be useful for debugging or just for the mundane purpose of image conversion:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;thumb &amp;lt;- make_thumbnails(tmp, pages = 1)
library(&amp;quot;png&amp;quot;)
thispng &amp;lt;- readPNG(thumb, native = TRUE)
d &amp;lt;- get_page_dims(tmp, pages = 1)[[1]]
plot(c(0, d[1]), c(0, d[2]), type = &amp;quot;n&amp;quot;, xlab = &amp;quot;&amp;quot;, ylab = &amp;quot;&amp;quot;, asp = 1)
rasterImage(thispng, 0, 0, d[1], d[2])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/mJZSM3P.png&#34; alt=&#34;plot of chunk example2d&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And, lastly, the &lt;code&gt;split_pdf()&lt;/code&gt; and &lt;code&gt;merge_pdf()&lt;/code&gt; functions can extract specific pages from a PDF or merge multiple PDFs together. Those functions should find multiple uses cases beyond the challenges of working with other peoples&amp;rsquo; data.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;tabulizer&lt;/code&gt; can&amp;rsquo;t solve all your PDF problems. More likely than not you&amp;rsquo;ll at some point encounter a PDF that contains scanned tables or tables that tabula-java&amp;rsquo;s algorithms can&amp;rsquo;t identify well. But for a wide array of well-formatted PDF tables, &lt;code&gt;tabulizer&lt;/code&gt; should provide a much simpler and much faster initial extraction of data than attempting to transcribe their contents manually.&lt;/p&gt;

&lt;h3 id=&#34;contribute&#34;&gt;Contribute&lt;/h3&gt;

&lt;p&gt;As always, the &lt;a href=&#34;https://github.com/ropensci/tabulizer/issues&#34;&gt;issue tracker&lt;/a&gt; on Github is open for suggestions, bug reports, and package support. &lt;a href=&#34;https://github.com/ropensci/tabulizer/pulls&#34;&gt;Pull requests&lt;/a&gt; are always welcome.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve flagged some specific issues on GitHub which interested users might want to help out with. These range from some basic issues:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Identifying and creating &lt;a href=&#34;https://github.com/ropensci/tabulizer/issues/47&#34;&gt;example use cases for the new &lt;code&gt;tabulizer&lt;/code&gt; wiki&lt;/a&gt; to showcase how the package works&lt;/li&gt;
&lt;li&gt;Adding &lt;a href=&#34;https://github.com/ropensci/tabulizer/issues/46&#34;&gt;comprehensive, cross-platform installation instructions&lt;/a&gt; to deal with the various intricacies of Java and rJava on various platforms&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To moderately difficult issues, like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ropensci/tabulizer/issues/49&#34;&gt;Improving the functionality and attractiveness of the Shiny-based &lt;code&gt;extract_areas()&lt;/code&gt; graphical interface&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To more advanced topics that more experienced developers - especially those with Java experience - might be interested in working on:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Improving handling of &lt;a href=&#34;https://github.com/ropensci/tabulizer/issues/10&#34;&gt;non-latin encodings&lt;/a&gt; including adding tests thereof&lt;/li&gt;
&lt;li&gt;Preparing &lt;code&gt;tabulizer&lt;/code&gt; for &lt;a href=&#34;https://github.com/ropensci/tabulizer/issues/48&#34;&gt;the migration of the tabula-java library to PDFBox 2.0&lt;/a&gt;, which will change some of the underlying classes (and methods thereof) that &lt;code&gt;tabulizer&lt;/code&gt; calls from both tabula-java and PDFBox&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Help of any kind on these issues will be very useful for getting the package ready for CRAN release!&lt;/p&gt;

&lt;h3 id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h3&gt;

&lt;p&gt;Many, many thanks to the Tabula team who have done considerable work to make the tabula-java library on which &lt;code&gt;tabulizer&lt;/code&gt; depends. I also want to express considerable thanks to &lt;a href=&#34;https://github.com/davidgohel&#34;&gt;David Gohel&lt;/a&gt; and &lt;a href=&#34;https://github.com/lmullen&#34;&gt;Lincoln Mullen&lt;/a&gt; for their feedback during the &lt;a href=&#34;https://github.com/ropensci/onboarding/issues/42&#34;&gt;rOpenSci onboarding process&lt;/a&gt;, which resulted in numerous improvements to the package and its usability, not least of which is the interactive shiny widget. Thanks, too, to &lt;a href=&#34;https://github.com/sckott&#34;&gt;Scott Chamberlain&lt;/a&gt; for overseeing the review process and to the whole of rOpenSci for their support of the R community.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>

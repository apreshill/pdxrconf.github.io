<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Climate Change on rOpenSci - open tools for open science</title>
    <link>https://ropensci.org/tags/climate-change/</link>
    <description>Recent content in Climate Change on rOpenSci - open tools for open science</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 01 Mar 2017 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://ropensci.org/tags/climate-change/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ccafs - client for CCAFS General Circulation Models data</title>
      <link>https://ropensci.org/technotes/2017/03/01/ccafs-release/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/technotes/2017/03/01/ccafs-release/</guid>
      <description>
        
        

&lt;p&gt;I&amp;rsquo;ve recently released the new package &lt;a href=&#34;https://github.com/ropensci/ccafs&#34;&gt;ccafs&lt;/a&gt;, which provides access
to data from Climate Change, Agriculture and Food Security
(CCAFS; &lt;a href=&#34;http://ccafs-climate.org/&#34;&gt;http://ccafs-climate.org/&lt;/a&gt;) General Circulation Models (GCM) data.
GCM&amp;rsquo;s are a particular type of climate model, used for weather forecasting,
and climate change forecasting - read more at
&lt;a href=&#34;https://en.wikipedia.org/wiki/General_circulation_model&#34;&gt;https://en.wikipedia.org/wiki/General_circulation_model&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ccafs&lt;/code&gt; falls in the data client camp - its focus is on getting users
data - many &lt;a href=&#34;https://ropensci.org/packages/#data_access&#34;&gt;rOpenSci packages&lt;/a&gt;
fall into this area. These kinds of packages are important so that
scientists don&amp;rsquo;t have to recreate the wheel themselves every time, but
instead use one client that everyone else uses.&lt;/p&gt;

&lt;p&gt;CCAFS GCM data files are &lt;code&gt;.zip&lt;/code&gt; files with a bunch of files inside. The
individual files are in ARC ASCII format (&lt;a href=&#34;https://en.wikipedia.org/wiki/Esri_grid#ASCII&#34;&gt;https://en.wikipedia.org/wiki/Esri_grid#ASCII&lt;/a&gt;) -
a plain text data format, but still require painful manipulation/wrangling to
get into an easily consumable format. The files have a &lt;code&gt;.asc&lt;/code&gt; file extension.&lt;/p&gt;

&lt;p&gt;For each &lt;code&gt;.asc&lt;/code&gt; file, the first 6 lines of each file indicate the reference of
the grid (number of columns and rows, corner coordinates, cellsize, and missing
data value), followed by the actual data values, delimited with single
space characters.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a related binary format - but its proprietary, so nevermind.&lt;/p&gt;

&lt;p&gt;The workflow with &lt;code&gt;ccafs&lt;/code&gt; for most users will likely be as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Search for data they want: &lt;code&gt;cc_search()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fetch/download data: &lt;code&gt;cc_data_fetch()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Reaad data: &lt;code&gt;cc_data_read()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;rsquo;ll dive into more details below.&lt;/p&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;First, install the package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;ccafs&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then load &lt;code&gt;ccafs&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;ccafs&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;search-for-data&#34;&gt;Search for data&lt;/h2&gt;

&lt;p&gt;Searching CCAF&amp;rsquo;s data holdings is not as easy as it could be as they don&amp;rsquo;t
provide any programmatic way to do so. However, we provide a way to search
using their web interface from R.&lt;/p&gt;

&lt;p&gt;You can search by the numbers representing each possible value for
each parameter. See the &lt;code&gt;?&#39;ccafs-search&#39;&lt;/code&gt; for help on what the numbers
refer to.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(result1 &amp;lt;- cc_search(file_set = 4, scenario = 6, model = 2, extent = &amp;quot;global&amp;quot;,
  format = &amp;quot;ascii&amp;quot;, period = 5, variable = 2, resolution = 3))
#&amp;gt; [1] &amp;quot;http://gisweb.ciat.cgiar.org/ccafs_climate/files/data/ipcc_4ar_ciat/sres_b1/2040s/bccr_bcm2_0/5min/bccr_bcm2_0_sres_b1_2040s_prec_5min_no_tile_asc.zip&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, you can use the helper list &lt;code&gt;cc_params&lt;/code&gt; where you can reference
options by name; the downside is that this leads to very verbose code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(result2 &amp;lt;- cc_search(file_set = cc_params$file_set$`Delta method IPCC AR4`,
                  scenario = cc_params$scenario$`SRES B1`,
                  model = cc_params$model$bccr_bcm2_0,
                  extent = cc_params$extent$global,
                  format = cc_params$format$ascii,
                  period = cc_params$period$`2040s`,
                  variable = cc_params$variable$Precipitation,
                  resolution = cc_params$resolution$`5 minutes`))
#&amp;gt; [1] &amp;quot;http://gisweb.ciat.cgiar.org/ccafs_climate/files/data/ipcc_4ar_ciat/sres_b1/2040s/bccr_bcm2_0/5min/bccr_bcm2_0_sres_b1_2040s_prec_5min_no_tile_asc.zip&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you already know what you want in terms of file paths, you can query
Amazon S3 directly with &lt;code&gt;cc_list_keys()&lt;/code&gt; (the data file come from Amazon S3):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cc_list_keys(max = 3)
#&amp;gt; # A tibble: 3 Ã— 5
#&amp;gt;                                              Key             LastModified
#&amp;gt;                                            &amp;lt;chr&amp;gt;                    &amp;lt;chr&amp;gt;
#&amp;gt; 1                                         ccafs/ 2014-02-28T15:15:45.000Z
#&amp;gt; 2 ccafs/2014-05-24-01-19-33-3A0DFF1F86F3E7F7.txt 2014-07-01T02:15:51.000Z
#&amp;gt; 3                                 ccafs/amzn.csv 2014-02-28T15:21:32.000Z
#&amp;gt; # ... with 3 more variables: ETag &amp;lt;chr&amp;gt;, Size &amp;lt;chr&amp;gt;, StorageClass &amp;lt;chr&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When using &lt;code&gt;cc_list_keys()&lt;/code&gt;, you&amp;rsquo;ll get not just &lt;code&gt;.zip&lt;/code&gt; files that can be
downloaded, but also directories. So beware that if you&amp;rsquo;re going after grabbing
&amp;ldquo;keys&amp;rdquo; for files that can be downloaded, you&amp;rsquo;re looking for &lt;code&gt;.zip&lt;/code&gt; files.&lt;/p&gt;

&lt;h2 id=&#34;fetch-and-read-data&#34;&gt;Fetch and read data&lt;/h2&gt;

&lt;p&gt;Once you get links from &lt;code&gt;cc_search()&lt;/code&gt; or &amp;ldquo;keys&amp;rdquo; from &lt;code&gt;cc_list_keys()&lt;/code&gt;, you
can pass either to &lt;code&gt;cc_data_fetch()&lt;/code&gt; - which normalizes the input - so it
doesn&amp;rsquo;t matter whether you pass in e.g.,&lt;/p&gt;

&lt;p&gt;&lt;code&gt;http://gisweb.ciat.cgiar.org/ccafs_climate/files/data/ipcc_4ar_ciat/&lt;/code&gt;
&lt;code&gt;sres_b1/2040s/bccr_bcm2_0/5min/bccr_bcm2_0_sres_b1_2040s_prec_5min_no_tile_asc.zip&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ccafs_climate/files/data/ipcc_4ar_ciat/sres_b1/2040s/bccr_bcm2_0/5min/&lt;/code&gt;
&lt;code&gt;bccr_bcm2_0_sres_b1_2040s_prec_5min_no_tile_asc.zip&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s download data with &lt;code&gt;cc_data_fetch()&lt;/code&gt; using the result we got above
using &lt;code&gt;cc_search()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;xx &amp;lt;- cc_data_fetch(result2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we can read data with &lt;code&gt;cc_data_read()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(dat &amp;lt;- cc_data_read(xx))
#&amp;gt; class       : RasterStack
#&amp;gt; dimensions  : 1800, 4320, 7776000, 12  (nrow, ncol, ncell, nlayers)
#&amp;gt; resolution  : 0.08333333, 0.08333333  (x, y)
#&amp;gt; extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
#&amp;gt; coord. ref. : NA
#&amp;gt; names       :      prec_1,     prec_10,     prec_11,     prec_12,      prec_2,      prec_3,      prec_4,      prec_5,      prec_6,      prec_7,      prec_8,      prec_9
#&amp;gt; min values  : -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648, -2147483648
#&amp;gt; max values  :  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647,  2147483647
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which gives a &lt;code&gt;raster&lt;/code&gt; class object, which you are likely familiar with - which
opens up all the tools that deal with &lt;code&gt;raster&lt;/code&gt; class objects, yay!&lt;/p&gt;

&lt;p&gt;You can easily plot the data with the &lt;code&gt;plot&lt;/code&gt; method from the  &lt;code&gt;raster&lt;/code&gt; package.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;raster&amp;quot;)
plot(dat)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-03-01-ccafs-release/unnamed-chunk-9-1.png&#34; alt=&#34;plot&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;caching&#34;&gt;Caching&lt;/h2&gt;

&lt;p&gt;For a better user experience, we cache files for you. That means
when we download data, we put the files in a known location. When a
user tries to download the same data again, we look to see if it&amp;rsquo;s already
been downloaded, and use the cached version - if we don&amp;rsquo;t have it
already, we download it.&lt;/p&gt;

&lt;p&gt;Of course, CCAFS may change their files, so you may not want the cached
version, but the new version from them. We provide tools to inspect your
cached files, and delete them.&lt;/p&gt;

&lt;p&gt;List your cached files:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cc_cache_list()
#&amp;gt;   [1] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc&amp;quot;
#&amp;gt;   [2] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc.zip&amp;quot;
#&amp;gt;   [3] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_1.asc&amp;quot;
#&amp;gt;   [4] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_10.asc&amp;quot;
#&amp;gt;   [5] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_11.asc&amp;quot;
#&amp;gt;   [6] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_12.asc&amp;quot;
#&amp;gt;   [7] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_13.asc&amp;quot;
#&amp;gt;   [8] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_14.asc&amp;quot;
#&amp;gt;   [9] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_15.asc&amp;quot;
#&amp;gt;  [10] &amp;quot;/Users/sacmac/Library/Caches/ccafs/bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc/bio_16.asc&amp;quot;
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get details on all files or a specific file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# cc_cache_details() # details for all files
cc_cache_details(cc_cache_list()[1])
#&amp;gt; &amp;lt;ccafs cached files&amp;gt;
#&amp;gt;   directory: /Users/sacmac/Library/Caches/ccafs
#&amp;gt;
#&amp;gt;   file: /bcc_csm1_1_m_rcp2_6_2030s_bio_10min_r1i1p1_no_tile_asc
#&amp;gt;   size: 0.001 mb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Be careful with &lt;code&gt;cc_cache_delete_all()&lt;/code&gt; as you will delete all your cached
files.&lt;/p&gt;

&lt;h2 id=&#34;ccafs-software-review&#34;&gt;ccafs software review&lt;/h2&gt;

&lt;p&gt;I want to touch briefly on the software review for this package. The reviews
for &lt;code&gt;ccafs&lt;/code&gt; were great, and I think the package was greatly improved via the
review process.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/mikoontz&#34;&gt;Michael Koontz&lt;/a&gt; and &lt;a href=&#34;https://github.com/manuramon&#34;&gt;Manuel Ramon&lt;/a&gt;
did reviews for &lt;code&gt;ccafs&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;One thing in particular that improved about &lt;code&gt;ccafs&lt;/code&gt; was the user interface -
that is, the programmatic interface. One feature about the interface was
adding the &lt;code&gt;cc_search()&lt;/code&gt; function. When I started developing &lt;code&gt;ccafs&lt;/code&gt;, I didn&amp;rsquo;t
see a way to programmatically search CCAFS data - other than the Amazon S3
data, which isn&amp;rsquo;t really search, but more like listing files in a directory -
so I just left it at that. During the reviews, reviewers wanted a clear workflow
for potential users - the package as submitted for review didn&amp;rsquo;t really have a
clear workflow; it was&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Know what you want already (&lt;code&gt;cc_list_keys&lt;/code&gt; helped get real paths at least)&lt;/li&gt;
&lt;li&gt;Download data&lt;/li&gt;
&lt;li&gt;Read data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Which is not ideal. There should be a discovery portion to the workflow. So
I decided to dig into possibly querying the CCAFS web portal itself. That panned
out, and the workflow we have now is much better:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Search for data with all the same variables you would on the CCAFS website&lt;/li&gt;
&lt;li&gt;Download data&lt;/li&gt;
&lt;li&gt;Read data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is much better!&lt;/p&gt;

&lt;p&gt;As always, reviews improved the documentation a lot by pointing out areas that
could use improvement - which all users will greatly benefit from.&lt;/p&gt;

&lt;p&gt;A new vignette (&lt;a href=&#34;https://cran.rstudio.com/web/packages/ccafs/vignettes/amazon_s3_keys.html&#34;&gt;https://cran.rstudio.com/web/packages/ccafs/vignettes/amazon_s3_keys.html&lt;/a&gt;)
was added in the review process to explain how to get a &amp;ldquo;key&amp;rdquo;, a URL for CCAFS data.&lt;/p&gt;

&lt;h2 id=&#34;to-do-and-feedback&#34;&gt;To Do and Feedback&lt;/h2&gt;

&lt;p&gt;There&amp;rsquo;s probably lots of improvements that can be made - I&amp;rsquo;m looking forward
to getting feedback from users on any bugs or feature requests. One immediate
thing is to &lt;a href=&#34;https://github.com/ropensci/ccafs/issues/22&#34;&gt;make the cache details more compact&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Overlaying species occurrence data with climate data</title>
      <link>https://ropensci.org/blog/2014/04/22/rwbclimate-sp/</link>
      <pubDate>Tue, 22 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/04/22/rwbclimate-sp/</guid>
      <description>
        
        &lt;p&gt;One of the goals of the rOpenSci is to facilitate interoperability between different data sources around web with our tools.  We can achieve this by providing functionality within our packages that converts data coming down via web APIs in one format (often a provider specific schema) into a standard format.  The new version of &lt;a href=&#34;http://github.com/ropensci/rwbclimate&#34;&gt;rWBclimate&lt;/a&gt; that we just posted to &lt;a href=&#34;http://cran.r-project.org/web/packages/rWBclimate/index.html&#34;&gt;CRAN&lt;/a&gt; does just that.  In an &lt;a href=&#34;http://www.ropensci.org/blog/2013/07/29/rWBclimate-rgbif/&#34;&gt;earlier post&lt;/a&gt; I wrote about how users could combine data from both &lt;a href=&#34;http://github.com/ropensci/rgbif&#34;&gt;rgbif&lt;/a&gt; and &lt;code&gt;rWBclimate&lt;/code&gt;. Back then I just thought it was pretty cool that you could overlay the points on a nice climate map.  Now we&amp;rsquo;ve come a long way, with the development of an easier to use and more comprehensive package for accessing species occurrence data, &lt;a href=&#34;http://github.com/ropensci/spocc&#34;&gt;spocc&lt;/a&gt;, and added conversion functions to create spatial objects out of both climate data maps, and species occurrence data.  The result is that you can grab data from both sources, and then extract climate information about your species occurrence data.&lt;/p&gt;

&lt;p&gt;In the example below I&amp;rsquo;m going to download climate data at the basin level for the US and Mexico, and then species occurrences for eight different tree species.  I&amp;rsquo;ll then extract the temperature from each point data with an spatial overlay and look at the distribution of temperatures for each species.  Furthermore the conversion to spatial objects functions will allow you to use our data with any &lt;a href=&#34;http://en.wikipedia.org/wiki/Shapefile&#34;&gt;shape files&lt;/a&gt; you might have.&lt;/p&gt;

&lt;p&gt;The first step is to grab the &lt;a href=&#34;https://developers.google.com/kml/documentation/&#34;&gt;KML&lt;/a&gt; files for each river basin making up the US and Mexico, which we &lt;a href=&#34;http://data.worldbank.org/sites/default/files/climate_data_api_basins.pdf&#34;&gt;identify with an integer&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
library(&amp;quot;rWBclimate&amp;quot;)
# Install spocc from our GitHub repo
# devtools::install_github(&amp;quot;spocc&amp;quot;, &amp;quot;ropensci&amp;quot;)
library(&amp;quot;spocc&amp;quot;)
library(&amp;quot;taxize&amp;quot;)
library(&amp;quot;plyr&amp;quot;)
library(&amp;quot;sp&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(spocc)
### Create path to store kml&#39;s
dir.create(&amp;quot;~/kmltmp&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;options(kmlpath = &amp;quot;~/kmltmp&amp;quot;)
options(stringsAsFactors = FALSE)

usmex &amp;lt;- c(273:284, 328:365)
### Download KML&#39;s and read them in.
usmex.basin &amp;lt;- create_map_df(usmex)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;

## Download temperature data
temp.dat &amp;lt;- get_historical_temp(usmex, &amp;quot;decade&amp;quot;)
temp.dat &amp;lt;- subset(temp.dat, temp.dat$year == 2000)


# Bind temperature data to map data frame

usmex.map.df &amp;lt;- climate_map(usmex.basin, temp.dat, return_map = F)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have created a map of the US and Mexico, downloaded the average temperature in each basin between 1990 and 2000, and bound them together.  Next let&amp;rsquo;s grab occurrence data using &lt;code&gt;spocc&lt;/code&gt; for our eight tree species (&lt;em&gt;Note:  &lt;code&gt;rgbif&lt;/code&gt; &amp;gt; 0.6.0 needs to be installed to work properly&lt;/em&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
## Grab some species occurrence data for the 8 tree species.

splist &amp;lt;- c(&amp;quot;Acer saccharum&amp;quot;, &amp;quot;Abies balsamea&amp;quot;, &amp;quot;Arbutus xalapensis&amp;quot;, &amp;quot;Betula alleghaniensis&amp;quot;, &amp;quot;Chilopsis linearis&amp;quot;, &amp;quot;Conocarpus erectus&amp;quot;, &amp;quot;Populus tremuloides&amp;quot;, &amp;quot;Larix laricina&amp;quot;)

## get data from bison and gbif
splist &amp;lt;- sort(splist)
out &amp;lt;- occ(query = splist, from = c(&amp;quot;bison&amp;quot;, &amp;quot;gbif&amp;quot;), limit = 100)

## scrub names
out &amp;lt;- fixnames(out, how = &amp;quot;query&amp;quot;)

## Create a data frame of all data.

out_df &amp;lt;- occ2df(out)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we&amp;rsquo;ve downloaded the data using their latin names, we might want to know the common names.  Luckily the &lt;code&gt;taxize&lt;/code&gt; package is great for that, and we can grab them with just a couple of lines of code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
### grab common names
cname &amp;lt;- ldply(sci2comm(get_tsn(splist), db = &amp;quot;itis&amp;quot;, simplify = TRUE), function(x) { return(x[1]) })[, 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;### Now let&#39;s create a vector of common names for easy plotting But first
### order on names so we can just add the names
out_df &amp;lt;- out_df[order(out_df$name), ]
### strip NA values and 0 values of coordinates
out_df &amp;lt;- out_df[!is.na(out_df$lat), ]
out_df &amp;lt;- out_df[out_df$lat &amp;gt; 0, ]
out_df$common &amp;lt;- rep(cname, table(out_df$name))

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have all the components we need, species data and spatial polygons with temperature data bound to them.  Before we do the spatial over lay, let&amp;rsquo;s have do a quick visualization.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
## Now just create the base temperature map
usmex.map &amp;lt;- ggplot() +
  geom_polygon(data = usmex.map.df, aes(x = long, y = lat, group = group, fill = data, alpha = 0.9)) +
  scale_fill_continuous(&amp;quot;Average annual \n temp: 1990-2000&amp;quot;, low = &amp;quot;yellow&amp;quot;, high = &amp;quot;red&amp;quot;) +
  guides(alpha = F) +
  theme_bw(10)

## And overlay of gbif data
usmex.map &amp;lt;- usmex.map +
  geom_point(data = out_df, aes(y = latitude, x = longitude, group = common, colour = common)) +
  xlim(-125, -59) +
  ylim(5, 55)

print(usmex.map)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-04-22-rwbclimate-sp/mapping_2.png&#34; alt=&#34;plot of chunk mapping&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now the question is, what&amp;rsquo;s the temperature at each point for each tree species?  We can convert our species data to spatial points with &lt;code&gt;occ_to_sp&lt;/code&gt;, and our data from &lt;code&gt;rWBclimate&lt;/code&gt; can be converted to spatial polygons with &lt;code&gt;kml_to_sp&lt;/code&gt;.  Next we can loop through each grouping of species, and call the &lt;code&gt;over&lt;/code&gt; function to get the temperature at each point.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Create a spatial polygon dataframe binding kml polygons to temperature
## data
temp_sdf &amp;lt;- kml_to_sp(usmex.basin, df = temp.dat)
### Now we can change the points to a spatial polygon:
sp_points &amp;lt;- occ_to_sp(out)

tdat &amp;lt;- vector()
### Get averages
for (i in 1:length(splist)) {
    tmp_sp &amp;lt;- sp_points[which(sp_points$name == splist[i]), ]
    tmp_t &amp;lt;- over(tmp_sp, temp_sdf)$data
    tdat &amp;lt;- c(tdat, tmp_t)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last step is to create a new data frame with our data.  Unfortunately the size of our old data frame &lt;code&gt;out_df&lt;/code&gt; won&amp;rsquo;t be the same size due to some invalid lat/long&amp;rsquo;s that came down with our data so the entire data frame will be reassembled.  After we assemble the data frame we can summarize our it with plyr, getting the mean temperature and latitude for each species.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
### Assemble new dataframe
spDF &amp;lt;- data.frame(matrix(nrow = dim(sp_points)[1], ncol = 0))
spDF$species &amp;lt;- sp_points$name
spDF &amp;lt;- cbind(coordinates(sp_points), spDF)

### This is important, be sure to order all the points alphebetically as we
### did earlier
spDF &amp;lt;- spDF[order(spDF$species), ]

spDF$cname &amp;lt;- rep(cname, table(sp_points$name))
spDF$temp &amp;lt;- tdat
### Strip NA&#39;s
spDF &amp;lt;- spDF[!is.na(spDF$temp), ]

## Create summary
summary_data &amp;lt;- ddply(spDF, .(cname), summarise, mlat = mean(latitude), mtemp = mean(temp),
    sdlat = sd(latitude), sdtemp = sd(temp))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First let&amp;rsquo;s look at a plot of mean temperature vs latititude, and to identify the points we&amp;rsquo;ll plot their common names.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(summary_data, aes(x = mlat, y = mtemp, label = cname)) +
  geom_text() +
  xlab(&amp;quot;Mean Latitude&amp;quot;) +
  ylab(&amp;quot;Mean Temperature (C)&amp;quot;) +
  theme_bw() +
  xlim(10, 50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-04-22-rwbclimate-sp/means.png&#34; alt=&#34;plot of chunk means&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This gives us a sense about how the means of each value are related, but we can also look at the distribution of temperatures with boxplots.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(spDF, aes(as.factor(cname), temp)) +
  geom_boxplot() +
  theme_bw(13) +
  ylab(&amp;quot;Temperature&amp;quot;) +
  xlab(&amp;quot;Common Name&amp;quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-04-22-rwbclimate-sp/boxplots.png&#34; alt=&#34;plot of chunk boxplots&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This gives a sense of how wide the temperature distributions are, as well as looking at some of the outliers.  The distributions look pretty skewed, and this probably reflects the large spatial granularity of our temperature data compared to the occurrence data.  However this example shows how you can easily combine data from multiple rOpenSci packages.  We will continue to work towards enhancing the interoperability of heterogeneous data streams via our tools.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Working with climate data from the web in R</title>
      <link>https://ropensci.org/blog/2013/08/18/sciordata/</link>
      <pubDate>Sun, 18 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2013/08/18/sciordata/</guid>
      <description>
        
        

&lt;p&gt;I recently attended &lt;a href=&#34;http://scioclimate.wikispaces.com&#34;&gt;ScienceOnline Climate&lt;/a&gt;, a conference in Washington, D.C. at AAAS. You may have heard of the &lt;a href=&#34;https://twitter.com/#sciox&#34;&gt;ScienceOnline annual meeting in North Carolina&lt;/a&gt; - this was one of their topical meetings focused on Climate Change. I moderated a session on &lt;a href=&#34;http://scioclimate.wikispaces.com/3W.+Working+With+Science+Data+From+Around+The+Web&#34;&gt;working with data from the web in R&lt;/a&gt;, focusing on climate data. Search Twitter for #scioClimate for tweets from the conference, and #sciordata for tweets from the session I ran. The following is an abbreviated demo of what I did in the workshop showing some of what you can do with climate data in R using our packages.&lt;/p&gt;

&lt;p&gt;Before digging in, why would you want to get climate data programatically vs. via pushing buttons in a browser? Learning a programming language can take some time - we all already know how to use browsers. So why?!  First, getting data programatically, especially in R (or Python), allows you to then easily do other stuff, like manipulate data, visualize, and analyze data. Second, if you do your work programatically, &lt;strong&gt;you&lt;/strong&gt; and &lt;em&gt;others&lt;/em&gt; can reproduce, and extend, the work you did with little extra effort. Third, programatically getting data makes tasks that are repetitive and slow, fast and easy - you can&amp;rsquo;t easily automate button clicks in a browser. Fourth, you can combine code with writing to make your entire workflow reproducible, whether it&amp;rsquo;s notes, a blog post, or even a research article.&lt;/p&gt;

&lt;h2 id=&#34;interactive-visualizations-in-r&#34;&gt;Interactive visualizations in R&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s start off with something shiny. The majority of time I make static visualizations, which are great for me to look at during analyses, and for publications of research findings in PDFs. However, static visualizations don&amp;rsquo;t take advantage of the interactive nature of the web. Ramnath Vaidyanathan has developed an R package, &lt;a href=&#34;https://github.com/ramnathv/rCharts&#34;&gt;rCharts&lt;/a&gt;, to generate dynamic Javascript visualizations directly from R that can be used interactively in a browser. Here is an example visualizing a dataset that comes with R.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(devtools)
install_github(&amp;quot;rCharts&amp;quot;, &amp;quot;ramnathv&amp;quot;)
library(rCharts)

# Load a data set
hair_eye_male &amp;lt;- subset(as.data.frame(HairEyeColor), Sex == &amp;quot;Male&amp;quot;)

# Make a javascript plot object
n1 &amp;lt;- nPlot(Freq ~ Hair, group = &amp;quot;Eye&amp;quot;, data = hair_eye_male, type = &amp;quot;multiBarChart&amp;quot;)

# Visualize
n1$show(cdn = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Check out the output &lt;a href=&#34;http://sckott.github.io/vis/nvd3_eg.html&#34;&gt;here&lt;/a&gt;. If you like you can take the source code from the visualization (right click on select &lt;em&gt;View Page Source&lt;/em&gt;) and put it in your html files, and you&amp;rsquo;re good to go (as long as you have dependencies, etc.) - quicker than learning &lt;a href=&#34;http://d3js.org/&#34;&gt;d3&lt;/a&gt; and company from scratch, eh. This is a super simple example, but you can imagine the possibilities.&lt;/p&gt;

&lt;h2 id=&#34;the-data-itself&#34;&gt;The data itself&lt;/h2&gt;

&lt;h3 id=&#34;first-install-some-packages-these-are-all-just-on-github-so-you-need-to-have-devtools-installed&#34;&gt;First, install some packages - these are all just on Github, so you need to have devtools installed&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(devtools)
install_github(&amp;quot;govdat&amp;quot;, &amp;quot;sckott&amp;quot;)
install_github(&amp;quot;rnoaa&amp;quot;, &amp;quot;ropensci&amp;quot;)
install_github(&amp;quot;rWBclimate&amp;quot;, &amp;quot;ropensci&amp;quot;)
install_github(&amp;quot;rnpn&amp;quot;, &amp;quot;ropensci&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;politicians-talk-sunlight-foundation-listens&#34;&gt;Politicians talk - Sunlight Foundation listens&lt;/h3&gt;

&lt;h4 id=&#34;look-at-mentions-of-the-phrase-climate-change-in-congress-using-the-govdat-package&#34;&gt;Look at mentions of the phrase &amp;ldquo;climate change&amp;rdquo; in congress, using the govdat package&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(govdat)
library(ggplot2)

# Get mentions of climate change from Democrats
dat_d &amp;lt;- sll_cw_timeseries(phrase = &amp;quot;climate change&amp;quot;, party = &amp;quot;D&amp;quot;)

# Add a column that says this is data from deomcrats
dat_d$party &amp;lt;- rep(&amp;quot;D&amp;quot;, nrow(dat_d))

# Get mentions of climate change from Democrats
dat_r &amp;lt;- sll_cw_timeseries(phrase = &amp;quot;climate change&amp;quot;, party = &amp;quot;R&amp;quot;)

# Add a column that says this is data from republicans
dat_r$party &amp;lt;- rep(&amp;quot;R&amp;quot;, nrow(dat_r))

# Put two tables together
dat_both &amp;lt;- rbind(dat_d, dat_r)

# Plot data
ggplot(dat_both, aes(day, count, colour = party)) + theme_grey(base_size = 20) +
    geom_line() + scale_colour_manual(values = c(&amp;quot;blue&amp;quot;, &amp;quot;red&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2013-08-17-sciordata/govdat.png&#34; alt=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;noaa-climate-data-using-the-rnoaa-package&#34;&gt;NOAA climate data, using the rnoaa package&lt;/h3&gt;

&lt;h4 id=&#34;map-sea-ice-for-12-years-for-april-only-for-the-north-pole&#34;&gt;Map sea ice for 12 years, for April only, for the North pole&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rnoaa)
library(scales)
library(ggplot2)
library(doMC)
library(plyr)

# Get URLs for data
urls &amp;lt;- seaiceeurls(mo = &amp;quot;Apr&amp;quot;, pole = &amp;quot;N&amp;quot;)[1:12]

# Download sea ice data
registerDoMC(cores = 4)
out &amp;lt;- llply(urls, noaa_seaice, storepath = &amp;quot;~/seaicedata&amp;quot;, .parallel = TRUE)

# Name elements of list
names(out) &amp;lt;- seq(1979, 1990, 1)

# Make a data.frame
df &amp;lt;- ldply(out)

# Plot data
ggplot(df, aes(long, lat, group = group)) + geom_polygon(fill = &amp;quot;steelblue&amp;quot;) +
    theme_ice() + facet_wrap(~.id)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2013-08-17-sciordata/seaice2.png&#34; alt=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;world-bank-climate-data-using-the-rwbclimate-package&#34;&gt;World Bank climate data, using the rWBclimate package&lt;/h3&gt;

&lt;h4 id=&#34;plotting-annual-data-for-different-countries&#34;&gt;Plotting annual data for different countries&lt;/h4&gt;

&lt;p&gt;Data can be extracted from countries or basins submitted as vectors. Here we will plot the expected temperature anomaly for each 20 year period over a baseline control period of 1961-2000. These countries chosen span the north to south pole. It&amp;rsquo;s clear from the plot that the northern most countries (US and Canada) have the biggest anomaly, and Belize, the most equatorial country, has the smallest anomaly.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rWBclimate)

# Search for data
country.list &amp;lt;- c(&amp;quot;CAN&amp;quot;, &amp;quot;USA&amp;quot;, &amp;quot;MEX&amp;quot;, &amp;quot;BLZ&amp;quot;, &amp;quot;ARG&amp;quot;)
country.dat &amp;lt;- get_model_temp(country.list, &amp;quot;annualanom&amp;quot;, 2010, 2100)

# Subset data to one specific model
country.dat.bcc &amp;lt;- country.dat[country.dat$gcm == &amp;quot;bccr_bcm2_0&amp;quot;, ]

# Exclude A2 scenario
country.dat.bcc &amp;lt;- subset(country.dat.bcc, country.dat.bcc$scenario != &amp;quot;a2&amp;quot;)

# Plot data
ggplot(country.dat.bcc, aes(x = fromYear, y = data, group = locator, colour = locator)) +
    geom_point() + geom_path() + ylab(&amp;quot;Temperature anomaly over baseline&amp;quot;) +
    theme_bw(base_size = 20)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2013-08-17-sciordata/unnamed-chunk-1.png&#34; alt=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;phenology-data-from-the-usa-national-phenology-network-using-rnpn&#34;&gt;Phenology data from the USA National Phenology Network, using rnpn&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rnpn)

# Lookup names
temp &amp;lt;- lookup_names(name = &amp;quot;bird&amp;quot;, type = &amp;quot;common&amp;quot;)
comnames &amp;lt;- temp[temp$species_id %in% c(357, 359, 1108), &amp;quot;common_name&amp;quot;]

# Get some data
out &amp;lt;- getobsspbyday(speciesid = c(357, 359, 1108), startdate = &amp;quot;2010-04-01&amp;quot;,
    enddate = &amp;quot;2013-09-31&amp;quot;)
names(out) &amp;lt;- comnames
df &amp;lt;- ldply(out)
df$date &amp;lt;- as.Date(df$date)

# Visualize data
library(ggplot2)
ggplot(df, aes(date, count)) + geom_line() + theme_grey(base_size = 20) + facet_grid(.id ~
    .)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2013-08-17-sciordata/rnpn.png&#34; alt=&#34;center&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;feedback-and-new-climate-data-sources&#34;&gt;Feedback and new climate data sources&lt;/h3&gt;

&lt;p&gt;Do use the above pacakges (&lt;a href=&#34;https://github.com/sckott/govdat&#34;&gt;govdat&lt;/a&gt;, &lt;a href=&#34;https://github.com/ropensci/rnoaa&#34;&gt;rnoaa&lt;/a&gt;, &lt;a href=&#34;https://github.com/ropensci/rWBclimate&#34;&gt;rWBclimate&lt;/a&gt;, and &lt;a href=&#34;https://github.com/ropensci/rnpn&#34;&gt;rnpn&lt;/a&gt;) to get climate data, and get in touch with bug reports, and feature requests.&lt;/p&gt;

&lt;p&gt;Surely there are other sources of climate data out there that you want to use in R, right? Let us know what else you want to use. Better yet, if you can sling some R code, start writing your own package to interact with a source of climate data on the web - we can lend a hand.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>

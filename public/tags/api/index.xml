<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Api on rOpenSci - open tools for open science</title>
    <link>https://ropensci.org/tags/api/</link>
    <description>Recent content in Api on rOpenSci - open tools for open science</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 05 Dec 2017 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://ropensci.org/tags/api/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Exploratory Data Analysis of Ancient Texts with rperseus</title>
      <link>https://ropensci.org/blog/2017/12/05/rperseus/</link>
      <pubDate>Tue, 05 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2017/12/05/rperseus/</guid>
      <description>
        
        

&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;When I was in grad school at Emory, I had a favorite desk in the library. The desk wasn’t particularly cozy or private, but what it lacked in comfort it made up for in real estate. My books and I needed room to operate. Students of the ancient world require many tools, and when jumping between commentaries, lexicons, and interlinears, additional clutter is additional “friction”, i.e., lapses in thought due to frustration. Technical solutions to this clutter exist, but the best ones are proprietary and expensive. Furthermore, they are somewhat inflexible, and you may have to shoehorn your thoughts into their framework. More friction.&lt;/p&gt;

&lt;p&gt;Interfacing with &lt;a href=&#34;http://www.perseus.tufts.edu/hopper/&#34;&gt;the Perseus Digital Library&lt;/a&gt; was a popular online alternative. The library includes a catalog of classical texts, a Greek and Latin lexicon, and a word study tool for appearances and references in other literature. If the university library’s reference copies of BDAG&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; and &lt;em&gt;Synopsis Quattuor Evangeliorum&lt;/em&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; were unavailable, Perseus was our next best thing.&lt;/p&gt;

&lt;p&gt;Fast forward several years, and I’ve abandoned my quest to become a biblical scholar. Much to my father’s dismay, I’ve learned writing code is more fun than writing exegesis papers. Still, I enjoy dabbling with dead languages, and it was the desire to wed my two loves, biblical studies and R, that birthed my latest package, &lt;code&gt;rperseus&lt;/code&gt;. The goal of this package is to furnish classicists with texts of the ancient world and a toolkit to unpack them.&lt;/p&gt;

&lt;h3 id=&#34;exploratory-data-analysis-in-biblical-studies&#34;&gt;Exploratory Data Analysis in Biblical Studies&lt;/h3&gt;

&lt;p&gt;Working with the Perseus Digital Library was already a trip down memory lane, but here’s an example of how I would have leveraged &lt;code&gt;rperseus&lt;/code&gt; many years ago.&lt;/p&gt;

&lt;p&gt;My best papers often sprung from the outer margins of my &lt;a href=&#34;https://en.wikipedia.org/wiki/Novum_Testamentum_Graece&#34;&gt;&lt;em&gt;Nestle-Aland Novum Testamentum Graece.&lt;/em&gt;&lt;/a&gt; Here the editors inserted cross references to parallel vocabulary, themes, and even grammatical constructions. Given the intertextuality of biblical literature, the margins are a rich source of questions: Where else does the author use similar vocabulary? How is the source material used differently? Does the literary context affect our interpretation of a particular word? This is exploratory data analysis in biblical studies.&lt;/p&gt;

&lt;p&gt;Unfortunately the excitement of your questions is incommensurate with the tedium of the process&amp;ndash;EDA continues by flipping back and forth between books, dog-earring pages, and avoiding paper cuts. &lt;code&gt;rperseus&lt;/code&gt; aims to streamline this process with two functions: &lt;code&gt;get_perseus_text&lt;/code&gt; and &lt;code&gt;perseus_parallel&lt;/code&gt;. The former returns a data frame containing the text from any work in the Perseus Digital Library, and the latter renders a parallel in &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Suppose I am writing a paper on different expressions of love in Paul’s letters. Naturally, I start in 1 Corinthians 13, the famed “Love Chapter” often heard at weddings and seen on bumper stickers. I finish the chapter and turn to the margins. In the image below, I see references to Colossians 1:4, 1 Thessalonians 1:3, 5:8, Hebrews 10:22-24, and Romans 8:35-39.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/img/blog-images/2017-12-05-rperseus/nantg.png&#34; alt=&#34;&#34; /&gt;
&lt;em&gt;1 Corinithians 13 in Nestle-Aland Novum Testamentum Graece&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Ignoring that some scholars exclude Colossians from the “authentic” letters, let’s see the references alongside each other:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rperseus) #devtools::install_github(“ropensci/rperseus”)
library(tidyverse)

tribble(
  ~label, ~excerpt,
  &amp;quot;Colossians&amp;quot;, &amp;quot;1.4&amp;quot;,
  &amp;quot;1 Thessalonians&amp;quot;, &amp;quot;1.3&amp;quot;,
  &amp;quot;1 Thessalonians&amp;quot;, &amp;quot;5.8&amp;quot;,
  &amp;quot;Romans&amp;quot;, &amp;quot;8.35-8.39&amp;quot;
  ) %&amp;gt;% 
  left_join(perseus_catalog) %&amp;gt;%
  filter(language == &amp;quot;grc&amp;quot;) %&amp;gt;%
  select(urn, excerpt) %&amp;gt;%
  pmap_df(get_perseus_text) %&amp;gt;%
  perseus_parallel(words_per_row = 4)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/img/blog-images/2017-12-05-rperseus/Parallel1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A brief explanation: First, I specify the labels and excerpts within a tibble. Second, I join the lazily loaded &lt;code&gt;perseus_catalog&lt;/code&gt; onto the data frame. Third, I filter for the Greek&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; and select the columns containing the arguments required for &lt;code&gt;get_perseus_text&lt;/code&gt;. Fourth, I map over each urn and excerpt, returning another data frame. Finally, I pipe the output into &lt;code&gt;perseus_parallel&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The key word shared by each passage is &lt;em&gt;agape&lt;/em&gt; (“love”). Without going into detail, it might be fruitful to consider the references alongside each other, pondering how the semantic range of &lt;em&gt;agape&lt;/em&gt; expands or contracts within the Pauline corpus. Paul had a penchant for appropriating and recasting old ideas&amp;ndash;often in slippery and unexpected ways&amp;ndash;and your Greek lexicon provides a mere approximation. In other words, how can we move from the dictionary definition of &lt;em&gt;agape&lt;/em&gt; towards Paul&amp;rsquo;s unique vision?&lt;/p&gt;

&lt;p&gt;If your Greek is rusty, you can parse each word with &lt;code&gt;parse_excerpt&lt;/code&gt; by locating the text&amp;rsquo;s urn within the &lt;code&gt;perseus_catalog&lt;/code&gt; object.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;parse_excerpt(urn = &amp;quot;urn:cts:greekLit:tlg0031.tlg012.perseus-grc2&amp;quot;, excerpt = &amp;quot;1.4&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;word&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;form&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;verse&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;part_of_speech&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;person&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;number&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;tense&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;mood&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;voice&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;gender&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;case&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;degree&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ἀκούω&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ἀκούσαντες&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;verb&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;plural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;aorist&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;participle&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;active&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;masculine&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;nominative&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ὁ&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;τὴν&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;article&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;singular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;feminine&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;accusative&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;πίστις&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;πίστιν&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;noun&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;singular&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;feminine&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;accusative&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;ὑμός&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ὑμῶν&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;pronoun&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;plural&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;masculine&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;genative&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If your Greek is &lt;em&gt;really&lt;/em&gt; rusty, you can also flip the &lt;code&gt;language&lt;/code&gt; filter to “eng” to view an older English translation.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; And if the margin references a text from the Old Testament, you can call the Septuagint as well as the original Hebrew.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:5&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tribble(
  ~label, ~excerpt,
  &amp;quot;Genesis&amp;quot;, &amp;quot;32.31&amp;quot;,
  &amp;quot;Genesis, pointed&amp;quot;, &amp;quot;32.31&amp;quot;,
  &amp;quot;Numeri&amp;quot;, &amp;quot;12.8&amp;quot;,
  &amp;quot;Numbers, pointed&amp;quot;, &amp;quot;12.8&amp;quot;
  ) %&amp;gt;% 
  left_join(perseus_catalog) %&amp;gt;%
  filter(language %in% c(&amp;quot;grc&amp;quot;, &amp;quot;hpt&amp;quot;)) %&amp;gt;%
  select(urn, excerpt) %&amp;gt;%
  pmap_df(get_perseus_text) %&amp;gt;%
  perseus_parallel()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/img/blog-images/2017-12-05-rperseus/Parallel2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Admittedly, there is some “friction” here in joining the &lt;code&gt;perseus_catalog&lt;/code&gt; onto the initial tibble. There is a learning curve with getting acquainted with the idiosyncrasies of the catalog object. A later release will aim to streamline this workflow.&lt;/p&gt;

&lt;h3 id=&#34;future-work&#34;&gt;Future Work&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://ropensci.github.io/rperseus/articles/rperseus-vignette.html&#34;&gt;Check the vignette&lt;/a&gt; for a more general overview of &lt;code&gt;rperseus&lt;/code&gt;. In the meantime, I look forward to getting more intimately acquainted with the Perseus Digital Library. Tentative plans to extend &lt;code&gt;rperseus&lt;/code&gt; a Shiny interface to further reduce “friction” and a method of creating a “book” of custom parallels with &lt;code&gt;bookdown&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h3&gt;

&lt;p&gt;I want to thank my two rOpenSci reviewers, &lt;a href=&#34;https://www.ildiczeller.com/&#34;&gt;Ildikó Czeller&lt;/a&gt; and &lt;a href=&#34;https://francoismichonneau.net/&#34;&gt;François Michonneau,&lt;/a&gt; for coaching me through the review process. They were the first two individuals to ever scrutinize my code, and I was lucky to hear their feedback. rOpenSci onboarding is truly a wonderful process.&lt;/p&gt;

&lt;!-- references --&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Bauer, Walter. &lt;em&gt;A Greek-English Lexicon of the New Testament and Other Early Christian Literature.&lt;/em&gt; Edited by Frederick W. Danker. 3rd ed. Chicago: University of Chicago Press, 2000.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Aland, Kurt. &lt;em&gt;Synopsis Quattuor Evangeliorum.&lt;/em&gt; Deutsche Bibelgesellschaft, 1997.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;The Greek text from the Perseus Digital Library is from 1885 standards. The advancement of textual criticism in the 20th century led to a more stable text you would find in current editions of the Greek New Testament.&lt;br /&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;The English translation is from Rainbow Missions, Inc. &lt;em&gt;World English Bible.&lt;/em&gt; Rainbow Missions, Inc.; revision of the American Standard Version of 1901. I’ve toyed with the idea of incorporating more modern translations, but that would require require resources beyond the Perseus Digital Library.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;&amp;ldquo;hpt&amp;rdquo; is the pointed Hebrew text from &lt;em&gt;Codex Leningradensis.&lt;/em&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:5&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;

      </description>
    </item>
    
    <item>
      <title>googleLanguageR - Analysing language through the Google Cloud Machine Learning APIs</title>
      <link>https://ropensci.org/blog/2017/10/03/googlelanguager/</link>
      <pubDate>Tue, 03 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2017/10/03/googlelanguager/</guid>
      <description>
        
        

&lt;!-- open source image taken from: https://upload.wikimedia.org/wikipedia/commons/2/21/Bell_System_switchboard.jpg --&gt;

&lt;p&gt;&lt;span&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-10-03-googlelanguager/switchboard.jpg&#34;&gt;&lt;/div&gt;
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;One of the greatest assets human beings possess is the power of speech and language, from which almost all our other accomplishments flow. To be able to analyse communication offers us a chance to gain a greater understanding of one another.&lt;/p&gt;

&lt;p&gt;To help you with this, &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/&#34;&gt;&lt;code&gt;googleLanguageR&lt;/code&gt;&lt;/a&gt; is an R package that allows you to perform speech-to-text transcription, neural net translation and natural language processing via the &lt;a href=&#34;https://cloud.google.com/products/machine-learning/&#34;&gt;Google Cloud machine learning services&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;An introduction to the package is below, but you can find out more details at the &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/&#34;&gt;&lt;code&gt;googleLanguageR&lt;/code&gt; website&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;google-s-bet&#34;&gt;Google&amp;rsquo;s bet&lt;/h3&gt;

&lt;p&gt;Google predicts that machine learning is to be a fundamental feature of business, and so they are looking to become the infrastructure that makes machine learning possible. Metaphorically speaking: If machine learning is electricity, then Google wants to be the pylons carrying it around the country.&lt;/p&gt;

&lt;!-- open source image taken from: https://pixabay.com/en/pylon-sky-electricity-tower-2515429/ --&gt;

&lt;p&gt;&lt;span&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-10-03-googlelanguager/pylon.jpg&#34;&gt;&lt;/div&gt;
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Google may not be the only company with such ambitions, but one advantage Google has is the amount of data it possesses. Twenty years of web crawling has given it an unprecedented corpus to train its models.  In addition, its recent moves into voice and video gives it one of the biggest audio and speech datasets, all of which have been used to help create machine learning applications within its products such as search and Gmail. Further investment in machine learning is shown by Google&amp;rsquo;s purchase of &lt;a href=&#34;https://deepmind.com/&#34;&gt;Deepmind&lt;/a&gt;, a UK based A.I. research firm that recently was in the news for defeating the top Go champion with its neural network trained Go bot.  Google has also taken an open-source route with the creation and publication of &lt;a href=&#34;https://www.tensorflow.org/&#34;&gt;Tensorflow&lt;/a&gt;, a leading machine learning framework.&lt;/p&gt;

&lt;p&gt;Whilst you can create your own machine learning models, for those users who haven&amp;rsquo;t the expertise, data or time to do so, Google also offers an increasing range of machine learning APIs that are pre-trained, such as image and video recognition or job search.  &lt;code&gt;googleLanguageR&lt;/code&gt; wraps the subset of those machine learning APIs that are language flavoured - Cloud Speech, Translation and Natural Language.&lt;/p&gt;

&lt;p&gt;Since they carry complementary outputs that can be used in each other&amp;rsquo;s input, all three of the APIs are included in one package. For example, you can transcribe a recording of someone speaking in Danish, translate that to English and then identify how positive or negative the writer felt about its content (sentiment analysis) then identify the most important concepts and objects within the content (entity analysis).&lt;/p&gt;

&lt;h3 id=&#34;motivations&#34;&gt;Motivations&lt;/h3&gt;

&lt;h4 id=&#34;fake-news&#34;&gt;Fake news&lt;/h4&gt;

&lt;p&gt;One reason why I started looking at this area was the growth of &amp;lsquo;fake news&amp;rsquo;, and its effect on political discourse on social media. I wondered if there was some way to put metrics on how much a news story fuelled one&amp;rsquo;s own bias within your own filter bubble.  The entity API provides a way to perform entity and sentiment analysis at scale on tweets, and by then comparing different users and news sources preferences the hope is to be able to judge how much they are in agreement with your own bias, views and trusted reputation sources.&lt;/p&gt;

&lt;h4 id=&#34;make-your-own-alexa&#34;&gt;Make your own Alexa&lt;/h4&gt;

&lt;p&gt;Another motivating application is the growth of voice commands that will become the primary way of user interface with technology.  Already, &lt;a href=&#34;https://www.thinkwithgoogle.com/data-gallery/detail/google-app-voice-search/&#34;&gt;Google reports up to 20% of search in its app&lt;/a&gt; is via voice search.  I&amp;rsquo;d like to be able to say &amp;ldquo;R, print me out that report for client X&amp;rdquo;.  A Shiny app that records your voice, uploads to the API then parses the return text into actions gives you a chance to create your very own Alexa-like infrastructure.&lt;/p&gt;

&lt;p&gt;&lt;span style=&#34;text-align:center&#34;&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-10-03-googlelanguager/alexa.jpg&#34;&gt;&lt;/div&gt;
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The voice activated internet connected speaker, Amazon&amp;rsquo;s Alexa - image from www.amazon.co.uk&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;translate-everything&#34;&gt;Translate everything&lt;/h4&gt;

&lt;p&gt;Finally, I live and work in Denmark.  As Danish is only spoken by less than 6 million people, applications that work in English may not be available in Danish very quickly, if at all.  The API&amp;rsquo;s translation service is the one that made the news in 2016 for &lt;a href=&#34;https://research.googleblog.com/2016/09/a-neural-network-for-machine.html&#34;&gt;&amp;ldquo;inventing its own language&amp;rdquo;&lt;/a&gt;, and offers much better English to Danish translations that the free web version and may make services available in Denmark sooner.&lt;/p&gt;

&lt;h3 id=&#34;using-the-library&#34;&gt;Using the library&lt;/h3&gt;

&lt;p&gt;To use these APIs within R, you first need to do a one-time setup to create a Google Project, add a credit card and authenticate which is &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/#installation&#34;&gt;detailed on the package website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After that, you feed in the R objects you want to operate upon.  The &lt;a href=&#34;https://github.com/ropensci/onboarding/issues/127&#34;&gt;rOpenSci review&lt;/a&gt; helped to ensure that this can scale up easily, so that you can feed in large character vectors which the library will parse and rate limit as required.  The functions also work within &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidyverse&lt;/a&gt; pipe syntax.&lt;/p&gt;

&lt;h4 id=&#34;speech-to-text&#34;&gt;Speech-to-text&lt;/h4&gt;

&lt;p&gt;The &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/articles/speech.html&#34;&gt;Cloud Speech API&lt;/a&gt; is exposed via the &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/reference/gl_speech.html&#34;&gt;&lt;code&gt;gl_speech&lt;/code&gt;&lt;/a&gt; function.&lt;/p&gt;

&lt;p&gt;It supports multiple audio formats and languages, and you can either feed a sub-60 second audio file directly, or perform asynchrnous requests for longer audio files.&lt;/p&gt;

&lt;p&gt;Example code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(googleLanguageR)

my_audio &amp;lt;- &amp;quot;my_audio_file.wav&amp;quot;
gl_speech(my_audio)
#  A tibble: 1 x 3
#  transcript confidence                 words
#* &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;                &amp;lt;list&amp;gt;
#1 Hello Mum  0.9227779 &amp;lt;data.frame [19 x 3]&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;translation&#34;&gt;Translation&lt;/h4&gt;

&lt;p&gt;The &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/articles/translation.html&#34;&gt;Cloud Translation API&lt;/a&gt; lets you translate text via &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/reference/gl_translate.html&#34;&gt;&lt;code&gt;gl_translate&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As you are charged per character, one tip here if you are working with lots of different languages is to perform detection of language offline first using another rOpenSci package, &lt;a href=&#34;https://github.com/ropensci/cld2&#34;&gt;&lt;code&gt;cld2&lt;/code&gt;&lt;/a&gt;.  That way you can avoid charges for text that is already in your target language i.e. English.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(googleLanguageR)
library(cld2)
library(purrr)

my_text &amp;lt;- c(&amp;quot;Katten sidder på måtten&amp;quot;, &amp;quot;The cat sat on the mat&amp;quot;)

## offline detect language via cld2
detected &amp;lt;- map_chr(my_text, detect_language)
# [1] &amp;quot;DANISH&amp;quot;  &amp;quot;ENGLISH&amp;quot;

## get non-English text
translate_me &amp;lt;- my_text[detected != &amp;quot;ENGLISH&amp;quot;]

## translate
gl_translate(translate_me)
## A tibble: 1 x 3
#                 translatedText detectedSourceLanguage                    text
#*                         &amp;lt;chr&amp;gt;                  &amp;lt;chr&amp;gt;                   &amp;lt;chr&amp;gt;
#1 The cat is sitting on the mat                     da Katten sidder på måtten
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;natural-language-processing&#34;&gt;Natural Language Processing&lt;/h4&gt;

&lt;p&gt;The &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/articles/nlp.html&#34;&gt;Natural Language API&lt;/a&gt; reveals the structure and meaning of text, accessible via the &lt;a href=&#34;http://code.markedmondson.me/googleLanguageR/reference/gl_nlp.html&#34;&gt;&lt;code&gt;gl_nlp&lt;/code&gt;&lt;/a&gt; function.&lt;/p&gt;

&lt;p&gt;It returns several analysis:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Entity analysis&lt;/em&gt; - finds named entities (currently proper names and common nouns) in the text along with entity types, salience, mentions for each entity, and other properties. If possible, will also return metadata about that entity such as a Wikipedia URL.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Syntax&lt;/em&gt; - analyzes the syntax of the text and provides sentence boundaries and tokenization along with part of speech tags, dependency trees, and other properties.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Sentiment&lt;/em&gt; - the overall sentiment of the text, represented by a magnitude [0, +inf] and score between -1.0 (negative sentiment) and 1.0 (positive sentiment)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are all useful to get an understanding of the meaning of a sentence, and has potentially the greatest number of applications of the APIs featured.  With entity analysis, auto categorisation of text is possible; the syntax returns let you pull out nouns and verbs for parsing into other actions; and the sentiment analysis allows you to get a feeling for emotion within text.&lt;/p&gt;

&lt;p&gt;A demonstration is below which gives an idea of what output you can generate:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(googleLanguageR)
quote &amp;lt;- &amp;quot;Two things are infinite: the universe and human stupidity; and I&#39;m not sure about the universe.&amp;quot;
nlp &amp;lt;- gl_nlp(quote)

str(nlp)
#List of 6
# $ sentences        :List of 1
#  ..$ :&#39;data.frame&#39;:	1 obs. of  4 variables:
#  .. ..$ content    : chr &amp;quot;Two things are infinite: the universe and human stupidity; and I&#39;m not sure about the universe.&amp;quot;
#  .. ..$ beginOffset: int 0
#  .. ..$ magnitude  : num 0.6
#  .. ..$ score      : num -0.6
# $ tokens           :List of 1
#  ..$ :&#39;data.frame&#39;:	20 obs. of  17 variables:
#  .. ..$ content       : chr [1:20] &amp;quot;Two&amp;quot; &amp;quot;things&amp;quot; &amp;quot;are&amp;quot; &amp;quot;infinite&amp;quot; ...
#  .. ..$ beginOffset   : int [1:20] 0 4 11 15 23 25 29 38 42 48 ...
#  .. ..$ tag           : chr [1:20] &amp;quot;NUM&amp;quot; &amp;quot;NOUN&amp;quot; &amp;quot;VERB&amp;quot; &amp;quot;ADJ&amp;quot; ...
#  .. ..$ aspect        : chr [1:20] &amp;quot;ASPECT_UNKNOWN&amp;quot; &amp;quot;ASPECT_UNKNOWN&amp;quot; &amp;quot;ASPECT_UNKNOWN&amp;quot; &amp;quot;ASPECT_UNKNOWN&amp;quot; ...
#  .. ..$ case          : chr [1:20] &amp;quot;CASE_UNKNOWN&amp;quot; &amp;quot;CASE_UNKNOWN&amp;quot; &amp;quot;CASE_UNKNOWN&amp;quot; &amp;quot;CASE_UNKNOWN&amp;quot; ...
#  .. ..$ form          : chr [1:20] &amp;quot;FORM_UNKNOWN&amp;quot; &amp;quot;FORM_UNKNOWN&amp;quot; &amp;quot;FORM_UNKNOWN&amp;quot; &amp;quot;FORM_UNKNOWN&amp;quot; ...
#  .. ..$ gender        : chr [1:20] &amp;quot;GENDER_UNKNOWN&amp;quot; &amp;quot;GENDER_UNKNOWN&amp;quot; &amp;quot;GENDER_UNKNOWN&amp;quot; &amp;quot;GENDER_UNKNOWN&amp;quot; ...
#  .. ..$ mood          : chr [1:20] &amp;quot;MOOD_UNKNOWN&amp;quot; &amp;quot;MOOD_UNKNOWN&amp;quot; &amp;quot;INDICATIVE&amp;quot; &amp;quot;MOOD_UNKNOWN&amp;quot; ...
#  .. ..$ number        : chr [1:20] &amp;quot;NUMBER_UNKNOWN&amp;quot; &amp;quot;PLURAL&amp;quot; &amp;quot;NUMBER_UNKNOWN&amp;quot; &amp;quot;NUMBER_UNKNOWN&amp;quot; ...
#  .. ..$ person        : chr [1:20] &amp;quot;PERSON_UNKNOWN&amp;quot; &amp;quot;PERSON_UNKNOWN&amp;quot; &amp;quot;PERSON_UNKNOWN&amp;quot; &amp;quot;PERSON_UNKNOWN&amp;quot; ...
#  .. ..$ proper        : chr [1:20] &amp;quot;PROPER_UNKNOWN&amp;quot; &amp;quot;PROPER_UNKNOWN&amp;quot; &amp;quot;PROPER_UNKNOWN&amp;quot; &amp;quot;PROPER_UNKNOWN&amp;quot; ...
#  .. ..$ reciprocity   : chr [1:20] &amp;quot;RECIPROCITY_UNKNOWN&amp;quot; &amp;quot;RECIPROCITY_UNKNOWN&amp;quot; &amp;quot;RECIPROCITY_UNKNOWN&amp;quot; &amp;quot;RECIPROCITY_UNKNOWN&amp;quot; ...
#  .. ..$ tense         : chr [1:20] &amp;quot;TENSE_UNKNOWN&amp;quot; &amp;quot;TENSE_UNKNOWN&amp;quot; &amp;quot;PRESENT&amp;quot; &amp;quot;TENSE_UNKNOWN&amp;quot; ...
#  .. ..$ voice         : chr [1:20] &amp;quot;VOICE_UNKNOWN&amp;quot; &amp;quot;VOICE_UNKNOWN&amp;quot; &amp;quot;VOICE_UNKNOWN&amp;quot; &amp;quot;VOICE_UNKNOWN&amp;quot; ...
#  .. ..$ headTokenIndex: int [1:20] 1 2 2 2 2 6 2 6 9 6 ...
#  .. ..$ label         : chr [1:20] &amp;quot;NUM&amp;quot; &amp;quot;NSUBJ&amp;quot; &amp;quot;ROOT&amp;quot; &amp;quot;ACOMP&amp;quot; ...
#  .. ..$ value         : chr [1:20] &amp;quot;Two&amp;quot; &amp;quot;thing&amp;quot; &amp;quot;be&amp;quot; &amp;quot;infinite&amp;quot; ...
# $ entities         :List of 1
#  ..$ :Classes ‘tbl_df’, ‘tbl’ and &#39;data.frame&#39;:	6 obs. of  9 variables:
#  .. ..$ name         : chr [1:6] &amp;quot;human stupidity&amp;quot; &amp;quot;things&amp;quot; &amp;quot;universe&amp;quot; &amp;quot;universe&amp;quot; ...
#  .. ..$ type         : chr [1:6] &amp;quot;OTHER&amp;quot; &amp;quot;OTHER&amp;quot; &amp;quot;OTHER&amp;quot; &amp;quot;OTHER&amp;quot; ...
#  .. ..$ salience     : num [1:6] 0.1662 0.4771 0.2652 0.2652 0.0915 ...
#  .. ..$ mid          : Factor w/ 0 levels: NA NA NA NA NA NA
#  .. ..$ wikipedia_url: Factor w/ 0 levels: NA NA NA NA NA NA
#  .. ..$ magnitude    : num [1:6] NA NA NA NA NA NA
#  .. ..$ score        : num [1:6] NA NA NA NA NA NA
#  .. ..$ beginOffset  : int [1:6] 42 4 29 86 29 86
#  .. ..$ mention_type : chr [1:6] &amp;quot;COMMON&amp;quot; &amp;quot;COMMON&amp;quot; &amp;quot;COMMON&amp;quot; &amp;quot;COMMON&amp;quot; ...
# $ language         : chr &amp;quot;en&amp;quot;
# $ text             : chr &amp;quot;Two things are infinite: the universe and human stupidity; and I&#39;m not sure about the universe.&amp;quot;
# $ documentSentiment:Classes ‘tbl_df’, ‘tbl’ and &#39;data.frame&#39;:	1 obs. of  2 variables:
#  ..$ magnitude: num 0.6
#  ..$ score    : num -0.6
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h3&gt;

&lt;p&gt;This package is 10 times better due to the efforts of the rOpenSci reviewers &lt;a href=&#34;http://enpiar.com/&#34;&gt;Neal Richardson&lt;/a&gt; and &lt;a href=&#34;http://www.juliagustavsen.com/&#34;&gt;Julia Gustavsen&lt;/a&gt;, who have whipped the documentation, outputs and test cases into the form they are today in &lt;code&gt;0.1.0&lt;/code&gt;.  Many thanks to them.&lt;/p&gt;

&lt;p&gt;Hopefully, this is just the beginning and the package can be further improved by its users - if you do give the package a try and find a potential improvement, &lt;a href=&#34;https://github.com/ropensci/googleLanguageR/issues&#34;&gt;raise an issue on GitHub&lt;/a&gt; and we can try to implement it.  I&amp;rsquo;m excited to see what users can do with these powerful tools.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Accessing patent data with the patentsview package</title>
      <link>https://ropensci.org/blog/2017/09/19/patentsview/</link>
      <pubDate>Tue, 19 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2017/09/19/patentsview/</guid>
      <description>
        
        

&lt;h3 id=&#34;why-care-about-patents&#34;&gt;Why care about patents?&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1. Patents play a critical role in incentivizing innovation, without
which we wouldn&amp;rsquo;t have much of the technology we rely on everyday&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;What does your iPhone, Google&amp;rsquo;s PageRank algorithm, and a butter
substitute called Smart Balance all have in common?&lt;/p&gt;

&lt;!-- These are open source images taken from: https://pixabay.com/ --&gt;

&lt;p&gt;&lt;span&gt;
&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-09-19-patentsview/iphone.png&#34; width=&#34;15%&#34;&gt;
&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-09-19-patentsview/google.jpg&#34; width=&#34;25%&#34;&gt;
&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-09-19-patentsview/butter.png&#34; width=&#34;25%&#34;&gt;
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&amp;hellip;They all probably wouldn&amp;rsquo;t be here if not for patents. A patent
provides its owner with the ability to make money off of something that
they invented, without having to worry about someone else copying their
technology. Think Apple would spend millions of dollars developing the
iPhone if Samsung could just come along and &lt;a href=&#34;http://www.reuters.com/article/us-apple-samsung-elec-appeal-idUSKCN1271LF&#34;&gt;rip it
off&lt;/a&gt;?
Probably not.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Patents offer a great opportunity for data analysis&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;There are two primary reasons for this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Patent data is public&lt;/strong&gt;. In return for the exclusive right to
profit off an invention, an individual/company has to publicly
disclose the details of their invention to the rest of the world.
&lt;a href=&#34;http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;amp;Sect2=HITOFF&amp;amp;p=1&amp;amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;amp;r=11&amp;amp;f=G&amp;amp;l=50&amp;amp;co1=AND&amp;amp;d=PTXT&amp;amp;s1=dog&amp;amp;OS=dog&amp;amp;RS=dog&#34;&gt;Examples of those
details&lt;/a&gt;
include the patent&amp;rsquo;s title, abstract, technology classification,
assigned organizations, etc.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Patent data can answer questions that people care about&lt;/strong&gt;.
Companies (especially big ones like IBM and Google) have a vested
interest in extracting insights from patents, and spend a lot of
time/resources trying figure out how to best manage their
intellectual property (IP) rights. They&amp;rsquo;re plagued by questions like
&amp;ldquo;who should I sell my underperforming patents to,&amp;rdquo; &amp;ldquo;which technology
areas are open to new innovations,&amp;rdquo; &amp;ldquo;what&amp;rsquo;s going to be the next big
thing in the world of buttery spreads,&amp;rdquo; etc. Patents offer a way to
provide data-driven answers to these questions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Combined, these two things make patents a prime target for data
analysis. However, until recently it was hard to get at the data inside
these documents. One had to either collect it manually using the
official &lt;a href=&#34;https://en.wikipedia.org/wiki/United_States_Patent_and_Trademark_Office&#34;&gt;United States Patent and Trademark
Office&lt;/a&gt;
(USPTO) &lt;a href=&#34;http://patft.uspto.gov/netahtml/PTO/search-adv.htm&#34;&gt;search
engine&lt;/a&gt;, or figure
out a way to download, parse, and model huge XML data dumps. Enter
PatentsView.&lt;/p&gt;

&lt;h3 id=&#34;patentsview-and-the-patentsview-package&#34;&gt;PatentsView and the &lt;code&gt;patentsview&lt;/code&gt; package&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.patentsview.org/web/#viz/relationships&#34;&gt;PatentsView&lt;/a&gt; is one
of USPTO&amp;rsquo;s new initiatives intended to increase the usability and value
of patent data. One feature of this project is a publicly accessible API
that makes it easy to programmatically interact with the data. A few of
the reasons why I like the API (and PatentsView more generally):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The API is free (no credential required) and currently doesn&amp;rsquo;t
impose rate limits/bandwidth throttling.&lt;/li&gt;
&lt;li&gt;The project offers &lt;a href=&#34;http://www.patentsview.org/download/&#34;&gt;bulk downloads of patent
data&lt;/a&gt; on their website (in a
flat file format), for those who want to be closest to the data.&lt;/li&gt;
&lt;li&gt;Both the API and the bulk download data contain disambiguated
entities such as inventors, assignees, organizations, etc. In other
words, the API will tell you whether it thinks that John Smith on
patent X is the same person as John Smith on patent Y. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;code&gt;patentsview&lt;/code&gt; R package is a wrapper around the PatentsView API. It
contains a function that acts as a client to the API (&lt;code&gt;search_pv()&lt;/code&gt;) as
well as several supporting functions. Full documentation of the package
can be found on its
&lt;a href=&#34;https://ropensci.github.io/patentsview/index.html&#34;&gt;website&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;installation&#34;&gt;Installation&lt;/h3&gt;

&lt;p&gt;You can install the stable version of &lt;code&gt;patentsview&lt;/code&gt; from CRAN:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;patentsview&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or get the development version from GitHub:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if (!require(devtools)) install.packages(&amp;quot;devtools&amp;quot;)

devtools::install_github(&amp;quot;ropensci/patentsview&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;getting-started&#34;&gt;Getting started&lt;/h3&gt;

&lt;p&gt;The package has one main function, &lt;code&gt;search_pv()&lt;/code&gt;, that makes it easy to
send requests to the API. There are two parameters to &lt;code&gt;search_pv()&lt;/code&gt; that
you&amp;rsquo;re going to want to think about just about every time you call it -
&lt;code&gt;query&lt;/code&gt; and &lt;code&gt;fields&lt;/code&gt;. You tell the API how you want to filter the patent
data with &lt;code&gt;query&lt;/code&gt;, and which fields you want to retrieve with
&lt;code&gt;fields&lt;/code&gt;. &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h4 id=&#34;query&#34;&gt;&lt;code&gt;query&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;Your query has to use the &lt;a href=&#34;http://www.patentsview.org/api/query-language.html&#34;&gt;PatentsView query
language&lt;/a&gt;, which is
a JSON-based syntax that is similar to the one used by Lucene. You can
write the query directly and pass it as a string to &lt;code&gt;search_pv()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(patentsview)

qry_1 &amp;lt;- &#39;{&amp;quot;_gt&amp;quot;:{&amp;quot;patent_year&amp;quot;:2007}}&#39;
search_pv(query = qry_1, fields = NULL) # This will retrieve a default set of fields
#&amp;gt; $data
#&amp;gt; #### A list with a single data frame on the patent data level:
#&amp;gt;
#&amp;gt; List of 1
#&amp;gt;  $ patents:&#39;data.frame&#39;: 25 obs. of  3 variables:
#&amp;gt;   ..$ patent_id    : chr [1:25] &amp;quot;7313829&amp;quot; ...
#&amp;gt;   ..$ patent_number: chr [1:25] &amp;quot;7313829&amp;quot; ...
#&amp;gt;   ..$ patent_title : chr [1:25] &amp;quot;Sealing device for body suit and sealin&amp;quot;..
#&amp;gt;
#&amp;gt; $query_results
#&amp;gt; #### Distinct entity counts across all downloadable pages of output:
#&amp;gt;
#&amp;gt; total_patent_count = 100,000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;Or you can use the domain specific language (DSL) provided in the
&lt;code&gt;patentsview&lt;/code&gt; package to help you write the query:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;qry_2 &amp;lt;- qry_funs$gt(patent_year = 2007) # All DSL functions are in the qry_funs list
qry_2 # qry_2 is the same as qry_1
#&amp;gt; {&amp;quot;_gt&amp;quot;:{&amp;quot;patent_year&amp;quot;:2007}}

search_pv(query = qry_2)
#&amp;gt; $data
#&amp;gt; #### A list with a single data frame on the patent data level:
#&amp;gt;
#&amp;gt; List of 1
#&amp;gt;  $ patents:&#39;data.frame&#39;: 25 obs. of  3 variables:
#&amp;gt;   ..$ patent_id    : chr [1:25] &amp;quot;7313829&amp;quot; ...
#&amp;gt;   ..$ patent_number: chr [1:25] &amp;quot;7313829&amp;quot; ...
#&amp;gt;   ..$ patent_title : chr [1:25] &amp;quot;Sealing device for body suit and sealin&amp;quot;..
#&amp;gt;
#&amp;gt; $query_results
#&amp;gt; #### Distinct entity counts across all downloadable pages of output:
#&amp;gt;
#&amp;gt; total_patent_count = 100,000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;qry_1&lt;/code&gt; and &lt;code&gt;qry_2&lt;/code&gt; will result in the same HTTP call to the API. Both
queries search for patents in USPTO that were published after 2007.
There are three gotchas to look out for when writing a query:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Field is queryable.&lt;/strong&gt; The API has 7 endpoints (the default
endpoint is &amp;ldquo;patents&amp;rdquo;), and each endpoint has its own set of fields
that you can filter on. &lt;em&gt;The fields that you can filter on are not
necessarily the same as the ones that you can retrieve.&lt;/em&gt; In other
words, the fields that you can include in &lt;code&gt;query&lt;/code&gt; (e.g.,
&lt;code&gt;patent_year&lt;/code&gt;) are not necessarily the same as those that you can
include in &lt;code&gt;fields&lt;/code&gt;. To see which fields you can query on, look in
the &lt;code&gt;fieldsdf&lt;/code&gt; data frame (&lt;code&gt;View(patentsview::fieldsdf)&lt;/code&gt;) for fields
that have a &amp;ldquo;y&amp;rdquo; indicator in their &lt;code&gt;can_query&lt;/code&gt; column for your given
endpoint.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Correct data type for field.&lt;/strong&gt; If you&amp;rsquo;re filtering on a field in
your query, you have to make sure that the value you are filtering
on is consistent with the field&amp;rsquo;s data type. For example,
&lt;code&gt;patent_year&lt;/code&gt; has type &amp;ldquo;integer,&amp;rdquo; so if you pass 2007 as a string
then you&amp;rsquo;re going to get an error (&lt;code&gt;patent_year = 2007&lt;/code&gt; is good,
&lt;code&gt;patent_year = &amp;quot;2007&amp;quot;&lt;/code&gt; is no good). You can find a field&amp;rsquo;s data type
in the &lt;code&gt;fieldsdf&lt;/code&gt; data frame.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Comparison function works with field&amp;rsquo;s data type.&lt;/strong&gt; The comparison
function(s) that you use (e.g., the greater-than function shown
above, &lt;code&gt;qry_funs$gt()&lt;/code&gt;) must be consistent with the field&amp;rsquo;s data
type. For example, you can&amp;rsquo;t use the &amp;ldquo;contains&amp;rdquo; function on fields
of type &amp;ldquo;integer&amp;rdquo; (&lt;code&gt;qry_funs$contains(patent_year = 2007)&lt;/code&gt; will
throw an error). See &lt;code&gt;?qry_funs&lt;/code&gt; for more details.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In short, use the &lt;code&gt;fieldsdf&lt;/code&gt; data frame when you write a query and you
should be fine. Check out the &lt;a href=&#34;https://ropensci.github.io/patentsview/articles/writing-queries.html&#34;&gt;writing queries
vignette&lt;/a&gt;
for more details.&lt;/p&gt;

&lt;h4 id=&#34;fields&#34;&gt;&lt;code&gt;fields&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;Up until now we have been using the default value for &lt;code&gt;fields&lt;/code&gt;. This
results in the API giving us some small set of default fields. Let&amp;rsquo;s see
about retrieving some more fields:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;search_pv(
  query = qry_funs$gt(patent_year = 2007),
  fields = c(&amp;quot;patent_abstract&amp;quot;, &amp;quot;patent_average_processing_time&amp;quot;,
             &amp;quot;inventor_first_name&amp;quot;, &amp;quot;inventor_total_num_patents&amp;quot;)
)
#&amp;gt; $data
#&amp;gt; #### A list with a single data frame (with list column(s) inside) on the patent data level:
#&amp;gt;
#&amp;gt; List of 1
#&amp;gt;  $ patents:&#39;data.frame&#39;: 25 obs. of  3 variables:
#&amp;gt;   ..$ patent_abstract               : chr [1:25] &amp;quot;A sealing device for a&amp;quot;..
#&amp;gt;   ..$ patent_average_processing_time: chr [1:25] &amp;quot;1324&amp;quot; ...
#&amp;gt;   ..$ inventors                     :List of 25
#&amp;gt;
#&amp;gt; $query_results
#&amp;gt; #### Distinct entity counts across all downloadable pages of output:
#&amp;gt;
#&amp;gt; total_patent_count = 100,000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The fields that you can retrieve depends on the endpoint that you are
hitting. We&amp;rsquo;ve been using the &amp;ldquo;patents&amp;rdquo; endpoint thus far, so all of
these are retrievable:
&lt;code&gt;fieldsdf[fieldsdf$endpoint == &amp;quot;patents&amp;quot;, &amp;quot;field&amp;quot;]&lt;/code&gt;. You can also use
&lt;code&gt;get_fields()&lt;/code&gt; to list the retrievable fields for a given endpoint:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;search_pv(
  query = qry_funs$gt(patent_year = 2007),
  fields = get_fields(endpoint = &amp;quot;patents&amp;quot;, groups = c(&amp;quot;patents&amp;quot;, &amp;quot;inventors&amp;quot;))
)
#&amp;gt; $data
#&amp;gt; #### A list with a single data frame (with list column(s) inside) on the patent data level:
#&amp;gt;
#&amp;gt; List of 1
#&amp;gt;  $ patents:&#39;data.frame&#39;: 25 obs. of  31 variables:
#&amp;gt;   ..$ patent_abstract                       : chr [1:25] &amp;quot;A sealing devi&amp;quot;..
#&amp;gt;   ..$ patent_average_processing_time        : chr [1:25] &amp;quot;1324&amp;quot; ...
#&amp;gt;   ..$ patent_date                           : chr [1:25] &amp;quot;2008-01-01&amp;quot; ...
#&amp;gt;   ..$ patent_firstnamed_assignee_city       : chr [1:25] &amp;quot;Cambridge&amp;quot; ...
#&amp;gt;   ..$ patent_firstnamed_assignee_country    : chr [1:25] &amp;quot;US&amp;quot; ...
#&amp;gt;   ..$ patent_firstnamed_assignee_id         : chr [1:25] &amp;quot;b9fc6599e3d60c&amp;quot;..
#&amp;gt;   ..$ patent_firstnamed_assignee_latitude   : chr [1:25] &amp;quot;42.3736&amp;quot; ...
#&amp;gt;   ..$ patent_firstnamed_assignee_location_id: chr [1:25] &amp;quot;42.3736158|-71&amp;quot;..
#&amp;gt;   ..$ patent_firstnamed_assignee_longitude  : chr [1:25] &amp;quot;-71.1097&amp;quot; ...
#&amp;gt;   ..$ patent_firstnamed_assignee_state      : chr [1:25] &amp;quot;MA&amp;quot; ...
#&amp;gt;   ..$ patent_firstnamed_inventor_city       : chr [1:25] &amp;quot;Lucca&amp;quot; ...
#&amp;gt;   ..$ patent_firstnamed_inventor_country    : chr [1:25] &amp;quot;IT&amp;quot; ...
#&amp;gt;   ..$ patent_firstnamed_inventor_id         : chr [1:25] &amp;quot;6416028-3&amp;quot; ...
#&amp;gt;   ..$ patent_firstnamed_inventor_latitude   : chr [1:25] &amp;quot;43.8376&amp;quot; ...
#&amp;gt;   ..$ patent_firstnamed_inventor_location_id: chr [1:25] &amp;quot;43.8376211|10.&amp;quot;..
#&amp;gt;   ..$ patent_firstnamed_inventor_longitude  : chr [1:25] &amp;quot;10.4951&amp;quot; ...
#&amp;gt;   ..$ patent_firstnamed_inventor_state      : chr [1:25] &amp;quot;Tuscany&amp;quot; ...
#&amp;gt;   ..$ patent_id                             : chr [1:25] &amp;quot;7313829&amp;quot; ...
#&amp;gt;   ..$ patent_kind                           : chr [1:25] &amp;quot;B1&amp;quot; ...
#&amp;gt;   ..$ patent_number                         : chr [1:25] &amp;quot;7313829&amp;quot; ...
#&amp;gt;   ..$ patent_num_cited_by_us_patents        : chr [1:25] &amp;quot;5&amp;quot; ...
#&amp;gt;   ..$ patent_num_claims                     : chr [1:25] &amp;quot;25&amp;quot; ...
#&amp;gt;   ..$ patent_num_combined_citations         : chr [1:25] &amp;quot;35&amp;quot; ...
#&amp;gt;   ..$ patent_num_foreign_citations          : chr [1:25] &amp;quot;0&amp;quot; ...
#&amp;gt;   ..$ patent_num_us_application_citations   : chr [1:25] &amp;quot;0&amp;quot; ...
#&amp;gt;   ..$ patent_num_us_patent_citations        : chr [1:25] &amp;quot;35&amp;quot; ...
#&amp;gt;   ..$ patent_processing_time                : chr [1:25] &amp;quot;792&amp;quot; ...
#&amp;gt;   ..$ patent_title                          : chr [1:25] &amp;quot;Sealing device&amp;quot;..
#&amp;gt;   ..$ patent_type                           : chr [1:25] &amp;quot;utility&amp;quot; ...
#&amp;gt;   ..$ patent_year                           : chr [1:25] &amp;quot;2008&amp;quot; ...
#&amp;gt;   ..$ inventors                             :List of 25
#&amp;gt;
#&amp;gt; $query_results
#&amp;gt; #### Distinct entity counts across all downloadable pages of output:
#&amp;gt;
#&amp;gt; total_patent_count = 100,000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s look at a quick example of pulling and analyzing patent data.
We&amp;rsquo;ll look at patents from the last ten years that are classified below
the &lt;a href=&#34;https://worldwide.espacenet.com/classification#!/CPC=H04L63/02&#34;&gt;H04L63/00 CPC
code&lt;/a&gt;.
Patents in this area relate to &amp;ldquo;network architectures or network
communication protocols for separating internal from external
traffic.&amp;rdquo; &lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; CPC codes offer a quick and dirty way to find patents of
interest, though getting a sense of their hierarchy can be tricky.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Download the data&lt;/li&gt;
&lt;/ol&gt;

&lt;!-- --&gt;

&lt;pre&gt;&lt;code&gt;library(patentsview)

# Write a query:
query &amp;lt;- with_qfuns( # with_qfuns is basically just: with(qry_funs, ...)
  and(
    begins(cpc_subgroup_id = &#39;H04L63/02&#39;),
    gte(patent_year = 2007)
  )
)

# Create a list of fields:
fields &amp;lt;- c(
  c(&amp;quot;patent_number&amp;quot;, &amp;quot;patent_year&amp;quot;),
  get_fields(endpoint = &amp;quot;patents&amp;quot;, groups = c(&amp;quot;assignees&amp;quot;, &amp;quot;cpcs&amp;quot;))
)

# Send HTTP request to API&#39;s server:
pv_res &amp;lt;- search_pv(query = query, fields = fields, all_pages = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;See where the patents are coming from (geographically)&lt;/li&gt;
&lt;/ol&gt;

&lt;!-- --&gt;

&lt;pre&gt;&lt;code&gt;library(leaflet)
library(htmltools)
library(dplyr)
library(tidyr)

data &amp;lt;-
  pv_res$data$patents %&amp;gt;%
    unnest(assignees) %&amp;gt;%
    select(assignee_id, assignee_organization, patent_number,
           assignee_longitude, assignee_latitude) %&amp;gt;%
    group_by_at(vars(-matches(&amp;quot;pat&amp;quot;))) %&amp;gt;%
    mutate(num_pats = n()) %&amp;gt;%
    ungroup() %&amp;gt;%
    select(-patent_number) %&amp;gt;%
    distinct() %&amp;gt;%
    mutate(popup = paste0(&amp;quot;&amp;lt;font color=&#39;Black&#39;&amp;gt;&amp;quot;,
                          htmlEscape(assignee_organization), &amp;quot;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;Patents:&amp;quot;,
                          num_pats, &amp;quot;&amp;lt;/font&amp;gt;&amp;quot;)) %&amp;gt;%
    mutate_at(vars(matches(&amp;quot;_l&amp;quot;)), as.numeric) %&amp;gt;%
    filter(!is.na(assignee_id))

leaflet(data) %&amp;gt;%
  addProviderTiles(providers$CartoDB.DarkMatterNoLabels) %&amp;gt;%
  addCircleMarkers(lng = ~assignee_longitude, lat = ~assignee_latitude,
                   popup = ~popup, ~sqrt(num_pats), color = &amp;quot;yellow&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-09-19-patentsview/unnamed-chunk-9-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Plot the growth of the field&amp;rsquo;s topics over time&lt;/li&gt;
&lt;/ol&gt;

&lt;!-- --&gt;

&lt;pre&gt;&lt;code&gt;library(ggplot2)
library(RColorBrewer)

data &amp;lt;-
  pv_res$data$patents %&amp;gt;%
    unnest(cpcs) %&amp;gt;%
    filter(cpc_subgroup_id != &amp;quot;H04L63/02&amp;quot;) %&amp;gt;% # remove patents categorized into only top-level category of H04L63/02
    mutate(
      title = case_when(
        grepl(&amp;quot;filtering&amp;quot;, .$cpc_subgroup_title, ignore.case = T) ~
          &amp;quot;Filtering policies&amp;quot;,
        .$cpc_subgroup_id %in% c(&amp;quot;H04L63/0209&amp;quot;, &amp;quot;H04L63/0218&amp;quot;) ~
          &amp;quot;Architectural arrangements&amp;quot;,
        grepl(&amp;quot;Firewall traversal&amp;quot;, .$cpc_subgroup_title, ignore.case = T) ~
          &amp;quot;Firewall traversal&amp;quot;,
        TRUE ~
          .$cpc_subgroup_title
      )
    ) %&amp;gt;%
    mutate(title = gsub(&amp;quot;.*(?=-)-&amp;quot;, &amp;quot;&amp;quot;, title, perl = TRUE)) %&amp;gt;%
    group_by(title, patent_year) %&amp;gt;%
    count() %&amp;gt;%
    ungroup() %&amp;gt;%
    mutate(patent_year = as.numeric(patent_year))

ggplot(data = data) +
  geom_smooth(aes(x = patent_year, y = n, colour = title), se = FALSE) +
  scale_x_continuous(&amp;quot;\nPublication year&amp;quot;, limits = c(2007, 2016),
                     breaks = 2007:2016) +
  scale_y_continuous(&amp;quot;Patents\n&amp;quot;, limits = c(0, 700)) +
  scale_colour_manual(&amp;quot;&amp;quot;, values = brewer.pal(5, &amp;quot;Set2&amp;quot;)) +
  theme_bw() + # theme inspired by https://hrbrmstr.github.io/hrbrthemes/
  theme(panel.border = element_blank(), axis.ticks = element_blank())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2017-09-19-patentsview/unnamed-chunk-10-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;learning-more&#34;&gt;Learning more&lt;/h3&gt;

&lt;p&gt;For analysis examples that go into a little more depth, check out the
&lt;a href=&#34;https://ropensci.github.io/patentsview/articles/citation-networks.html&#34;&gt;data applications
vignettes&lt;/a&gt;
on the package&amp;rsquo;s website. If you&amp;rsquo;re just interested in &lt;code&gt;search_pv()&lt;/code&gt;,
there are
&lt;a href=&#34;https://ropensci.github.io/patentsview/articles/examples.html&#34;&gt;examples&lt;/a&gt;
on the site for that as well. To contribute to the package or report an
issue, check out the &lt;a href=&#34;https://github.com/ropensci/patentsview/issues&#34;&gt;issues page on
GitHub&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;d like to thank the package&amp;rsquo;s two reviewers, &lt;a href=&#34;https://github.com/poldham&#34;&gt;Paul
Oldham&lt;/a&gt; and &lt;a href=&#34;http://blog.haunschmid.name/&#34;&gt;Verena
Haunschmid&lt;/a&gt;, for taking the time to review
the package and providing helpful feedback. I&amp;rsquo;d also like to thank
&lt;a href=&#34;http://www.masalmon.eu/&#34;&gt;Maëlle Salmon&lt;/a&gt; for shepherding the package
along the rOpenSci review process, as well &lt;a href=&#34;https://scottchamberlain.info/&#34;&gt;Scott
Chamberlain&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/stefaniebutland&#34;&gt;Stefanie
Butland&lt;/a&gt; for their miscellaneous
help.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;This is both good and bad, as there are errors in the disambiguation. The algorithm that is responsible for the disambiguation was created by the winner of the &lt;a href=&#34;http://www.patentsview.org/workshop/&#34;&gt;PatentsView Inventor Disambiguation Technical Workshop&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;These two parameters end up getting translated into a MySQL query by the API&amp;rsquo;s server, which then gets sent to a back-end database. &lt;code&gt;query&lt;/code&gt; and &lt;code&gt;fields&lt;/code&gt; are used to create the query&amp;rsquo;s &lt;code&gt;WHERE&lt;/code&gt; and &lt;code&gt;SELECT&lt;/code&gt; clauses, respectively.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;There is a slightly more in-depth definition that says that these are patents &amp;ldquo;related to the (logical) separation of traffic/(sub-) networks to achieve protection.&amp;rdquo;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;

      </description>
    </item>
    
    <item>
      <title>crul - an HTTP client</title>
      <link>https://ropensci.org/technotes/2016/11/09/crul-release/</link>
      <pubDate>Wed, 09 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/technotes/2016/11/09/crul-release/</guid>
      <description>
        
        

&lt;p&gt;A new package &lt;a href=&#34;https://cran.rstudio.com/web/packages/crul&#34;&gt;crul&lt;/a&gt; is
on CRAN. &lt;code&gt;crul&lt;/code&gt; is another HTTP client for R, but is relatively simplified
compared to &lt;a href=&#34;https://github.com/hadley/httr&#34;&gt;httr&lt;/a&gt;, and is being built
to link closely with &lt;a href=&#34;https://github.com/ropenscilabs/webmockr&#34;&gt;webmockr&lt;/a&gt; and &lt;a href=&#34;https://github.com/ropenscilabs/vcr&#34;&gt;vcr&lt;/a&gt;. &lt;code&gt;webmockr&lt;/code&gt; and
&lt;code&gt;vcr&lt;/code&gt; are packages ported from Ruby&amp;rsquo;s &lt;a href=&#34;https://github.com/bblimke/webmock&#34;&gt;webmock&lt;/a&gt;
and &lt;a href=&#34;https://github.com/vcr/vcr&#34;&gt;vcr&lt;/a&gt;, respectively.
They both make mocking HTTP requests really easy.&lt;/p&gt;

&lt;p&gt;A major use case for mocking HTTP requests is for unit tests. Nearly all the
packages I work on personally make HTTP
requests in their test suites, so I wanted to make it really easy to
mock HTTP requests. You don&amp;rsquo;t have to use mocking in test suites of course.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;crul&lt;/code&gt; is not meant to replace other HTTP R libraries, but rather to make it
easy to integrate mocking.&lt;/p&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;crul&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If binaries aren&amp;rsquo;t available, try from source:
&lt;code&gt;install.packages(&amp;quot;crul&amp;quot;, type = &amp;quot;source&amp;quot;)&lt;/code&gt; or from GitHub:
&lt;code&gt;devtools::install_github(&amp;quot;ropenscilabs/crul&amp;quot;)&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(crul)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;the-client&#34;&gt;The client&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;HttpClient&lt;/code&gt; is where to start&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(x &amp;lt;- HttpClient$new(
  url = &amp;quot;https://httpbin.org&amp;quot;,
  opts = list(
    timeout = 1
  ),
  headers = list(
    a = &amp;quot;hello world&amp;quot;
  )
))
#&amp;gt; &amp;lt;crul connection&amp;gt;
#&amp;gt;   url: https://httpbin.org
#&amp;gt;   options:
#&amp;gt;     timeout: 1
#&amp;gt;   headers:
#&amp;gt;     a: hello world
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Makes a R6 class, that has all the bits and bobs you&amp;rsquo;d expect for doing HTTP
requests. When it prints, it gives any defaults you&amp;rsquo;ve set. As you update
the object you can see what&amp;rsquo;s been set&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x$opts
#&amp;gt; $timeout
#&amp;gt; [1] 1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x$headers
#&amp;gt; $a
#&amp;gt; [1] &amp;quot;hello world&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;make-a-request&#34;&gt;Make a request&lt;/h2&gt;

&lt;p&gt;The client object created above has http methods that you can call,
and pass paths to, as well as query parameters, body values, and any other
curl options.&lt;/p&gt;

&lt;p&gt;Here, we&amp;rsquo;ll do a &lt;strong&gt;GET&lt;/strong&gt; request on the route &lt;code&gt;/get&lt;/code&gt; on our base url
&lt;code&gt;https://httpbin.org&lt;/code&gt; (the full url is then &lt;code&gt;https://httpbin.org/get&lt;/code&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- x$get(&amp;quot;get&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The response from a http request is another R6 class &lt;code&gt;HttpResponse&lt;/code&gt;, which
has slots for the outputs of the request, and some functions to deal with
the response:&lt;/p&gt;

&lt;p&gt;Status code&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res$status_code
#&amp;gt; [1] 200
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Status code with the message and explanation&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res$status_http()
#&amp;gt; &amp;lt;Status code: 200&amp;gt;
#&amp;gt;   Message: OK
#&amp;gt;   Explanation: Request fulfilled, document follows
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The content&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res$content
#&amp;gt;   [1] 7b 0a 20 20 22 61 72 67 73 22 3a 20 7b 7d 2c 20 0a 20 20 22 68 65 61
#&amp;gt;  [24] 64 65 72 73 22 3a 20 7b 0a 20 20 20 20 22 41 22 3a 20 22 68 65 6c 6c
#&amp;gt;  [47] 6f 20 77 6f 72 6c 64 22 2c 20 0a 20 20 20 20 22 41 63 63 65 70 74 22
#&amp;gt;  [70] 3a 20 22 2a 2f 2a 22 2c 20 0a 20 20 20 20 22 41 63 63 65 70 74 2d 45
#&amp;gt;  [93] 6e 63 6f 64 69 6e 67 22 3a 20 22 67 7a 69 70 2c 20 64 65 66 6c 61 74
#&amp;gt; [116] 65 22 2c 20 0a 20 20 20 20 22 48 6f 73 74 22 3a 20 22 68 74 74 70 62
#&amp;gt; [139] 69 6e 2e 6f 72 67 22 2c 20 0a 20 20 20 20 22 55 73 65 72 2d 41 67 65
#&amp;gt; [162] 6e 74 22 3a 20 22 6c 69 62 63 75 72 6c 2f 37 2e 34 39 2e 31 20 72 2d
#&amp;gt; [185] 63 75 72 6c 2f 32 2e 32 20 63 72 75 6c 2f 30 2e 31 2e 30 22 0a 20 20
#&amp;gt; [208] 7d 2c 20 0a 20 20 22 6f 72 69 67 69 6e 22 3a 20 22 31 35 37 2e 31 33
#&amp;gt; [231] 30 2e 31 37 39 2e 38 36 22 2c 20 0a 20 20 22 75 72 6c 22 3a 20 22 68
#&amp;gt; [254] 74 74 70 73 3a 2f 2f 68 74 74 70 62 69 6e 2e 6f 72 67 2f 67 65 74 22
#&amp;gt; [277] 0a 7d 0a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;HTTP method&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res$method
#&amp;gt; [1] &amp;quot;get&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Request headers&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res$request_headers
#&amp;gt; $a
#&amp;gt; [1] &amp;quot;hello world&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Response headers&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res$response_headers
#&amp;gt; [1] &amp;quot;HTTP/1.1 200 OK&amp;quot;
#&amp;gt; [2] &amp;quot;Server: nginx&amp;quot;
#&amp;gt; [3] &amp;quot;Date: Wed, 09 Nov 2016 19:25:14 GMT&amp;quot;
#&amp;gt; [4] &amp;quot;Content-Type: application/json&amp;quot;
#&amp;gt; [5] &amp;quot;Content-Length: 279&amp;quot;
#&amp;gt; [6] &amp;quot;Connection: keep-alive&amp;quot;
#&amp;gt; [7] &amp;quot;Access-Control-Allow-Origin: *&amp;quot;
#&amp;gt; [8] &amp;quot;Access-Control-Allow-Credentials: true&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And you can parse the content with a provided function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res$parse()
#&amp;gt; [1] &amp;quot;{\n  \&amp;quot;args\&amp;quot;: {}, \n  \&amp;quot;headers\&amp;quot;: {\n    \&amp;quot;A\&amp;quot;: \&amp;quot;hello world\&amp;quot;, \n    \&amp;quot;Accept\&amp;quot;: \&amp;quot;*/*\&amp;quot;, \n    \&amp;quot;Accept-Encoding\&amp;quot;: \&amp;quot;gzip, deflate\&amp;quot;, \n    \&amp;quot;Host\&amp;quot;: \&amp;quot;httpbin.org\&amp;quot;, \n    \&amp;quot;User-Agent\&amp;quot;: \&amp;quot;libcurl/7.49.1 r-curl/2.2 crul/0.1.0\&amp;quot;\n  }, \n  \&amp;quot;origin\&amp;quot;: \&amp;quot;157.130.179.86\&amp;quot;, \n  \&amp;quot;url\&amp;quot;: \&amp;quot;https://httpbin.org/get\&amp;quot;\n}\n&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;parse the JSON&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;jsonlite::fromJSON(res$parse())
#&amp;gt; $args
#&amp;gt; named list()
#&amp;gt;
#&amp;gt; $headers
#&amp;gt; $headers$A
#&amp;gt; [1] &amp;quot;hello world&amp;quot;
#&amp;gt;
#&amp;gt; $headers$Accept
#&amp;gt; [1] &amp;quot;*/*&amp;quot;
#&amp;gt;
#&amp;gt; $headers$`Accept-Encoding`
#&amp;gt; [1] &amp;quot;gzip, deflate&amp;quot;
#&amp;gt;
#&amp;gt; $headers$Host
#&amp;gt; [1] &amp;quot;httpbin.org&amp;quot;
#&amp;gt;
#&amp;gt; $headers$`User-Agent`
#&amp;gt; [1] &amp;quot;libcurl/7.49.1 r-curl/2.2 crul/0.1.0&amp;quot;
#&amp;gt;
#&amp;gt;
#&amp;gt; $origin
#&amp;gt; [1] &amp;quot;157.130.179.86&amp;quot;
#&amp;gt;
#&amp;gt; $url
#&amp;gt; [1] &amp;quot;https://httpbin.org/get&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;future-work&#34;&gt;Future work&lt;/h2&gt;

&lt;h3 id=&#34;mocking&#34;&gt;Mocking&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;crul&lt;/code&gt; doesn&amp;rsquo;t currently have mocking ability, but I am working right now on
getting the first version of &lt;a href=&#34;https://github.com/ropenscilabs/webmockr&#34;&gt;webmockr&lt;/a&gt; on
CRAN. It will work together with &lt;code&gt;crul&lt;/code&gt; so that when you use &lt;code&gt;crul&lt;/code&gt; you can
choose to turn on mocking, specify which patterns to match for mocking,
and much more.  &lt;code&gt;webmockr&lt;/code&gt; is built with plugin system in mind, so that we
could make a plugin for &lt;code&gt;httr&lt;/code&gt;, &lt;code&gt;RCurl&lt;/code&gt;, or any other http R library.&lt;/p&gt;

&lt;p&gt;I actually started &lt;code&gt;vcr&lt;/code&gt; first, but realized that I needed to go back and
build &lt;code&gt;webmockr&lt;/code&gt; first. So once &lt;code&gt;webmockr&lt;/code&gt; is up on CRAN, I&amp;rsquo;ll work on getting
&lt;code&gt;vcr&lt;/code&gt; on CRAN as well.&lt;/p&gt;

&lt;h3 id=&#34;errors&#34;&gt;Errors&lt;/h3&gt;

&lt;p&gt;Another package I&amp;rsquo;ve been working on, &lt;a href=&#34;https://github.com/sckott/fauxpas&#34;&gt;fauxpas&lt;/a&gt;, is meant to be a
general purpose HTTP errors package, and work with any HTTP R library.
Other similar languages like Ruby and Python have a better error story,
and I thought I&amp;rsquo;d try it out for R.  I&amp;rsquo;ll work on incorporating &lt;code&gt;fauxpas&lt;/code&gt;
into &lt;code&gt;crul&lt;/code&gt; as well, though probably in Suggests in case users don&amp;rsquo;t want
to use it.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>rOpenSci geospatial libraries</title>
      <link>https://ropensci.org/blog/2016/03/17/ropensci-geospatial-stack/</link>
      <pubDate>Thu, 17 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2016/03/17/ropensci-geospatial-stack/</guid>
      <description>
        
        

&lt;p&gt;Geospatial data input/output, manipulation, and vizualization are tasks that are common to many disciplines. Thus, we&amp;rsquo;re keenly interested in making great tools in this space. We have an increasing set of spatial tools, each of which we&amp;rsquo;ll cover sparingly. See the &lt;strong&gt;cran&lt;/strong&gt; and &lt;strong&gt;github&lt;/strong&gt; badges for more information.&lt;/p&gt;

&lt;p&gt;We are not trying to replace the current R geospatial libraries - rather, we&amp;rsquo;re trying to fill in gaps and create smaller tools to make it easy to plug in just the tools you need to your workflow.&lt;/p&gt;

&lt;h2 id=&#34;geojsonio&#34;&gt;geojsonio&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/geojsonio/&#34;&gt;&lt;span class=&#34;label label-warning&#34;&gt;cran&lt;/span&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ropensci/geojsonio&#34;&gt;&lt;span class=&#34;label label-info&#34;&gt;github&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ropensci/geojsonio&#34;&gt;geojsonio&lt;/a&gt; - A tool for converting to and from geojson data. Convert data to/from GeoJSON from various R classes, including vectors, lists, data frames, shape files, and spatial classes.&lt;/p&gt;

&lt;p&gt;e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;geojsonio&amp;quot;)
geojson_json(c(-99.74, 32.45), pretty = TRUE)
#&amp;gt; {
#&amp;gt;   &amp;quot;type&amp;quot;: &amp;quot;FeatureCollection&amp;quot;,
#&amp;gt;   &amp;quot;features&amp;quot;: [
#&amp;gt;     {
#&amp;gt;       &amp;quot;type&amp;quot;: &amp;quot;Feature&amp;quot;,
#&amp;gt;       &amp;quot;geometry&amp;quot;: {
#&amp;gt;         &amp;quot;type&amp;quot;: &amp;quot;Point&amp;quot;,
#&amp;gt;         &amp;quot;coordinates&amp;quot;: [-99.74, 32.45]
#&amp;gt;       },
#&amp;gt;       &amp;quot;properties&amp;quot;: {}
#&amp;gt;     }
#&amp;gt;   ]
#&amp;gt; }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;wellknown&#34;&gt;wellknown&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/wellknown/&#34;&gt;&lt;span class=&#34;label label-warning&#34;&gt;cran&lt;/span&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ropensci/wellknown&#34;&gt;&lt;span class=&#34;label label-info&#34;&gt;github&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ropensci/wellknown&#34;&gt;wellknown&lt;/a&gt; - A tool for converting to and from well-known text data. Convert WKT/WKB to GeoJSON and vice versa. Functions included for converting between GeoJSON to WKT/WKB, creating both GeoJSON features, and non-features, creating WKT/WKB from R objects (e.g., lists, data.frames, vectors), and linting WKT.&lt;/p&gt;

&lt;p&gt;e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;wellknown&amp;quot;)
point(data.frame(lon = -116.4, lat = 45.2))
#&amp;gt; [1] &amp;quot;POINT (-116.4000000000000057 45.2000000000000028)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;gistr&#34;&gt;gistr&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/gistr/&#34;&gt;&lt;span class=&#34;label label-warning&#34;&gt;cran&lt;/span&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ropensci/gistr&#34;&gt;&lt;span class=&#34;label label-info&#34;&gt;github&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ropensci/gistr&#34;&gt;gistr&lt;/a&gt; - This is not a geospatial tool per se, but it&amp;rsquo;s extremely useful for sharing maps. For example, with just a few lines, you can share an interactive map to GitHub.&lt;/p&gt;

&lt;p&gt;e.g. using &lt;code&gt;geojsonio&lt;/code&gt; from above&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;gistr&amp;quot;)
cat(geojson_json(us_cities[1:100,], lat = &#39;lat&#39;, lon = &#39;long&#39;), file = &amp;quot;map.geojson&amp;quot;)
gist_create(&amp;quot;map.geojson&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2016-03-17-ropensci-geospatial-stack/map.png&#34; alt=&#34;map&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;lawn&#34;&gt;lawn&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/lawn/&#34;&gt;&lt;span class=&#34;label label-warning&#34;&gt;cran&lt;/span&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ropensci/lawn&#34;&gt;&lt;span class=&#34;label label-info&#34;&gt;github&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;An R client for &lt;a href=&#34;http://turfjs.org/&#34;&gt;turf.js&lt;/a&gt;, an &lt;em&gt;Advanced geospatial analysis for browsers and node&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;lawn&lt;/code&gt; has a function for every method in &lt;code&gt;turf.js&lt;/code&gt;. In addition, there&amp;rsquo;s:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a few functions wrapping the
Node package &lt;code&gt;geojson-random&lt;/code&gt; &lt;a href=&#34;https://github.com/mapbox/geojson-random&#34;&gt;https://github.com/mapbox/geojson-random&lt;/a&gt; for making random geojson features&lt;/li&gt;
&lt;li&gt;a helper function &lt;code&gt;view()&lt;/code&gt; to easily visualize results from calls to &lt;code&gt;lawn&lt;/code&gt; functions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;lawn&amp;quot;)
lawn_hex_grid(c(-96,31,-84,40), 50, &#39;miles&#39;) %&amp;gt;% view
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2016-03-17-ropensci-geospatial-stack/hexgridmap.png&#34; alt=&#34;hexgridmap&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;geoaxe&#34;&gt;geoaxe&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/geoaxe/&#34;&gt;&lt;span class=&#34;label label-warning&#34;&gt;cran&lt;/span&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ropenscilabs/geoaxe&#34;&gt;&lt;span class=&#34;label label-info&#34;&gt;github&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;An R client for splitting geospatial objects into pieces.&lt;/p&gt;

&lt;p&gt;e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;geoaxe&amp;quot;)
library(&amp;quot;rgeos&amp;quot;)
wkt &amp;lt;- &amp;quot;POLYGON((-180 -20, -140 55, 10 0, -140 -60, -180 -20))&amp;quot;
poly &amp;lt;- rgeos::readWKT(wkt)
polys &amp;lt;- chop(x = poly)
plot(poly, lwd = 6, mar = c(0, 0, 0, 0))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2016-03-17-ropensci-geospatial-stack/unnamed-chunk-6-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-6&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Add chopped up polygon bits&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(polys, add = TRUE, mar = c(0, 0, 0, 0))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2016-03-17-ropensci-geospatial-stack/unnamed-chunk-7-1.png&#34; alt=&#34;plot of chunk unnamed-chunk-7&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;proj&#34;&gt;proj&lt;/h2&gt;

&lt;p&gt;&lt;span class=&#34;label label-default&#34;&gt;cran&lt;/span&gt; &lt;a href=&#34;https://github.com/ropensci/proj&#34;&gt;&lt;span class=&#34;label label-info&#34;&gt;github&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;An R client for &lt;a href=&#34;https://github.com/proj4js/proj4js&#34;&gt;proj4js&lt;/a&gt;, a Javascript library for projections.  &lt;code&gt;proj&lt;/code&gt; is not on CRAN yet.&lt;/p&gt;

&lt;h2 id=&#34;getlandsat&#34;&gt;getlandsat&lt;/h2&gt;

&lt;p&gt;&lt;span class=&#34;label label-default&#34;&gt;cran&lt;/span&gt; &lt;a href=&#34;https://github.com/ropenscilabs/getlandsat&#34;&gt;&lt;span class=&#34;label label-info&#34;&gt;github&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;An R client to fetch Landsat data from AWS public data sets. &lt;code&gt;getlandsat&lt;/code&gt; is not on CRAN yet.&lt;/p&gt;

&lt;p&gt;e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;getlandsat&amp;quot;)
head(lsat_scenes())
#&amp;gt;                entityId     acquisitionDate cloudCover processingLevel
#&amp;gt; 1 LC80101172015002LGN00 2015-01-02 15:49:05      80.81            L1GT
#&amp;gt; 2 LC80260392015002LGN00 2015-01-02 16:56:51      90.84            L1GT
#&amp;gt; 3 LC82270742015002LGN00 2015-01-02 13:53:02      83.44            L1GT
#&amp;gt; 4 LC82270732015002LGN00 2015-01-02 13:52:38      52.29             L1T
#&amp;gt; 5 LC82270622015002LGN00 2015-01-02 13:48:14      38.85             L1T
#&amp;gt; 6 LC82111152015002LGN00 2015-01-02 12:30:31      22.93            L1GT
#&amp;gt;   path row   min_lat    min_lon   max_lat    max_lon
#&amp;gt; 1   10 117 -79.09923 -139.66082 -77.75440 -125.09297
#&amp;gt; 2   26  39  29.23106  -97.48576  31.36421  -95.16029
#&amp;gt; 3  227  74 -21.28598  -59.27736 -19.17398  -57.07423
#&amp;gt; 4  227  73 -19.84365  -58.93258 -17.73324  -56.74692
#&amp;gt; 5  227  62  -3.95294  -55.38896  -1.84491  -53.32906
#&amp;gt; 6  211 115 -78.54179  -79.36148 -75.51003  -69.81645
#&amp;gt;                                                                                 download_url
#&amp;gt; 1 https://s3-us-west-2.amazonaws.com/landsat-pds/L8/010/117/LC80101172015002LGN00/index.html
#&amp;gt; 2 https://s3-us-west-2.amazonaws.com/landsat-pds/L8/026/039/LC80260392015002LGN00/index.html
#&amp;gt; 3 https://s3-us-west-2.amazonaws.com/landsat-pds/L8/227/074/LC82270742015002LGN00/index.html
#&amp;gt; 4 https://s3-us-west-2.amazonaws.com/landsat-pds/L8/227/073/LC82270732015002LGN00/index.html
#&amp;gt; 5 https://s3-us-west-2.amazonaws.com/landsat-pds/L8/227/062/LC82270622015002LGN00/index.html
#&amp;gt; 6 https://s3-us-west-2.amazonaws.com/landsat-pds/L8/211/115/LC82111152015002LGN00/index.html
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;siftgeojson&#34;&gt;siftgeojson&lt;/h2&gt;

&lt;p&gt;&lt;span class=&#34;label label-default&#34;&gt;cran&lt;/span&gt; &lt;a href=&#34;https://github.com/ropenscilabs/siftgeojson&#34;&gt;&lt;span class=&#34;label label-info&#34;&gt;github&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Slice and dice GeoJSON just as easily as you would a data.frame. This is built on top of &lt;code&gt;jqr&lt;/code&gt;, an R wrapper for &lt;a href=&#34;https://stedolan.github.io/jq/&#34;&gt;jq&lt;/a&gt;, a JSON processor.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;siftgeojson&amp;quot;)
# get sample data
file &amp;lt;- system.file(&amp;quot;examples&amp;quot;, &amp;quot;zillow_or.geojson&amp;quot;, package = &amp;quot;siftgeojson&amp;quot;)
json &amp;lt;- paste0(readLines(file), collapse = &amp;quot;&amp;quot;)
# sift to Multnomah County only, and check that only Multnomah County came back
sifter(json, COUNTY == Multnomah) %&amp;gt;% jqr::index() %&amp;gt;% jqr::dotstr(properties.COUNTY)
#&amp;gt; [
#&amp;gt;     &amp;quot;Multnomah&amp;quot;,
#&amp;gt;     &amp;quot;Multnomah&amp;quot;,
#&amp;gt;     &amp;quot;Multnomah&amp;quot;,
#&amp;gt;     &amp;quot;Multnomah&amp;quot;,
#&amp;gt;     &amp;quot;Multnomah&amp;quot;,
#&amp;gt;     &amp;quot;Multnomah&amp;quot;,
#&amp;gt;     &amp;quot;Multnomah&amp;quot;,
#&amp;gt;     &amp;quot;Multnomah&amp;quot;,
#&amp;gt;     &amp;quot;Multnomah&amp;quot;,
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;maps&#34;&gt;Maps&lt;/h2&gt;

&lt;p&gt;rOpenSci has an offering in this space: &lt;code&gt;plotly&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;plotly&#34;&gt;plotly&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/plotly/&#34;&gt;&lt;span class=&#34;label label-warning&#34;&gt;cran&lt;/span&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/ropensci/plotly&#34;&gt;&lt;span class=&#34;label label-info&#34;&gt;github&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ropensci/plotly&#34;&gt;plotly&lt;/a&gt; is an R client for &lt;a href=&#34;https://plot.ly/&#34;&gt;Plotly&lt;/a&gt; - a web interface and API for creating interactive graphics.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;plotly&amp;quot;)
plot_ly(iris, x = Petal.Length, y = Petal.Width,
        color = Species, mode = &amp;quot;markers&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2016-03-17-ropensci-geospatial-stack/plotly.png&#34; alt=&#34;plotly&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;maptools-task-view&#34;&gt;Maptools Task View&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ropensci/maptools&#34;&gt;&lt;span class=&#34;label label-info&#34;&gt;github&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://jwhollister.com/&#34;&gt;Jeff Hollister&lt;/a&gt; is leading the &lt;a href=&#34;https://github.com/ropensci/maptools&#34;&gt;maptools task view&lt;/a&gt; to organize R mapping tools packages, sources of data, projections, static and interactive mapping, data transformation, and more.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Curling - exploring web request options</title>
      <link>https://ropensci.org/blog/2014/12/18/curl-options/</link>
      <pubDate>Thu, 18 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/12/18/curl-options/</guid>
      <description>
        
        

&lt;p&gt;rOpenSci specializes in creating R libraries for accessing data resources on the web from R. Most times you request data from the web in R with our packages, you should have no problem. However, you evenutally will run into problems. In addition, there are advanced things you can do modifying requests to web resources that fall in the &lt;em&gt;advanced stuff&lt;/em&gt; category.&lt;/p&gt;

&lt;p&gt;Underlying almost all of our packages are requests to web resources served over the &lt;code&gt;http&lt;/code&gt; protocol via &lt;a href=&#34;http://curl.haxx.se/&#34;&gt;curl&lt;/a&gt;. &lt;code&gt;curl&lt;/code&gt; &lt;em&gt;is a command line tool and library for transferring data with URL syntax, supporting (lots of protocols)&lt;/em&gt; . &lt;code&gt;curl&lt;/code&gt; has many options that you may not know about.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll go over some of the common and less commonly used curl options, and try to explain why you may want to use some of them.&lt;/p&gt;

&lt;h2 id=&#34;discover-curl-options&#34;&gt;Discover curl options&lt;/h2&gt;

&lt;p&gt;You can go to the source, that is the curl manual page at &lt;a href=&#34;http://curl.haxx.se/docs/manpage.html&#34;&gt;http://curl.haxx.se/docs/manpage.html&lt;/a&gt;. In R: &lt;code&gt;RCurl::listCurlOptions()&lt;/code&gt; for finding curl options, give website for more info and equivalent call in &lt;code&gt;httr&lt;/code&gt; is &lt;code&gt;httr::httr_options()&lt;/code&gt;. &lt;code&gt;httr::httr_options()&lt;/code&gt; gives more information for each curl option, including the libcurl variable name (e.g., &lt;code&gt;CURLOPT_CERTINFO&lt;/code&gt;) and the type of variable (e.g., logical).&lt;/p&gt;

&lt;h2 id=&#34;other-ways-to-use-curl-besides-r&#34;&gt;Other ways to use curl besides R&lt;/h2&gt;

&lt;p&gt;Perhaps the canonical way to use curl is on the command line. You can get curl for your operating system at &lt;a href=&#34;http://curl.haxx.se/download.html&#34;&gt;http://curl.haxx.se/download.html&lt;/a&gt;, though hopefully you already have curl. Once you have curl, you can have lots of fun. For example, get the contents of the Google landing page:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl https://www.google.com
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;If you like that you may also like &lt;a href=&#34;https://github.com/jakubroztocil/httpie&#34;&gt;httpie&lt;/a&gt;, a Python command line tool that is a little more convenient than curl (e.g., JSON output is automatically parsed and colorized).&lt;/li&gt;
&lt;li&gt;Alot of data from the web is in JSON format. A great command line tool to pair with &lt;code&gt;curl&lt;/code&gt; is &lt;a href=&#34;http://stedolan.github.io/jq/&#34;&gt;jq&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: if you are on windows you may require extra setup if you want to play with curl on the command line. OSX and linux have it by default. On Windows 8, installing the latest version from here &lt;a href=&#34;http://curl.haxx.se/download.html#Win64&#34;&gt;http://curl.haxx.se/download.html#Win64&lt;/a&gt; worked for me.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;install-httr&#34;&gt;Install httr&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: &lt;code&gt;RCurl&lt;/code&gt; is a dependency, so you&amp;rsquo;ll get it when you install &lt;code&gt;httr&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;httr&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are some new features in &lt;code&gt;httr&lt;/code&gt; dev version you may want. If so, do:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;devtools&amp;quot;)
devtools::install_github(&amp;quot;hadley/httr&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Load &lt;code&gt;httr&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;httr&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;general-option-setting&#34;&gt;general option setting&lt;/h2&gt;

&lt;p&gt;With &lt;code&gt;httr&lt;/code&gt; you can either set globally for an R session like&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set_config(timeout(seconds = 2))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or use &lt;code&gt;with_config()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with_config(verbose(), {
  GET(&amp;quot;http://www.google.com/search&amp;quot;)
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or extensions to &lt;code&gt;with_*&lt;/code&gt;, like for &lt;code&gt;verbose&lt;/code&gt; output&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;with_verbose(
  GET(&amp;quot;http://www.google.com/search&amp;quot;)
)
#&amp;gt; Response [http://www.google.com/webhp]
#&amp;gt;   Date: 2014-12-17 07:54
#&amp;gt;   Status: 200
#&amp;gt;   Content-Type: text/html; charset=ISO-8859-1
#&amp;gt;   Size: 19.3 kB
#&amp;gt; &amp;lt;!doctype html&amp;gt;&amp;lt;html itemscope=&amp;quot;&amp;quot; itemtype=&amp;quot;http://schema.org/WebPage&amp;quot; l...
#&amp;gt; function _gjh(){!_gjuc()&amp;amp;&amp;amp;window.google&amp;amp;&amp;amp;google.x&amp;amp;&amp;amp;google.x({id:&amp;quot;GJH&amp;quot;},f...
#&amp;gt; if (!iesg){document.f&amp;amp;&amp;amp;document.f.q.focus();document.gbqf&amp;amp;&amp;amp;document.gbqf...
#&amp;gt; }
#&amp;gt; })();&amp;lt;/script&amp;gt;&amp;lt;div id=&amp;quot;mngb&amp;quot;&amp;gt;   &amp;lt;div id=gbar&amp;gt;&amp;lt;nobr&amp;gt;&amp;lt;b class=gb1&amp;gt;Search&amp;lt;/...
#&amp;gt; a.i.Z,window.gbar.elr&amp;amp;&amp;amp;a.i.$(window.gbar.elr()),window.gbar.elc&amp;amp;&amp;amp;window....
#&amp;gt; });})();&amp;lt;/script&amp;gt; &amp;lt;/div&amp;gt; &amp;lt;/span&amp;gt;&amp;lt;br clear=&amp;quot;all&amp;quot; id=&amp;quot;lgpd&amp;quot;&amp;gt;&amp;lt;div id=&amp;quot;lga&amp;quot;&amp;gt;...
#&amp;gt; });})();&amp;lt;/script&amp;gt;&amp;lt;/div&amp;gt;&amp;lt;/div&amp;gt;&amp;lt;span id=&amp;quot;footer&amp;quot;&amp;gt;&amp;lt;div style=&amp;quot;font-size:10p...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or pass into each function call&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;GET(&amp;quot;http://www.google.com/search&amp;quot;, query=list(q=&amp;quot;httr&amp;quot;), timeout(seconds = 0.5))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With &lt;code&gt;RCurl&lt;/code&gt; you can set options for a function call by passing curl options to the &lt;code&gt;.opts&lt;/code&gt; parameter&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;getForm(&amp;quot;http://www.google.com/search?q=RCurl&amp;quot;, btnG=&amp;quot;Search&amp;quot;, .opts = list(timeout.ms = 20))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For all examples below I&amp;rsquo;ll use &lt;code&gt;httr&lt;/code&gt;, and pass in config options to function calls.&lt;/p&gt;

&lt;h2 id=&#34;curl-options-in-ropensci-packages&#34;&gt;curl options in rOpenSci packages&lt;/h2&gt;

&lt;p&gt;In most of our packages we allow you to pass in any curl options, either via &lt;code&gt;...&lt;/code&gt; or a named parameter. We are increasingly making our packages consistent, but they may not all have this ability yet. For example, using the &lt;code&gt;rgbif&lt;/code&gt; package, an R client for &lt;a href=&#34;http://www.gbif.org/&#34;&gt;GBIF&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;rgbif&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;verbose output&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;rgbif&amp;quot;)
res &amp;lt;- occ_search(geometry=c(-125.0,38.4,-121.8,40.9), limit=20, config=verbose())
#&amp;gt; -&amp;gt; GET /v1/occurrence/search?geometry=POLYGON%28%28-125%2038.4%2C%20-121.8%2038.4%2C%20-121.8%2040.9%2C%20-125%2040.9%2C%20-125%2038.4%29%29&amp;amp;limit=20&amp;amp;offset=0 HTTP/1.1
#&amp;gt; -&amp;gt; User-Agent: curl/7.37.1 Rcurl/1.95.4.5 httr/0.6.0
#&amp;gt; -&amp;gt; Host: api.gbif.org
#&amp;gt; -&amp;gt; Accept-Encoding: gzip
#&amp;gt; -&amp;gt; Accept: application/json, text/xml, application/xml, */*
#&amp;gt; -&amp;gt;
#&amp;gt; &amp;lt;- HTTP/1.1 200 OK
#&amp;gt; &amp;lt;- Content-Type: application/json
#&amp;gt; &amp;lt;- Access-Control-Allow-Origin: *
#&amp;gt; &amp;lt;- Server: Jetty(9.1.z-SNAPSHOT)
#&amp;gt; &amp;lt;- x-api-url: /v1/occurrence/search?geometry=POLYGON%28%28-125%2038.4%2C%20-121.8%2038.4%2C%20-121.8%2040.9%2C%20-125%2040.9%2C%20-125%2038.4%29%29&amp;amp;limit=20&amp;amp;offset=0
#&amp;gt; &amp;lt;- Content-Length: 48698
#&amp;gt; &amp;lt;- Accept-Ranges: bytes
#&amp;gt; &amp;lt;- Date: Tue, 16 Dec 2014 23:35:52 GMT
#&amp;gt; &amp;lt;- X-Varnish: 1067986052 1067940827
#&amp;gt; &amp;lt;- Age: 209
#&amp;gt; &amp;lt;- Via: 1.1 varnish
#&amp;gt; &amp;lt;- Connection: keep-alive
#&amp;gt; &amp;lt;-
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Print progress&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- occ_search(geometry=c(-125.0,38.4,-121.8,40.9), limit=20, config=progress())
#&amp;gt; |===================================================================| 100%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can also combine curl options - use &lt;code&gt;c()&lt;/code&gt; in this case to combine them&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;c(verbose(), progress())
#&amp;gt; Config:
#&amp;gt; List of 4
#&amp;gt;  $ debugfunction   :function (...)
#&amp;gt;  $ verbose         :TRUE
#&amp;gt;  $ noprogress      :FALSE
#&amp;gt;  $ progressfunction:function (...)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- occ_search(geometry=c(-125.0,38.4,-121.8,40.9), limit=20, config=c(verbose(), progress()))
#&amp;gt; -&amp;gt; GET /v1/occurrence/search?geometry=POLYGON%28%28-125%2038.4%2C%20-121.8%2038.4%2C%20-121.8%2040.9%2C%20-125%2040.9%2C%20-125%2038.4%29%29&amp;amp;limit=20&amp;amp;offset=0 HTTP/1.1
#&amp;gt; -&amp;gt; User-Agent: curl/7.37.1 Rcurl/1.95.4.5 httr/0.6.0
#&amp;gt; -&amp;gt; Host: api.gbif.org
#&amp;gt; -&amp;gt; Accept-Encoding: gzip
#&amp;gt; -&amp;gt; Accept: application/json, text/xml, application/xml, */*
#&amp;gt; -&amp;gt;
#&amp;gt; &amp;lt;- HTTP/1.1 200 OK
#&amp;gt; &amp;lt;- Content-Type: application/json
#&amp;gt; &amp;lt;- Access-Control-Allow-Origin: *
#&amp;gt; &amp;lt;- Server: Jetty(9.1.z-SNAPSHOT)
#&amp;gt; &amp;lt;- x-api-url: /v1/occurrence/search?geometry=POLYGON%28%28-125%2038.4%2C%20-121.8%2038.4%2C%20-121.8%2040.9%2C%20-125%2040.9%2C%20-125%2038.4%29%29&amp;amp;limit=20&amp;amp;offset=0
#&amp;gt; &amp;lt;- Content-Length: 48698
#&amp;gt; &amp;lt;- Accept-Ranges: bytes
#&amp;gt; &amp;lt;- Date: Tue, 16 Dec 2014 23:35:52 GMT
#&amp;gt; &amp;lt;- X-Varnish: 1067986052 1067940827
#&amp;gt; &amp;lt;- Age: 209
#&amp;gt; &amp;lt;- Via: 1.1 varnish
#&amp;gt; &amp;lt;- Connection: keep-alive
#&amp;gt; &amp;lt;-
#&amp;gt;   |======================================================================| 100%
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;timeout&#34;&gt;timeout&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Set a timeout for a request. If request exceeds timeout, request stops.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;httr&lt;/code&gt;: &lt;code&gt;timeout(seconds=2)&lt;/code&gt; Here, the value is in seconds - converted to ms internally&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RCurl&lt;/code&gt;: &lt;code&gt;timeout.ms=2000&lt;/code&gt; Here, the value is in ms&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: For this section and those following, I&amp;rsquo;ll mention an &lt;code&gt;RCurl&lt;/code&gt; equivalent if there is one.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;GET(&amp;quot;http://www.google.com/search&amp;quot;, timeout(0.01))
#&amp;gt; Error in function (type, msg, asError = TRUE)  :
#&amp;gt;   Connection timed out after 16 milliseconds
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Why use this?&lt;/em&gt; You sometimes are working with a web resource that is somewhat unreliable. For example, if you want to run a script on a server that may take many hours, and the web resource could be down at some point during that time, you could set the timeout and error catch the response so that the script doesn&amp;rsquo;t hang on a server that&amp;rsquo;s not responding. Another example could be if you call a web resource in an R package. In your test suite, you may want to test that a web resource is responding quickly, so you could set a timeout, and not test if that fails.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;verbose&#34;&gt;verbose&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Print detailed info on a curl call&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;httr&lt;/code&gt;: &lt;code&gt;verbose()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RCurl&lt;/code&gt;: &lt;code&gt;verbose=TRUE&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Just do a &lt;code&gt;HEAD&lt;/code&gt; request so we don&amp;rsquo;t have to deal with big output&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HEAD(&amp;quot;http://www.google.com/search&amp;quot;, verbose())
#&amp;gt; -&amp;gt; HEAD / HTTP/1.1
#&amp;gt; -&amp;gt; User-Agent: curl/7.37.1 Rcurl/1.95.4.5 httr/0.6.0
#&amp;gt; -&amp;gt; Host: had.co.nz
#&amp;gt; -&amp;gt; Accept-Encoding: gzip
#&amp;gt; -&amp;gt; Accept: application/json, text/xml, application/xml, */*
#&amp;gt; -&amp;gt;
#&amp;gt; &amp;lt;- HTTP/1.1 200 OK
#&amp;gt; &amp;lt;- X-Powered-By: PHP/4.4.6
#&amp;gt; &amp;lt;- Content-type: text/html
#&amp;gt; &amp;lt;- Date: Tue, 16 Dec 2014 21:03:21 GMT
#&amp;gt; &amp;lt;- Server: LiteSpeed
#&amp;gt; &amp;lt;- Connection: Keep-Alive
#&amp;gt; &amp;lt;- Keep-Alive: timeout=5, max=100
#&amp;gt; &amp;lt;-
#&amp;gt; Response [http://had.co.nz/]
#&amp;gt;   Date: 2014-12-16 12:29
#&amp;gt;   Status: 200
#&amp;gt;   Content-Type: text/html
#&amp;gt; &amp;lt;EMPTY BODY&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Why use this?&lt;/em&gt; As you can see verbose output gives you lots of information that may be useful for debugging a request. You typically don&amp;rsquo;t need verbose output unless you want to inspect a request.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;headers&#34;&gt;headers&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Add headers to modify requests, including authentication, setting content-type, accept type, etc.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;httr&lt;/code&gt;: &lt;code&gt;add_headers()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RCurl&lt;/code&gt;: &lt;code&gt;httpheader&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- HEAD(&amp;quot;http://www.google.com/search&amp;quot;, add_headers(Accept = &amp;quot;application/json&amp;quot;))
res$request$opts$httpheader
#&amp;gt;             Accept
#&amp;gt; &amp;quot;application/json&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Note: there are shortcuts for &lt;code&gt;add_headers(Accept = &amp;quot;application/json&amp;quot;)&lt;/code&gt; and add_headers(Accept = &amp;ldquo;application/xml&amp;rdquo;): &lt;code&gt;accept_json()&lt;/code&gt;, and &lt;code&gt;accept_xml()&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Why use this?&lt;/em&gt; For some web resources, using headers is mandatory, and &lt;code&gt;httr&lt;/code&gt; makes including them quite easy. Headers are nice too because e.g., passing authentication in the header instead of the URL string means your private data is not as exposed to prying eyes.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;authenticate&#34;&gt;authenticate&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Set authentication details for a resource&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;httr&lt;/code&gt;: &lt;code&gt;authenticate()&lt;/code&gt;, &lt;code&gt;oauth2.0_token()&lt;/code&gt;, &lt;code&gt;oauth_app()&lt;/code&gt;, &lt;code&gt;oauth_endpoint()&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RCurl&lt;/code&gt;: various&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;authenticate()&lt;/code&gt; for basic username/password authentication&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;authenticate(user = &amp;quot;foo&amp;quot;, password = &amp;quot;bar&amp;quot;)
#&amp;gt; Config:
#&amp;gt; List of 2
#&amp;gt;  $ httpauth:1
#&amp;gt;   ..- attr(*, &amp;quot;names&amp;quot;)=&amp;quot;basic&amp;quot;
#&amp;gt;  $ userpwd :&amp;quot;foo:bar&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To use an API key, this depends on the data provider. They may request it one or either of the header (in multiple different ways)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HEAD(&amp;quot;http://www.google.com/search&amp;quot;, add_headers(Authorization = &amp;quot;Bearer 234kqhrlj2342&amp;quot;))
# or
HEAD(&amp;quot;http://www.google.com/search&amp;quot;, add_headers(&amp;quot;token&amp;quot; = &amp;quot;234kqhrlj2342&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or as a query parameter (which is passed in the URL string)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;HEAD(&amp;quot;http://www.google.com/search&amp;quot;, query = list(api_key = &amp;quot;&amp;lt;your key&amp;gt;&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Another authentication options is OAuth workflows. &lt;code&gt;OAuth2&lt;/code&gt; is probably more commonly used than &lt;code&gt;OAuth1&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Find OAuth settings for github &lt;a href=&#34;http://developer.github.com/v3/oauth/&#34;&gt;http://developer.github.com/v3/oauth/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;endpts &amp;lt;- oauth_endpoint(authorize = &amp;quot;authorize&amp;quot;, access = &amp;quot;access_token&amp;quot;, base_url = &amp;quot;https://github.com/login/oauth&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Register an application at &lt;a href=&#34;https://github.com/settings/applications&#34;&gt;https://github.com/settings/applications&lt;/a&gt;. Use any URL you would like for the homepage URL (&lt;a href=&#34;http://github.com&#34;&gt;http://github.com&lt;/a&gt; is fine) and &lt;a href=&#34;http://localhost:1410&#34;&gt;http://localhost:1410&lt;/a&gt; as the callback url. Insert your client ID and secret below - if secret is omitted, it will look it up in the GITHUB_CONSUMER_SECRET environmental variable.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;myapp &amp;lt;- oauth_app(appname = &amp;quot;github&amp;quot;, key = &amp;quot;&amp;lt;key&amp;gt;&amp;quot;, secret = &amp;quot;&amp;lt;secret&amp;gt;&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Get OAuth credentials&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;github_token &amp;lt;- oauth2.0_token(endpts, myapp)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Use API&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gtoken &amp;lt;- config(token = github_token)
req &amp;lt;- GET(&amp;quot;https://api.github.com/rate_limit&amp;quot;, gtoken)
content(req)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cookies&#34;&gt;cookies&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Set or get cookies.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;httr&lt;/code&gt;: &lt;code&gt;set_cookies()&lt;/code&gt;, &lt;code&gt;cookies()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RCurl&lt;/code&gt;: &lt;code&gt;cookie&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Set cookies&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;GET(&amp;quot;http://httpbin.org/cookies&amp;quot;, set_cookies(a = 1, b = 2))
#&amp;gt; Response [http://httpbin.org/cookies]
#&amp;gt;   Date: 2014-12-17 07:54
#&amp;gt;   Status: 200
#&amp;gt;   Content-Type: application/json
#&amp;gt;   Size: 50 B
#&amp;gt; {
#&amp;gt;   &amp;quot;cookies&amp;quot;: {
#&amp;gt;     &amp;quot;a&amp;quot;: &amp;quot;1&amp;quot;,
#&amp;gt;     &amp;quot;b&amp;quot;: &amp;quot;2&amp;quot;
#&amp;gt;   }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If there are cookies in a response, you can access them easily with &lt;code&gt;cookies()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- GET(&amp;quot;http://httpbin.org/cookies/set&amp;quot;, query = list(a = 1, b = 2))
cookies(res)
#&amp;gt; $b
#&amp;gt; [1] 2
#&amp;gt;
#&amp;gt; $a
#&amp;gt; [1] 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;progress&#34;&gt;progress&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Print curl progress&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;httr&lt;/code&gt;: &lt;code&gt;progress()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RCurl&lt;/code&gt;: &lt;code&gt;progressfunction&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- GET(&amp;quot;http://httpbin.org&amp;quot;, progress())
#&amp;gt; |==================================| 100%
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Why use this?&lt;/em&gt; As you could imagine, this is increasingly useful as a request for a web resource takes longer and longer. For very long requests, this will help you know approximately when a request will finish.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;proxies&#34;&gt;proxies&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;When behind a proxy, give authentiction details for your proxy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;httr&lt;/code&gt;: &lt;code&gt;use_proxy()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RCurl&lt;/code&gt;: See various curl options that start with &lt;code&gt;proxy&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;GET(&amp;quot;http://www.google.com/search&amp;quot;, use_proxy(url = &amp;quot;125.39.66.66&amp;quot;, port = 80, username = &amp;quot;username&amp;quot;, password = &amp;quot;password&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Why use this?&lt;/em&gt; Most of us likely don&amp;rsquo;t need to worry about this. However, if you are in a work place, or maybe in certain geographic locations, you may have to use a proxy. I haven&amp;rsquo;t personally used a proxy in R, so any feedback on this is great.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;user-agent&#34;&gt;user agent&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Some resources require a user-agent string.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;httr&lt;/code&gt;: &lt;code&gt;user_agent()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RCurl&lt;/code&gt;: &lt;code&gt;useragent&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Get the default user agent set if using &lt;code&gt;httr&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;GET(&amp;quot;http://httpbin.org/user-agent&amp;quot;)
#&amp;gt; Response [http://httpbin.org/user-agent]
#&amp;gt;   Date: 2014-12-17 07:54
#&amp;gt;   Status: 200
#&amp;gt;   Content-Type: application/json
#&amp;gt;   Size: 59 B
#&amp;gt; {
#&amp;gt;   &amp;quot;user-agent&amp;quot;: &amp;quot;curl/7.37.1 Rcurl/1.95.4.5 httr/0.6.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Set a user agent string&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;GET(&amp;quot;http://httpbin.org/user-agent&amp;quot;, user_agent(&amp;quot;its me!&amp;quot;))
#&amp;gt; Response [http://httpbin.org/user-agent]
#&amp;gt;   Date: 2014-12-17 07:54
#&amp;gt;   Status: 200
#&amp;gt;   Content-Type: application/json
#&amp;gt;   Size: 29 B
#&amp;gt; {
#&amp;gt;   &amp;quot;user-agent&amp;quot;: &amp;quot;its me!&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Why use this?&lt;/em&gt; This is set by default in a http request, as you can see in the first example above for user agent. Some web APIs require that you set a specific user agent. For example, the &lt;a href=&#34;https://developer.github.com/v3/#user-agent-required&#34;&gt;GitHub API&lt;/a&gt; requires that you include a user agent string in the header of each request that is your username or the name of your application so they can contact you if there is a problem.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;questions&#34;&gt;Questions?&lt;/h2&gt;

&lt;p&gt;Let us know if you have any questions. To a &lt;code&gt;curl&lt;/code&gt; newbie, it may seem a bit overwhelming, but we&amp;rsquo;re here to help.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Changes in rnoaa v0.2.0</title>
      <link>https://ropensci.org/blog/2014/07/21/rnoaa_v02/</link>
      <pubDate>Mon, 21 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/07/21/rnoaa_v02/</guid>
      <description>
        
        

&lt;p&gt;We just released &lt;code&gt;v0.2&lt;/code&gt; of &lt;code&gt;rnoaa&lt;/code&gt;. For details on the update, see the &lt;a href=&#34;https://github.com/ropensci/rnoaa/releases/tag/v0.2.0&#34;&gt;release notes&lt;/a&gt;. What follows are some notes on the more important changes.&lt;/p&gt;

&lt;h2 id=&#34;updating-to-v0-2&#34;&gt;Updating to v0.2&lt;/h2&gt;

&lt;p&gt;Install &lt;code&gt;rnoaa&lt;/code&gt; from CRAN&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;rnoaa&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or Github&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&amp;quot;ropensci/rnoaa&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then load &lt;code&gt;rnoaa&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;rnoaa&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ui-changes&#34;&gt;UI changes&lt;/h2&gt;

&lt;p&gt;We changed almost all function names to have a more intuitive programmatic user interface (or &lt;em&gt;UI&lt;/em&gt;).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We changed all &lt;code&gt;noaa*()&lt;/code&gt; functions to &lt;code&gt;ncdc*()&lt;/code&gt; - these work only with NOAA National Climatic Data Center (NCDC) data, so the &lt;code&gt;ncdc&lt;/code&gt; name makes sense.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;noaa_seaice()&lt;/code&gt; changed to &lt;code&gt;seaice()&lt;/code&gt;, which works with NOAA sea ice data.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;noaa_swdi()&lt;/code&gt; changed to &lt;code&gt;swdi()&lt;/code&gt;, which works with data from the Severe Weather Data Inventory.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;two-new-data-sources&#34;&gt;Two new data sources&lt;/h2&gt;

&lt;h3 id=&#34;erddap&#34;&gt;ERDDAP&lt;/h3&gt;

&lt;p&gt;We added new functions to interact with &lt;a href=&#34;http://coastwatch.pfeg.noaa.gov/erddap/index.html&#34;&gt;NOAA ERDDAP data&lt;/a&gt;: &lt;code&gt;erddap_info()&lt;/code&gt;, &lt;code&gt;erddap_data()&lt;/code&gt;, and &lt;code&gt;erddap_search()&lt;/code&gt;. As a quick example, let&amp;rsquo;s search for data, get a dataset identifier, then get information on that dataset, then get the data.&lt;/p&gt;

&lt;p&gt;Search for data&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(out &amp;lt;- erddap_search(query=&#39;fish size&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 7 results, showing first 20
##                                         title          dataset_id
## 1                          CalCOFI Fish Sizes    erdCalCOFIfshsiz
## 2                        CalCOFI Larvae Sizes    erdCalCOFIlrvsiz
## 3                                CalCOFI Tows      erdCalCOFItows
## 4     GLOBEC NEP MOCNESS Plankton (MOC1) Data       erdGlobecMoc1
## 5 GLOBEC NEP Vertical Plankton Tow (VPT) Data        erdGlobecVpt
## 6         CalCOFI Larvae Counts Positive Tows erdCalCOFIlrvcntpos
## 7  OBIS - ARGOS Satellite Tracking of Animals           aadcArgos
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using a datasetid, search for information on a datasetid&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(id &amp;lt;- out$info$dataset_id[1])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;erdCalCOFIfshsiz&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;erddap_info(datasetid=id)$variables
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##           variable_name data_type           actual_range
## 1  calcofi_species_code       int               19, 1550
## 2           common_name    String
## 3                cruise    String
## 4           fish_1000m3     float
## 5            fish_count     float
## 6             fish_size     float
## 7              itis_tsn       int
## 8              latitude     float         32.515, 38.502
## 9                  line     float             46.6, 93.3
## 10            longitude     float        -128.5, -117.33
## 11         net_location    String
## 12             net_type    String
## 13       order_occupied       int
## 14       percent_sorted     float
## 15       sample_quality     float
## 16      scientific_name    String
## 17                 ship    String
## 18            ship_code    String
## 19 standard_haul_factor     float
## 20              station     float            28.0, 114.9
## 21                 time    double 9.94464E8, 9.9510582E8
## 22           tow_number       int                  2, 10
## 23             tow_type    String
## 24       volume_sampled     float
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get data from the dataset, sticking to three variables for brevity&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dat &amp;lt;- erddap_data(datasetid = id, fields = c(&#39;latitude&#39;,&#39;longitude&#39;,&#39;scientific_name&#39;))
head(dat)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    latitude  longitude       scientific_name
## 2 35.038334 -120.88333 Microstomus pacificus
## 3  34.97167 -121.02333    Cyclothone signata
## 4  34.97167 -121.02333    Cyclothone signata
## 5  34.97167 -121.02333    Cyclothone signata
## 6  34.97167 -121.02333    Cyclothone signata
## 7  34.97167 -121.02333    Cyclothone signata
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;NROW(dat)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] 20939
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;buoys&#34;&gt;Buoys!&lt;/h3&gt;

&lt;p&gt;We added functions to get data from the &lt;a href=&#34;http://www.ndbc.noaa.gov/&#34;&gt;NOAA data buoy center&lt;/a&gt;. Keep in mind you have to install an external library to R called &lt;code&gt;netcdf&lt;/code&gt;, and an R pacakge called &lt;code&gt;ncdf4&lt;/code&gt;. See &lt;a href=&#34;https://github.com/ropensci/rnoaa#important---buoy-data&#34;&gt;the source package README&lt;/a&gt; for more help. Install the &lt;code&gt;buoy&lt;/code&gt; branch from Github:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&amp;quot;rnoaa&amp;quot;, &amp;quot;ropensci&amp;quot;, ref=&amp;quot;buoy&amp;quot;)
library(&#39;rnoaa&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(out &amp;lt;- buoy(dataset = &#39;pwind&#39;, buoyid = 41021))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Available buoys in pwind:
41001 41002 41004 41006 41008 41009 41010 41012 41013 41021 41022 41023 41025 41035 41036 41040 41041 41043 41044 41046 41047 41048 41049 42001 42002 42003 42007 42012 42019 42020 42035 42036 42038 42039 42040 42041 42054 42055 42056 42057 42058 42059 42060 42065 42otp 44004 44005 44007 44008 44009 44011 44013 44014 44017 44018 44020 44025 44027 44028 44065 44066 45001 45002 45003 45004 45005 45006 45007 45008 45011 45012 46001 46002 46003 46005 46006 46011 46012 46013 46014 46015 46022 46023 46025 46026 46027 46028 46029 46030 46035 46041 46042 46044 46045 46047 46050 46051 46053 46054 46059 46060 46061 46062 46063 46066 46069 46070 46071 46072 46073 46075 46076 46077 46078 46079 46080 46081 46082 46083 46084 46085 46086 46087 46088 46089 46106 46270 51000 51001 51002 51003 51004 51028 51100 51101 alsn6 amaa2 amps2 amps3 amps4 auga2 blia2 burl1 buzm3 caro3 cdrf1 chlv2 clkn7 csbf1 dbln6 desw1 disw3 dpia1 drfa2 dryf1 dsln7 ducn7 fbis1 ffia2 fila2 fpsn7 fwyf1 gbcl1 gdil1 glln6 iosn3 ktnf1 lkwf1 lmbv4 lonf1 lscm4 mdrm1 mism1 mlrf1 mpcl1 mrka2 nwpo3 ostf1 pila2 pilm4 plsf1 pota2 ptac1 ptat2 ptgc1 roam4 sacv4 sanf1 sauf1 sbio1 sgnw3 sgof1 sisw1 smkf1 spgf1 srst2 stdm4 svls1 tplm2 ttiw1 venf1 verv4 wpow1
Available files for buoy 41021:
p1996.nc
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Dimensions: [rows 4797, cols 3]
3 variables: [gust_dir, gust_spd, gust_time]

   gust_dir gust_spd gust_time
1       153      1.3 827105820
2        87      2.0 827106720
3        52      2.5 827110320
4        85      7.1 827113920
5       119      5.7 827117520
6        78      3.3 827121120
7       147     22.1 827124720
8       348      2.5 827128320
9        74      0.5 827134980
10       92      0.6 827137920
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out$metadata[1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;$gust_dir
$gust_dir$name
[1] &amp;quot;gust_dir&amp;quot;

$gust_dir$prec
[1] &amp;quot;int&amp;quot;

$gust_dir$units
[1] &amp;quot;degrees_true&amp;quot;

$gust_dir$longname
[1] &amp;quot;Gust Direction&amp;quot;

$gust_dir$missval
[1] 999

$gust_dir$hasAddOffset
[1] FALSE

$gust_dir$hasScaleFact
[1] FALSE
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(out$data); tail(out$data)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;  gust_dir gust_spd gust_time
1      153      1.3 827105820
2       87      2.0 827106720
3       52      2.5 827110320
4       85      7.1 827113920
5      119      5.7 827117520
6       78      3.3 827121120
     gust_dir gust_spd gust_time
4792       33     16.6 848164800
4793       21     15.6 848168340
4794       10     14.8 848172660
4795       19     15.9 848176140
4796       19     15.5 848177640
4797       25     14.4 848181420
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;more-help&#34;&gt;More help!&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve added new vignettes, including one for NCDC attributes, one for an example NCDC workflow, a Seaice vignette, an SWDI vignette, an ERDDAP vignette, and a vignette for NOAA buoy data. The buoy functions and vignette is only available on the Github &lt;code&gt;buoy&lt;/code&gt; branch.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>taxize v0.3.0 update - a new data source, taxonomy in writing, and uBio examples</title>
      <link>https://ropensci.org/blog/2014/05/20/taxize_v03/</link>
      <pubDate>Tue, 20 May 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/05/20/taxize_v03/</guid>
      <description>
        
        

&lt;p&gt;We just released &lt;code&gt;v0.3&lt;/code&gt; of &lt;code&gt;taxize&lt;/code&gt;. For details on the update, see the &lt;a href=&#34;https://github.com/ropensci/taxize/releases/tag/v0.3.0&#34;&gt;release notes&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;some-new-features&#34;&gt;Some new features&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;New function &lt;code&gt;iplant_resolve()&lt;/code&gt; to do name resolution using the iPlant name resolution service. Note, this is different from &lt;a href=&#34;http://taxosaurus.org/&#34;&gt;http://taxosaurus.org/&lt;/a&gt; that is wrapped in the &lt;code&gt;tnrs()&lt;/code&gt; function.&lt;/li&gt;
&lt;li&gt;New function &lt;code&gt;ipni_search()&lt;/code&gt; to search for names in the International Plant Names Index (IPNI). See below for more.&lt;/li&gt;
&lt;li&gt;New function &lt;code&gt;resolve()&lt;/code&gt; that unifies name resolution services from iPlant&amp;rsquo;s name resolution service (via &lt;code&gt;iplant_resolve()&lt;/code&gt;), Taxosaurus&amp;rsquo; TNRS (via &lt;code&gt;tnrs()&lt;/code&gt;), and GNR&amp;rsquo;s name resolution service (via &lt;code&gt;gnr_resolve()&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;All &lt;code&gt;get_&lt;/code&gt; functions now returning a new &lt;em&gt;uri&lt;/em&gt; attribute that is a link to the taxon on the web. If NA is given back (e.g. nothing found), the uri attribute is blank. You can go directly to the uri in your default browser by doing, for example: &lt;code&gt;browseURL(attr(result, &amp;quot;uri&amp;quot;))&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;updating-to-v0-3&#34;&gt;Updating to v0.3&lt;/h2&gt;

&lt;p&gt;Since &lt;code&gt;taxize&lt;/code&gt; is not updated to &lt;code&gt;v0.3&lt;/code&gt; on CRAN yet at the time of writing this, install &lt;code&gt;taxize&lt;/code&gt; from GitHub:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::install_github(&amp;quot;ropensci/taxize&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then load &lt;code&gt;taxize&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;taxize&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;international-plant-names-index-ipni&#34;&gt;International Plant Names Index (IPNI)&lt;/h2&gt;

&lt;p&gt;We added the IPNI as a new data source in &lt;code&gt;taxize&lt;/code&gt; in &lt;code&gt;v0.3&lt;/code&gt;. Currently, there is only one function to interact with IPNI: &lt;code&gt;ipni_search()&lt;/code&gt;. What follows are a few examples of how you can use &lt;code&gt;ipni_search()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Search for the genus &lt;em&gt;Brintonia&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ipni_search(genus=&#39;Brintonia&#39;)[,c(1:3)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##         id version     family
## 1   7996-1     1.3 Asteraceae
## 2 296073-2     1.3 Asteraceae
## 3  36551-2     1.3 Asteraceae
## 4 186337-1     1.3 Asteraceae
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Search for the species &lt;em&gt;Pinus contorta&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(ipni_search(genus=&#39;Pinus&#39;, species=&#39;contorta&#39;)[,c(1:3)])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##           id     version   family
## 1   262873-1 1.1.2.1.1.2 Pinaceae
## 2   262872-1 1.2.2.1.1.1 Pinaceae
## 3 30000492-2     1.1.2.1 Pinaceae
## 4   196950-2         1.4 Pinaceae
## 5   921291-1         1.4 Pinaceae
## 6   196949-2         1.5 Pinaceae
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Different output formats (the default is &lt;em&gt;minimal&lt;/em&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(ipni_search(genus=&#39;Ceanothus&#39;)[,c(1:3)])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##           id     version     family
## 1    55268-3         1.1 Rhamnaceae
## 2 30006383-2 1.1.2.1.1.3 Rhamnaceae
## 3    55269-3         1.1 Rhamnaceae
## 4    33421-1         1.5 Rhamnaceae
## 5 60461578-2         1.1 Rhamnaceae
## 6   331948-2         1.4 Rhamnaceae
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(ipni_search(genus=&#39;Ceanothus&#39;, output=&#39;extended&#39;))[,c(1:3)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##           id     version     family
## 1    55269-3         1.1 Rhamnaceae
## 2    33421-1         1.5 Rhamnaceae
## 3    55268-3         1.1 Rhamnaceae
## 4 30006383-2 1.1.2.1.1.3 Rhamnaceae
## 5 60461578-2         1.1 Rhamnaceae
## 6   331948-2         1.4 Rhamnaceae
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you do something wrong, you get a message, and the actual output is &lt;code&gt;NA&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ipni_search(genus=&#39;Brintoniaasasf&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Warning: No data found
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] NA
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ubio-examples&#34;&gt;uBio examples&lt;/h2&gt;

&lt;p&gt;Until now, we have had functions to interact with uBio&amp;rsquo;s API, but it probably hasn&amp;rsquo;t been too clear how to use them, and they were a little buggy for sure. We have squashed many bugs in ubio functions. Here is an example workflow of how to use ubio functions.&lt;/p&gt;

&lt;h3 id=&#34;ubio-search&#34;&gt;ubio_search&lt;/h3&gt;

&lt;p&gt;Search uBio by taxonomic name. This is sort of the entry point for uBio where you can search by taxonomic name, from which  you can get namebankID&amp;rsquo;s that can be passed to the &lt;code&gt;ubio_classification_search&lt;/code&gt; and &lt;code&gt;ubio_namebankID&lt;/code&gt; functions&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lapply(ubio_search(searchName = &#39;elephant&#39;), head)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $scientific
##   namebankid       namestring   fullnamestring packageid packagename
## 1    6938660 Cerylon elephant Cerylon elephant        80 Cerylonidae
##   basionymunit rankid rankname
## 1      6938660     24  species
##
## $vernacular
##   namebankid    namestring languagecode    languagename packageid
## 1    8118711 Elephant fish          115 Creole, English         3
## 2    8118714 Elephant fish          115 Creole, English         3
## 3    8118726 Elephant fish          115 Creole, English         3
## 4    8115700 Elephant fish          115 Creole, English         3
## 5    8115663 Elephant fish          115 Creole, English         3
## 6    8114377 Elephant fish          115 Creole, English      2463
##   packagename namebankidlink   namestringlink
## 1      Pisces         132263 Mormyrus tapirus
## 2      Pisces         132258 Mormyrus tapirus
## 3      Pisces         181174 Mormyrus tapirus
## 4      Pisces         128971 Mormyrus tapirus
## 5      Pisces         128972 Mormyrus tapirus
## 6  Mormyridae        2299821 Mormyrus tapirus
##                  fullnamestringlink
## 1 Mormyrus tapirus Pappenheim, 1905
## 2 Mormyrus tapirus Pappenheim, 1905
## 3 Mormyrus tapirus Pappenheim, 1905
## 4 Mormyrus tapirus Pappenheim, 1905
## 5 Mormyrus tapirus Pappenheim, 1905
## 6 Mormyrus tapirus Pappenheim, 1905
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;id &amp;lt;- ubio_search(searchName = &#39;elephant&#39;)$scientific$namebankid[1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Error: CHAR() can only be applied to a &#39;CHARSXP&#39;, not a &#39;NULL&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ubio-id&#34;&gt;ubio_id&lt;/h3&gt;

&lt;p&gt;Get data on a specific uBio &lt;code&gt;namebankID&lt;/code&gt;. Use the id from the previous code block&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ubio_id(namebankID = id)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $data
##   namebankid       namestring   fullnamestring packageid packagename
## 1    6938660 Cerylon elephant Cerylon elephant        80 Cerylonidae
##   basionymunit rankid rankname
## 1      6938660     24  Species
##
## $synonyms
## NULL
##
## $vernaculars
## NULL
##
## $cites
## NULL
##
## $mappings
## NULL
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ubio-classification-search&#34;&gt;ubio_classification_search&lt;/h3&gt;

&lt;p&gt;Return &lt;code&gt;hierarchiesID&lt;/code&gt; that refer to the given &lt;code&gt;namebankID&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ubio_classification_search(namebankID = 3070378)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##   hierarchiesid classificationtitleid              classificationtitle
## 1       2477072                    84                    NCBI Taxonomy
## 2      11166818                   100                    NCBI Taxonomy
## 3      17950600                   104 uBiota 2008-03-20T10:36:50-04:00
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ubio-classification&#34;&gt;ubio_classification&lt;/h3&gt;

&lt;p&gt;Return all ClassificationBank data pertaining to a particular &lt;code&gt;hierarchiesID&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ubio_classification(hierarchiesID = 2483153)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Error: XML content does not seem to be XML: &#39;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ubio-synonyms&#34;&gt;ubio_synonyms&lt;/h3&gt;

&lt;p&gt;Search for taxonomic synonyms by &lt;code&gt;hierarchiesID&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ubio_synonyms(hierarchiesID = 4091702)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Error: invalid subscript type &#39;list&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;examples-of-using-taxize-in-writing&#34;&gt;Examples of using taxize in writing&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s say one is writing a paragraph in which you are using taxonomic or common names, and perhaps you want to have the number of taxa in a particular group. You can write a paragaph like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;I studied the common weed species _Tragopogon dubius_ (`r sci2comm(&#39;Tragopogon dubius&#39;, db=&#39;itis&#39;)[[1]][1]`; `r tax_name(query = &amp;quot;Tragopogon dubius&amp;quot;, get = &amp;quot;family&amp;quot;, db = &amp;quot;ncbi&amp;quot;)[[1]]`) and _Cirsium arvense_ (`r sci2comm(&#39;Cirsium arvense&#39;, db=&#39;itis&#39;)[[1]][1]`; `r tax_name(query = &amp;quot;Cirsium arvense&amp;quot;, get = &amp;quot;family&amp;quot;, db = &amp;quot;ncbi&amp;quot;)[[1]]`).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which renders to:&lt;/p&gt;

&lt;p&gt;I studied the common weed species &lt;em&gt;Tragopogon dubius&lt;/em&gt; (yellow salsify; Asteraceae) and &lt;em&gt;Cirsium arvense&lt;/em&gt; (Canada thistle; Asteraceae).&lt;/p&gt;

&lt;p&gt;Notice how inside backticks you can execute code by starting with an &lt;em&gt;r&lt;/em&gt;, then doing something like searching for common names for a taxon.&lt;/p&gt;

&lt;h3 id=&#34;another-example&#34;&gt;Another example:&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;We found that `r sci2comm(&#39;Tragopogon dubius&#39;, db=&#39;itis&#39;)[[1]][1]` was very invasive.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Renders to:&lt;/p&gt;

&lt;p&gt;We found that yellow salsify was very invasive.&lt;/p&gt;

&lt;h3 id=&#34;another-example-1&#34;&gt;Another example:&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;There are `r nrow(downstream(&#39;Tragopogon&#39;, db = &amp;quot;col&amp;quot;, downto = &amp;quot;Species&amp;quot;)$Tragopogon)` species (source: Catalogue of Life) in the _Tragopogon_ genus, meaning there is much more to study :)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Renders to:&lt;/p&gt;

&lt;p&gt;There are 142 species (source: Catalogue of Life) in the &lt;em&gt;Tragopogon&lt;/em&gt; genus, meaning there is much more to study :)&lt;/p&gt;

&lt;h2 id=&#34;el-fin&#34;&gt;el fin&lt;/h2&gt;

&lt;p&gt;Please do update to &lt;code&gt;v0.3&lt;/code&gt;, try it out, report bugs, and get back to us with any questions!&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Overlaying species occurrence data with climate data</title>
      <link>https://ropensci.org/blog/2014/04/22/rwbclimate-sp/</link>
      <pubDate>Tue, 22 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/04/22/rwbclimate-sp/</guid>
      <description>
        
        &lt;p&gt;One of the goals of the rOpenSci is to facilitate interoperability between different data sources around web with our tools.  We can achieve this by providing functionality within our packages that converts data coming down via web APIs in one format (often a provider specific schema) into a standard format.  The new version of &lt;a href=&#34;http://github.com/ropensci/rwbclimate&#34;&gt;rWBclimate&lt;/a&gt; that we just posted to &lt;a href=&#34;http://cran.r-project.org/web/packages/rWBclimate/index.html&#34;&gt;CRAN&lt;/a&gt; does just that.  In an &lt;a href=&#34;http://www.ropensci.org/blog/2013/07/29/rWBclimate-rgbif/&#34;&gt;earlier post&lt;/a&gt; I wrote about how users could combine data from both &lt;a href=&#34;http://github.com/ropensci/rgbif&#34;&gt;rgbif&lt;/a&gt; and &lt;code&gt;rWBclimate&lt;/code&gt;. Back then I just thought it was pretty cool that you could overlay the points on a nice climate map.  Now we&amp;rsquo;ve come a long way, with the development of an easier to use and more comprehensive package for accessing species occurrence data, &lt;a href=&#34;http://github.com/ropensci/spocc&#34;&gt;spocc&lt;/a&gt;, and added conversion functions to create spatial objects out of both climate data maps, and species occurrence data.  The result is that you can grab data from both sources, and then extract climate information about your species occurrence data.&lt;/p&gt;

&lt;p&gt;In the example below I&amp;rsquo;m going to download climate data at the basin level for the US and Mexico, and then species occurrences for eight different tree species.  I&amp;rsquo;ll then extract the temperature from each point data with an spatial overlay and look at the distribution of temperatures for each species.  Furthermore the conversion to spatial objects functions will allow you to use our data with any &lt;a href=&#34;http://en.wikipedia.org/wiki/Shapefile&#34;&gt;shape files&lt;/a&gt; you might have.&lt;/p&gt;

&lt;p&gt;The first step is to grab the &lt;a href=&#34;https://developers.google.com/kml/documentation/&#34;&gt;KML&lt;/a&gt; files for each river basin making up the US and Mexico, which we &lt;a href=&#34;http://data.worldbank.org/sites/default/files/climate_data_api_basins.pdf&#34;&gt;identify with an integer&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
library(&amp;quot;rWBclimate&amp;quot;)
# Install spocc from our GitHub repo
# devtools::install_github(&amp;quot;spocc&amp;quot;, &amp;quot;ropensci&amp;quot;)
library(&amp;quot;spocc&amp;quot;)
library(&amp;quot;taxize&amp;quot;)
library(&amp;quot;plyr&amp;quot;)
library(&amp;quot;sp&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(spocc)
### Create path to store kml&#39;s
dir.create(&amp;quot;~/kmltmp&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;options(kmlpath = &amp;quot;~/kmltmp&amp;quot;)
options(stringsAsFactors = FALSE)

usmex &amp;lt;- c(273:284, 328:365)
### Download KML&#39;s and read them in.
usmex.basin &amp;lt;- create_map_df(usmex)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;

## Download temperature data
temp.dat &amp;lt;- get_historical_temp(usmex, &amp;quot;decade&amp;quot;)
temp.dat &amp;lt;- subset(temp.dat, temp.dat$year == 2000)


# Bind temperature data to map data frame

usmex.map.df &amp;lt;- climate_map(usmex.basin, temp.dat, return_map = F)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have created a map of the US and Mexico, downloaded the average temperature in each basin between 1990 and 2000, and bound them together.  Next let&amp;rsquo;s grab occurrence data using &lt;code&gt;spocc&lt;/code&gt; for our eight tree species (&lt;em&gt;Note:  &lt;code&gt;rgbif&lt;/code&gt; &amp;gt; 0.6.0 needs to be installed to work properly&lt;/em&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
## Grab some species occurrence data for the 8 tree species.

splist &amp;lt;- c(&amp;quot;Acer saccharum&amp;quot;, &amp;quot;Abies balsamea&amp;quot;, &amp;quot;Arbutus xalapensis&amp;quot;, &amp;quot;Betula alleghaniensis&amp;quot;, &amp;quot;Chilopsis linearis&amp;quot;, &amp;quot;Conocarpus erectus&amp;quot;, &amp;quot;Populus tremuloides&amp;quot;, &amp;quot;Larix laricina&amp;quot;)

## get data from bison and gbif
splist &amp;lt;- sort(splist)
out &amp;lt;- occ(query = splist, from = c(&amp;quot;bison&amp;quot;, &amp;quot;gbif&amp;quot;), limit = 100)

## scrub names
out &amp;lt;- fixnames(out, how = &amp;quot;query&amp;quot;)

## Create a data frame of all data.

out_df &amp;lt;- occ2df(out)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we&amp;rsquo;ve downloaded the data using their latin names, we might want to know the common names.  Luckily the &lt;code&gt;taxize&lt;/code&gt; package is great for that, and we can grab them with just a couple of lines of code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
### grab common names
cname &amp;lt;- ldply(sci2comm(get_tsn(splist), db = &amp;quot;itis&amp;quot;, simplify = TRUE), function(x) { return(x[1]) })[, 2]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;### Now let&#39;s create a vector of common names for easy plotting But first
### order on names so we can just add the names
out_df &amp;lt;- out_df[order(out_df$name), ]
### strip NA values and 0 values of coordinates
out_df &amp;lt;- out_df[!is.na(out_df$lat), ]
out_df &amp;lt;- out_df[out_df$lat &amp;gt; 0, ]
out_df$common &amp;lt;- rep(cname, table(out_df$name))

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have all the components we need, species data and spatial polygons with temperature data bound to them.  Before we do the spatial over lay, let&amp;rsquo;s have do a quick visualization.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
## Now just create the base temperature map
usmex.map &amp;lt;- ggplot() +
  geom_polygon(data = usmex.map.df, aes(x = long, y = lat, group = group, fill = data, alpha = 0.9)) +
  scale_fill_continuous(&amp;quot;Average annual \n temp: 1990-2000&amp;quot;, low = &amp;quot;yellow&amp;quot;, high = &amp;quot;red&amp;quot;) +
  guides(alpha = F) +
  theme_bw(10)

## And overlay of gbif data
usmex.map &amp;lt;- usmex.map +
  geom_point(data = out_df, aes(y = latitude, x = longitude, group = common, colour = common)) +
  xlim(-125, -59) +
  ylim(5, 55)

print(usmex.map)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-04-22-rwbclimate-sp/mapping_2.png&#34; alt=&#34;plot of chunk mapping&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now the question is, what&amp;rsquo;s the temperature at each point for each tree species?  We can convert our species data to spatial points with &lt;code&gt;occ_to_sp&lt;/code&gt;, and our data from &lt;code&gt;rWBclimate&lt;/code&gt; can be converted to spatial polygons with &lt;code&gt;kml_to_sp&lt;/code&gt;.  Next we can loop through each grouping of species, and call the &lt;code&gt;over&lt;/code&gt; function to get the temperature at each point.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Create a spatial polygon dataframe binding kml polygons to temperature
## data
temp_sdf &amp;lt;- kml_to_sp(usmex.basin, df = temp.dat)
### Now we can change the points to a spatial polygon:
sp_points &amp;lt;- occ_to_sp(out)

tdat &amp;lt;- vector()
### Get averages
for (i in 1:length(splist)) {
    tmp_sp &amp;lt;- sp_points[which(sp_points$name == splist[i]), ]
    tmp_t &amp;lt;- over(tmp_sp, temp_sdf)$data
    tdat &amp;lt;- c(tdat, tmp_t)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last step is to create a new data frame with our data.  Unfortunately the size of our old data frame &lt;code&gt;out_df&lt;/code&gt; won&amp;rsquo;t be the same size due to some invalid lat/long&amp;rsquo;s that came down with our data so the entire data frame will be reassembled.  After we assemble the data frame we can summarize our it with plyr, getting the mean temperature and latitude for each species.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
### Assemble new dataframe
spDF &amp;lt;- data.frame(matrix(nrow = dim(sp_points)[1], ncol = 0))
spDF$species &amp;lt;- sp_points$name
spDF &amp;lt;- cbind(coordinates(sp_points), spDF)

### This is important, be sure to order all the points alphebetically as we
### did earlier
spDF &amp;lt;- spDF[order(spDF$species), ]

spDF$cname &amp;lt;- rep(cname, table(sp_points$name))
spDF$temp &amp;lt;- tdat
### Strip NA&#39;s
spDF &amp;lt;- spDF[!is.na(spDF$temp), ]

## Create summary
summary_data &amp;lt;- ddply(spDF, .(cname), summarise, mlat = mean(latitude), mtemp = mean(temp),
    sdlat = sd(latitude), sdtemp = sd(temp))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First let&amp;rsquo;s look at a plot of mean temperature vs latititude, and to identify the points we&amp;rsquo;ll plot their common names.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(summary_data, aes(x = mlat, y = mtemp, label = cname)) +
  geom_text() +
  xlab(&amp;quot;Mean Latitude&amp;quot;) +
  ylab(&amp;quot;Mean Temperature (C)&amp;quot;) +
  theme_bw() +
  xlim(10, 50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-04-22-rwbclimate-sp/means.png&#34; alt=&#34;plot of chunk means&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This gives us a sense about how the means of each value are related, but we can also look at the distribution of temperatures with boxplots.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(spDF, aes(as.factor(cname), temp)) +
  geom_boxplot() +
  theme_bw(13) +
  ylab(&amp;quot;Temperature&amp;quot;) +
  xlab(&amp;quot;Common Name&amp;quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 0.5, vjust = 0.5))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-04-22-rwbclimate-sp/boxplots.png&#34; alt=&#34;plot of chunk boxplots&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This gives a sense of how wide the temperature distributions are, as well as looking at some of the outliers.  The distributions look pretty skewed, and this probably reflects the large spatial granularity of our temperature data compared to the occurrence data.  However this example shows how you can easily combine data from multiple rOpenSci packages.  We will continue to work towards enhancing the interoperability of heterogeneous data streams via our tools.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Make your ggplots shareable, collaborative, and with D3</title>
      <link>https://ropensci.org/blog/2014/04/17/plotly/</link>
      <pubDate>Thu, 17 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/04/17/plotly/</guid>
      <description>
        
        

&lt;p&gt;&lt;em&gt;Editor&amp;rsquo;s note: This is a guest post by Matt Sundquist from &lt;a href=&#34;https://plot.ly/&#34;&gt;Plot.ly&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You can access the source code for this post at &lt;a href=&#34;https://gist.github.com/sckott/10991885&#34;&gt;https://gist.github.com/sckott/10991885&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ropensci/plotly&#34;&gt;Ggplotly&lt;/a&gt; and &lt;a href=&#34;https://plot.ly/api/r&#34;&gt;Plotly&amp;rsquo;s R API&lt;/a&gt; let you make ggplot2 plots, add &lt;code&gt;py$ggplotly()&lt;/code&gt;, and make your plots interactive, online, and drawn with D3. Let&amp;rsquo;s make some.&lt;/p&gt;

&lt;h2 id=&#34;1-getting-started-and-examples&#34;&gt;1. Getting Started and Examples&lt;/h2&gt;

&lt;p&gt;Here is Fisher&amp;rsquo;s iris data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;ggplot2&amp;quot;)
ggiris &amp;lt;- qplot(Petal.Width, Sepal.Length, data = iris, color = Species)
print(ggiris)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-04-17-plotly/unnamed-chunk-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s make it in Plotly. Install:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;devtools&amp;quot;)
library(&amp;quot;devtools&amp;quot;)
install_github(&amp;quot;plotly&amp;quot;, &amp;quot;ropensci&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Load.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;plotly&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: RCurl
## Loading required package: bitops
## Loading required package: RJSONIO
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sign up &lt;a href=&#34;https://plot.ly&#34;&gt;online&lt;/a&gt;, use our public keys below, or sign up like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;signup(&amp;quot;new_username&amp;quot;, &amp;quot;your_email@domain.com&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That should have responded with your new key. Use that to create a plotly interface object, or use ours:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;py &amp;lt;- plotly(&amp;quot;RgraphingAPI&amp;quot;, &amp;quot;ektgzomjbx&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It just works.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;py$ggplotly(ggiris)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/554&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;The call opens a browser tab. Or in an &lt;code&gt;.Rmd&lt;/code&gt; document, the plot is embedded if you specify the &lt;code&gt;plotly=TRUE&lt;/code&gt; chunk option (see &lt;a href=&#34;https://gist.github.com/sckott/10991885&#34;&gt;source&lt;/a&gt;). If you&amp;rsquo;re running this from the source, it makes all the graphs at once in your browser. Reaction my first time: here be dragons.&lt;/p&gt;

&lt;p&gt;If you click the &lt;em&gt;data and graph&lt;/em&gt; link in the embed, it takes you to Plotly&amp;rsquo;s GUI, where you can edit the graph, see the data, and share your plot with collaborators.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-2-maps&#34;&gt;1.2 Maps&lt;/h3&gt;

&lt;p&gt;Next: Maps!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(canada.cities, package=&amp;quot;maps&amp;quot;)
viz &amp;lt;- ggplot(canada.cities, aes(long, lat)) +
  borders(regions=&amp;quot;canada&amp;quot;, name=&amp;quot;borders&amp;quot;) +
  coord_equal() +
  geom_point(aes(text=name, size=pop), colour=&amp;quot;red&amp;quot;, alpha=1/2, name=&amp;quot;cities&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Call Plotly.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;py$ggplotly(viz)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/555&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-3-scatter&#34;&gt;1.3 Scatter&lt;/h3&gt;

&lt;p&gt;Want to make a scatter and add a &lt;a href=&#34;http://docs.ggplot2.org/current/geom_smooth.html&#34;&gt;smoothed conditional mean&lt;/a&gt;? Here&amp;rsquo;s how to do it in Plotly. For the rest of the plots, we&amp;rsquo;ll just print the Plotly version to save space. You can hover on text to get data, or click and drag across a section to zoom in.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model &amp;lt;- lm(mpg ~ wt + factor(cyl), data=mtcars)
grid &amp;lt;- with(mtcars, expand.grid(
  wt = seq(min(wt), max(wt), length = 20),
  cyl = levels(factor(cyl))
))

grid$mpg &amp;lt;- stats::predict(model, newdata=grid)

viz2 &amp;lt;- qplot(wt, mpg, data=mtcars, colour=factor(cyl)) + geom_line(data=grid)
py$ggplotly(viz2)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/556&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-4-lines&#34;&gt;1.4 Lines&lt;/h3&gt;

&lt;p&gt;Or, take &lt;code&gt;ggplotly&lt;/code&gt; for a spin with the orange dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;orange &amp;lt;- qplot(age, circumference, data = Orange, colour = Tree, geom = &amp;quot;line&amp;quot;)
py$ggplotly(orange)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/557&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-5-alpha-blend&#34;&gt;1.5 Alpha blend&lt;/h3&gt;

&lt;p&gt;Or, make plots &lt;a href=&#34;http://mandymejia.wordpress.com/2013/11/13/10-reasons-to-switch-to-ggplot-7/&#34;&gt;beautiful&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;prettyPlot &amp;lt;- ggplot(data=diamonds, aes(x=carat, y=price, colour=clarity))
prettyPlot &amp;lt;- prettyPlot + geom_point(alpha = 1/10)
py$ggplotly(prettyPlot)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/558&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-6-functions&#34;&gt;1.6 Functions&lt;/h3&gt;

&lt;p&gt;Want to &lt;a href=&#34;http://stackoverflow.com/questions/1853703/plotting-functions-in-r&#34;&gt;draw functions&lt;/a&gt; with a &lt;code&gt;curve&lt;/code&gt;?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;eq &amp;lt;- function(x) {x*x}
tmp &amp;lt;- data.frame(x=1:50, y=eq(1:50))

# Make plot object
p &amp;lt;- qplot(x, y, data=tmp, xlab=&amp;quot;X-axis&amp;quot;, ylab=&amp;quot;Y-axis&amp;quot;)
c &amp;lt;- stat_function(fun=eq)

py$ggplotly(p + c)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/559&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;2-a-github-for-data-and-graphs&#34;&gt;2. A GitHub for data and graphs&lt;/h2&gt;

&lt;p&gt;Like we might work together on code on GitHub or a project in a Google Doc, we can edit graphs and data together on Plotly. Here&amp;rsquo;s how it works:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Your URL is shareable.&lt;/li&gt;
&lt;li&gt;Public use is free.&lt;/li&gt;
&lt;li&gt;You can set &lt;a href=&#34;http://plot.ly/api/r/docs/privacy&#34;&gt;the privacy&lt;/a&gt; of your graph.&lt;/li&gt;
&lt;li&gt;You can edit and add to plots from our GUI or with R or &lt;a href=&#34;https://plot.ly/api&#34;&gt;APIs&lt;/a&gt; for Python, MATLA, Julia, Perl, Arduino, Raspberry Pi, and REST.&lt;/li&gt;
&lt;li&gt;You get a profile of graphs, like &lt;a href=&#34;https://plot.ly/~RhettAllain/&#34;&gt;Rhett Allain&lt;/a&gt; from Wired Science.&lt;/li&gt;
&lt;li&gt;You can &lt;a href=&#34;http://plot.ly/api/r/docs/iframes&#34;&gt;embed interactive graphs in iframes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-1-inspiration-and-team&#34;&gt;2.1 Inspiration and team&lt;/h3&gt;

&lt;p&gt;Plotly&amp;rsquo;s API is part of &lt;code&gt;rOpenSci&lt;/code&gt; and being developed by the brilliant &lt;a href=&#34;http://cbio.ensmp.fr/~thocking/&#34;&gt;Toby Hocking&lt;/a&gt; and Plotly&amp;rsquo;s own &lt;a href=&#34;https://github.com/chriddyp&#34;&gt;Chris Parmer&lt;/a&gt;. You can find it on &lt;a href=&#34;https://github.com/ropensci/plotly&#34;&gt;GitHub&lt;/a&gt;. Your thoughts, issues, and pull requests are welcome. Right now, you can make scatter and line plots; let us know what you&amp;rsquo;d like to see next.&lt;/p&gt;

&lt;p&gt;The project was inspired by &lt;a href=&#34;https://github.com/hadley/&#34;&gt;Hadley Wickham&lt;/a&gt; and the elegance and precision of &lt;a href=&#34;http://ggplot2.org/&#34;&gt;&lt;code&gt;ggplot2&lt;/code&gt;&lt;/a&gt;. Thanks to &lt;a href=&#34;http://scottchamberlain.info/&#34;&gt;Scott Chamberlain&lt;/a&gt;, &lt;a href=&#34;https://github.com/jcheng5&#34;&gt;Joe Cheng&lt;/a&gt;, and &lt;a href=&#34;https://twitter.com/efvmw&#34;&gt;Elizabeth Morrison-Wells&lt;/a&gt; for their help.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;3-ggthemes-and-plotly&#34;&gt;3. ggthemes and Plotly&lt;/h2&gt;

&lt;p&gt;Using &lt;a href=&#34;https://github.com/jrnold/ggthemes&#34;&gt;&lt;code&gt;ggthemes&lt;/code&gt;&lt;/a&gt; opens up another set of custom graph filters for styling your graphs. To get started, you&amp;rsquo;ll want to install &lt;code&gt;ggthemes&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;devtools&amp;quot;)
install_github(&amp;quot;ggthemes&amp;quot;, &amp;quot;jrnold&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and load your data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;ggplot2&amp;quot;)
library(&amp;quot;ggthemes&amp;quot;)
dsamp &amp;lt;- diamonds[sample(nrow(diamonds), 1000), ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;
Inverse gray.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;gray &amp;lt;- (qplot(carat, price, data = dsamp, colour = cut) +
           theme_igray())
py$ggplotly(gray)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/560&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;
The Tableau scale.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tableau &amp;lt;- (qplot(carat, price, data = dsamp, colour = cut) +
              theme_igray() +
              scale_colour_tableau())
py$ggplotly(tableau)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/561&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;br&gt;&lt;br&gt;
&lt;a href=&#34;http://www.perceptualedge.com/articles/visual_business_intelligence/rules_for_using_color.pdf&#34;&gt;Stephen Few&amp;rsquo;s&lt;/a&gt; scale.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;few &amp;lt;- (qplot(carat, price, data = dsamp, colour = cut) +
          theme_few() +
          scale_colour_few())
py$ggplotly(few)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe height=&#34;600&#34; id=&#34;igraph&#34; scrolling=&#34;no&#34; seamless=&#34;seamless&#34;
                src=&#34;https://plot.ly/~RgraphingAPI/562&#34; width=&#34;600&#34; frameBorder=&#34;0&#34;&gt;&lt;/iframe&gt;

      </description>
    </item>
    
    <item>
      <title>The ins and outs of interacting with web APIs</title>
      <link>https://ropensci.org/blog/2014/04/14/webapis/</link>
      <pubDate>Mon, 14 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/04/14/webapis/</guid>
      <description>
        
        

&lt;p&gt;We&amp;rsquo;ve received a number of questions from our users about dealing with the finer details of data sources on the web. Whether you&amp;rsquo;re reading data from local storage such as a csv file, a &lt;code&gt;.Rdata&lt;/code&gt; store, or possibly a proprietary file format, you&amp;rsquo;ve most likely run into some issues in the past. Common problems include passing incorrect paths, files being too big for memory, or requiring several packages to read files in incompatible formats. Reading data from the web entails a whole other set of challenges. Although there are many ways to obtain data from the web, this post primarily deals with retrieving data from Application Programming Interfaces also known as APIs.&lt;/p&gt;

&lt;p&gt;To demystify some of the issues around getting data from the web in R, here&amp;rsquo;s some background on some of the common issues we get questions about:&lt;/p&gt;

&lt;h2 id=&#34;rest-apis&#34;&gt;REST APIs&lt;/h2&gt;

&lt;p&gt;First, let&amp;rsquo;s cover the types of APIs we work with. We prefer, and almost exclusively get data from providers via, REST APIs. REST stands for Representational State Transfer.  This isn&amp;rsquo;t a specific set of rules, but more a set of principles followed. They are&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use HTTP methods explicitly. These are GET, PUT, POST, DELETE&lt;/li&gt;
&lt;li&gt;Expose directory structure-like URIs.&lt;/li&gt;
&lt;li&gt;Transfer XML, JavaScript Object Notation (JSON), or both.&lt;/li&gt;
&lt;li&gt;Be stateless. This one we&amp;rsquo;ll explain in more detail. One advantage of REST over other data transfer protocols is that it is stateless. &lt;em&gt;state&lt;/em&gt; simply refers to the state of a request for data. In other protocols like &lt;a href=&#34;http://en.wikipedia.org/wiki/SOAP&#34;&gt;SOAP&lt;/a&gt; the state is preserved on the server, while in REST, the state is all controlled by the client (the user). &lt;em&gt;state&lt;/em&gt; can be conrolled by the user in REST calls via parameters passed like &lt;code&gt;limit&lt;/code&gt;, &lt;code&gt;page&lt;/code&gt;, etc. (see below). In short, REST APIs are nicer to build and use (in many cases).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;where-do-the-data-come-from&#34;&gt;Where do the data come from?&lt;/h2&gt;

&lt;p&gt;Where are data actually stored? Data are stored in some sort of database, sometimes relational column-row based database such as a SQL database (MySQL, PostgreSQL, etc.), or perhaps a NoSQL databases like CouchDB (NoSQL databases don&amp;rsquo;t have a column-row setup, but store &lt;em&gt;documents&lt;/em&gt;, like a text document, XML text, and even binary files). Nearly all of the data that can be obtained through one of our packages is likely stored in a relational database.&lt;/p&gt;

&lt;p&gt;If there is an ability to search in the API, data providers often provide this by using an indexing tool like &lt;a href=&#34;https://lucene.apache.org/solr/&#34;&gt;Solr&lt;/a&gt; or &lt;a href=&#34;http://www.elasticsearch.org/&#34;&gt;Elasticsearch&lt;/a&gt; to provide much richer search on their data.&lt;/p&gt;

&lt;p&gt;Databases can be hosted by the institutions serving the data, but most often they are located on some cloud service like Amazon Web Services.&lt;/p&gt;

&lt;h2 id=&#34;data-vs-metadata-vs-data-metadata&#34;&gt;Data vs. metadata vs. data/metadata&lt;/h2&gt;

&lt;p&gt;Information providers differ in many ways, but one of them is what kind of information they provide. Some provide &lt;strong&gt;data&lt;/strong&gt; directly in response to the request. GBIF&amp;rsquo;s API is a good example of this. If you click on this URL &lt;a href=&#34;http://api.gbif.org/v0.9/occurrence/search?taxonKey=1&amp;amp;limit=2&#34;&gt;http://api.gbif.org/v0.9/occurrence/search?taxonKey=1&amp;amp;limit=2&lt;/a&gt; you will see JSON formatted data in your browser window.&lt;/p&gt;

&lt;p&gt;Other providers give back metadata in response to requests. Dryad is a good example of this. If you search for a dataset on Dryad, you get back metadata describing the data. Another call is required to get the data itself.&lt;/p&gt;

&lt;p&gt;Another set of providers only has, and thus can only provide, metadata. For example, our &lt;a href=&#34;https://github.com/ropensci/rmetadata&#34;&gt;rmetadata&lt;/a&gt; R package interacts with a number of APIs for scholarly metadata. These are metadata describing scholarly works, and don&amp;rsquo;t provide the content of the works they describe (e.g., full content of a journal article).&lt;/p&gt;

&lt;p&gt;The issue of what is returned from the provider is separate from the above topic about the type of database - data can be returned from a SQL (column-row database) or a NoSQL database.&lt;/p&gt;

&lt;h2 id=&#34;data-return-limits&#34;&gt;Data return limits&lt;/h2&gt;

&lt;p&gt;Data providers often impose limits on the number of requests within a certain time frame to avoid slowing down the system, and to aid in supporting simultaneous data requests.&lt;/p&gt;

&lt;p&gt;Given these limits, data providers impose limits on how many records can be returned in a single query. This parameter is usually called &lt;code&gt;limit&lt;/code&gt;. There is often a maximum number of requests you can request at any given time, and is an arbitary number set by the data provider. Because there is a limit, an additional parameter is often used called &lt;code&gt;offset&lt;/code&gt; (or &lt;code&gt;start&lt;/code&gt;). &lt;code&gt;offset&lt;/code&gt; is the record to start at for the returned data. Let&amp;rsquo;s say a data provider you want data from has a maximum &lt;code&gt;limit&lt;/code&gt; value of 1000, and you want 3000 records. If you want to get them all, you&amp;rsquo;d have to make 3 different data requests, setting &lt;code&gt;limit&lt;/code&gt; to 1000 for each request, and &lt;code&gt;offset&lt;/code&gt; to 1 for the first request, 1001 for the second, and 2001 for the third request.&lt;/p&gt;

&lt;p&gt;Another approach is with a set of parameters: &lt;code&gt;page&lt;/code&gt; and &lt;code&gt;page_size&lt;/code&gt;. For example, if you wanted 3000 records returned, but the limit is 1000 records per page, you could set &lt;code&gt;page_size&lt;/code&gt; to 1000, and &lt;code&gt;page&lt;/code&gt; to 1, 2, and 3 on three separate requests. Some combination of the parameters &lt;code&gt;limit&lt;/code&gt;, &lt;code&gt;offset&lt;/code&gt; (or &lt;code&gt;start&lt;/code&gt;), &lt;code&gt;page&lt;/code&gt;, and &lt;code&gt;page_size&lt;/code&gt; are available in many of the functions in rOpenSci R packages.&lt;/p&gt;

&lt;p&gt;In some functions in rOpenSci packages, we hide this detail from you and just expose the &lt;code&gt;limit&lt;/code&gt; parameter to you so that if you set &lt;code&gt;limit = 15000&lt;/code&gt; and the data provider allows a max of 1000, we figure out the calls needed, and make those for you so a many calls appear as one to the user. We haven&amp;rsquo;t been consistent across our packages in doing this method or letting the user manually do multiple calls.&lt;/p&gt;

&lt;h2 id=&#34;parameters&#34;&gt;Parameters&lt;/h2&gt;

&lt;p&gt;Parameters can vary widely among data providers. The ones mentioned above, &lt;code&gt;limit&lt;/code&gt;, &lt;code&gt;page&lt;/code&gt;, and &lt;code&gt;start&lt;/code&gt; are relatively common among data providers. There is often a query parameter called &lt;code&gt;query&lt;/code&gt; or simply &lt;code&gt;q&lt;/code&gt; (Bond anyone?). If there is authentication (see below), there is often an &lt;code&gt;api_key&lt;/code&gt; or &lt;code&gt;key&lt;/code&gt; parameter. For searches of data that are geographically defined, there is often a &lt;code&gt;geometry&lt;/code&gt; parameter (often accepts &lt;a href=&#34;http://en.wikipedia.org/wiki/Well-known_text&#34;&gt;Well Known Text polygons&lt;/a&gt;), or &lt;code&gt;bbox&lt;/code&gt; for bounding box (which accepts NW, SE, SW, and NE points defining the bounding box).&lt;/p&gt;

&lt;p&gt;As you are using the API of a data provider through an R package we have written, we can set parameters differently, then just match them up internally in our code - so be aware that the parameter you see in the R function is not necessarily the same as the parameter name in the API. For example, if the parameter defined in the API is &lt;code&gt;theQuickBrownFoxJumpsOverTheLazyDog&lt;/code&gt;, we&amp;rsquo;d likely use a parameter in the function that is much shorter and easier to remember, like &lt;code&gt;foxdog&lt;/code&gt; as a shorthand.&lt;/p&gt;

&lt;h2 id=&#34;http-codes&#34;&gt;HTTP codes&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Http_codes&#34;&gt;HTTP codes&lt;/a&gt; are a system for signaling the status of an HTTP request in a 3-digit number. APIs return such codes so that developers can quickly resolve a problem. We are starting to expose these HTTP codes in our R packages when something goes wrong, and mostly not showing them when the call worked as planned. Success is indicated by 2XX series codes, where 200 indicates standard successful request, whereas 206 indicates that the provider is only giving partial content back. Here are error codes you may get when something is wrong - it&amp;rsquo;s good to be aware of them:&lt;/p&gt;

&lt;p&gt;4XX series codes indicate a client error - or rather, a user error. Common codes include&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;400 &lt;em&gt;Bad request&lt;/em&gt; - query specified incorrectly&lt;/li&gt;
&lt;li&gt;401 &lt;em&gt;Unauthorized&lt;/em&gt; - you need to provide authentication or what was provided was incorrect&lt;/li&gt;
&lt;li&gt;403 &lt;em&gt;Forbidden&lt;/em&gt; - you aren&amp;rsquo;t allowed to access the resource&lt;/li&gt;
&lt;li&gt;404 &lt;em&gt;Not found&lt;/em&gt; - often indicates that youre query was not constructed correctly&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;5XX series codes indicate a server error, or a data provider error. Common ones include&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;501 &lt;em&gt;Not implemented&lt;/em&gt; - implying future availability&lt;/li&gt;
&lt;li&gt;503 &lt;em&gt;Service unavailable&lt;/em&gt; - server unavailable, usually (hopefully) temporary&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you get any of the 4XX series errors using our R packages, check to make sure your query is correct, and if so, get in touch with us as we may need to fix a bug in our code. If you get a 5XX series code, it suggests that something is wrong on the provider&amp;rsquo;s end. If this problem perists, contact the data provider directly or let us know.&lt;/p&gt;

&lt;h2 id=&#34;authentication&#34;&gt;Authentication&lt;/h2&gt;

&lt;p&gt;Most providers require authentication to limit access to paying customers, impose limits on users, and/or simply to track data usage. These limits also prevent a few heavy users from monopolizing the resource.&lt;/p&gt;

&lt;p&gt;Authentication usually happens in one of three ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Username/password combo: You usually pass these in as parameters to a function call. This is generally not a great way to do authentication, but sometimes data sources require this. In our experience, this method is rarely used.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;API key: Pass in an alphanumeric key as a parameter in a function call.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;OAuth:  In R, a web page opens from your R session where you have to enter some personal information, or simply get redirected back to R saying you&amp;rsquo;re all set. This method is relatively easy, but is an extra step not required in the above two methods.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;wrap-up&#34;&gt;Wrap up&lt;/h2&gt;

&lt;p&gt;We hope this been useful for those that weren&amp;rsquo;t familiar with these things previously. If you have questions about APIs, ask below, &lt;a href=&#34;https://twitter.com/ropensci&#34;&gt;on Twitter&lt;/a&gt;, or &lt;a href=&#34;mailto:info@ropensci.org&#34;&gt;email us&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Accessing iNaturalist data</title>
      <link>https://ropensci.org/blog/2014/03/26/rinat/</link>
      <pubDate>Wed, 26 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/03/26/rinat/</guid>
      <description>
        
        &lt;p&gt;The &lt;a href=&#34;http://www.inaturalist.org/&#34;&gt;iNaturalist&lt;/a&gt; project is a really cool way to both engage people in citizen science and collect species occurrence data.  The premise is pretty simple, users download an app for their smartphone, and then can easily geo reference any specimen they see, uploading it to the iNaturalist website.  It let&amp;rsquo;s users turn casual observations into meaningful crowdsourced species occurrence data. They also provide a nice robust API to access almost all of their data.  We&amp;rsquo;ve developed a package &lt;a href=&#34;https://github.com/ropensci/rinat&#34;&gt;&lt;code&gt;rinat&lt;/code&gt;&lt;/a&gt; that can easily access all of that data in R.  Our package &lt;a href=&#34;https://github.com/ropensci/spocc&#34;&gt;&lt;code&gt;spocc&lt;/code&gt;&lt;/a&gt; uses iNaturalist data as one of it&amp;rsquo;s sources, &lt;code&gt;rinat&lt;/code&gt; provides an interface for all the features available in the API.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Searching&lt;/em&gt;
Currently you can get access to iNaturalist occurrence records from our package &lt;code&gt;spocc&lt;/code&gt;, which works great for scenarios where you want lot&amp;rsquo;s of data from many sources, but &lt;code&gt;rinat&lt;/code&gt; will get you full details on every record and offers other searching on terms other than species names. First let&amp;rsquo;s see how this matches with what you can get with &lt;code&gt;spocc&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;options(stringsAsFactors = F)
library(spocc)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## Loading required package: ggplot2
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rinat)
out &amp;lt;- occ(query = &amp;quot;Accipiter striatus&amp;quot;, from = &amp;quot;inat&amp;quot;)
inat_out &amp;lt;- get_inat_obs(taxon = &amp;quot;Accipiter striatus&amp;quot;, maxresults = 25)
### Compare Id&#39;s and see that results are the same without viewing full tables
cbind(out$inat$data$Accipiter_striatus$Id[1:5], inat_out$Id[1:5])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##        [,1]   [,2]
## [1,] 581369 581369
## [2,] 574433 574433
## [3,] 570635 570635
## [4,] 555214 555214
## [5,] 551405 551405
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The results are the same, the &lt;code&gt;rinat&lt;/code&gt; package will offer a bit more flexiblity in searching.  You can search for records by a fuzzy search query, a taxon (used above in &lt;code&gt;spocc&lt;/code&gt;), a location in a bounding box, or by date.  Let&amp;rsquo;s say you just want to search by for records of Mayflies, you can use the taxon parameter to search for all lower level taxonomic matches below order.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;may_flies &amp;lt;- get_inat_obs(taxon = &amp;quot;Ephemeroptera&amp;quot;)
## See what species names come back.
may_flies$Species.guess[1:10]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Mayfly&amp;quot;               &amp;quot;Heptageniidae&amp;quot;        &amp;quot;Ephemerella subvaria&amp;quot;
##  [4] &amp;quot;Ephemerella subvaria&amp;quot; &amp;quot;Mayflies&amp;quot;             &amp;quot;Stream Mayflies&amp;quot;
##  [7] &amp;quot;Mayflies&amp;quot;             &amp;quot;Mayflies&amp;quot;             &amp;quot;Mayflies&amp;quot;
## [10] &amp;quot;Hexagenia&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You could also search using the fuzzy query parameter, looking for mentions of a specific habitat or a common name. Below I&amp;rsquo;ll search for one of my favorite habitats, vernal ponds and see what species come back.  Also we can search for common names and see the scientific names (which should be all the same).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;vp_obs &amp;lt;- get_inat_obs(query = &amp;quot;vernal pool&amp;quot;)
vp_obs$Species.guess[1:10]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Docks (Genus Rumex)&amp;quot;
##  [2] &amp;quot;Blennosperma bakeri&amp;quot;
##  [3] &amp;quot;Rails, Gallinules, and Coots&amp;quot;
##  [4] &amp;quot;Western Spadefoot&amp;quot;
##  [5] &amp;quot;Western Spadefoot&amp;quot;
##  [6] &amp;quot;Eupsilia&amp;quot;
##  [7] &amp;quot;upland chorus frog&amp;quot;
##  [8] &amp;quot;Wood Frog&amp;quot;
##  [9] &amp;quot;Striped Meadowhawk (Sympetrum pallipes)&amp;quot;
## [10] &amp;quot;Ambystoma maculatum&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;
# Now le&#39;ts look up by common name:

deer &amp;lt;- get_inat_obs(query = &amp;quot;Mule Deer&amp;quot;)
deer$Scientific.name[1:10]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Odocoileus hemionus&amp;quot; &amp;quot;Odocoileus hemionus&amp;quot; &amp;quot;Odocoileus hemionus&amp;quot;
##  [4] &amp;quot;Odocoileus hemionus&amp;quot; &amp;quot;Odocoileus hemionus&amp;quot; &amp;quot;Odocoileus hemionus&amp;quot;
##  [7] &amp;quot;Odocoileus hemionus&amp;quot; &amp;quot;Odocoileus hemionus&amp;quot; &amp;quot;Odocoileus&amp;quot;
## [10] &amp;quot;Odocoileus hemionus&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All of these general searching functions return a dataframe that is m x 32 (where m is the requested number of results).  The column names are mostly self-explanatory, including, common names, species names, observer id&amp;rsquo;s, observer names, data quality, licenses and url&amp;rsquo;s for images so you can go look at the photo a user took.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Filtering&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;All searches can also be filtered by space and time.  You can search for records within a specific bounding box, or on a specific date (but not a range).  We can redo our deer search using a bounding box for the western United States.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;bounds &amp;lt;- c(38.44047, -125, 40.86652, -121.837)
deer &amp;lt;- get_inat_obs(query = &amp;quot;Mule Deer&amp;quot;, bounds = bounds)
cat(paste(&amp;quot;The number of records found in your bunding box:&amp;quot;, dim(deer)[1],
    sep = &amp;quot; &amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## The number of records found in your bunding box: 47
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By checking the dimensions, we can see only 47 records were found.  We could try the samething for a given day, month or year. Let&amp;rsquo;s try searhing for cumulative totals of observations of Ephemeroptera and see if we can detect seasonality.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(ggplot2)
out &amp;lt;- rep(NA, 12)
for (i in 1:12) {
    out[i] &amp;lt;- dim(get_inat_obs(taxon = &amp;quot;Ephemeroptera&amp;quot;, month = i, maxresults = 200))[1]
}
out &amp;lt;- data.frame(out)
out$month &amp;lt;- factor(month.name, levels = month.name)
ggplot(out, aes(x = month, y = out, group = 1)) + geom_point() + stat_smooth(se = FALSE) +
    xlab(&amp;quot;Month&amp;quot;) + ylab(&amp;quot;Cumulative of Mayfly observations&amp;quot;) + theme_bw(16)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-03-26-rinat/filter_date.png&#34; alt=&#34;plot of chunk filter_date&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Exactly as you&amp;rsquo;d expect observations of this season insect tend to peak in the summer and then slowly decline.  Except for September peak, it follows the expected trend.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;User and project data&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;There are several other functions from the API that allow you to access data about projects and users. You can grab detailed data about projects, users and observations.  Let&amp;rsquo;s look at the &lt;a href=&#34;http://www.inaturalist.org/projects/state-flowers-of-the-united-states-eol-collection&#34;&gt;EOL state flowers project&lt;/a&gt;.  First we can grab some basic info on the project by searching for it based on it&amp;rsquo;s &amp;ldquo;slug&amp;rdquo;.  You can find this in the URL of the project: &amp;ldquo;&lt;a href=&#34;http://www.inaturalist.org/projects/state-flowers-of-the-united-states-eol-collection&amp;quot;&#34;&gt;http://www.inaturalist.org/projects/state-flowers-of-the-united-states-eol-collection&amp;quot;&lt;/a&gt;, which is the section of text after &amp;ldquo;projects/&amp;rdquo;, so in this case it would be &amp;ldquo;state-flowers-of-the-united-states-eol-collection&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s grab some info on the project by getting observations but set the &lt;code&gt;type&lt;/code&gt; as &amp;ldquo;info&amp;rdquo;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;eol_flow &amp;lt;- get_inat_obs_project(&amp;quot;state-flowers-of-the-united-states-eol-collection&amp;quot;,
    type = &amp;quot;info&amp;quot;, raw = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 204  Records
## 0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;### See how many taxa there are, and how many counts there have been
cat(paste(&amp;quot;The project has observed this many species:&amp;quot;, eol_flow$taxa_number,
    sep = &amp;quot; &amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## The project has observed this many species: 20
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cat(paste(&amp;quot;The project has observed this many occurrences:&amp;quot;, eol_flow$taxa_count,
    sep = &amp;quot; &amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## The project has observed this many occurrences: 204
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can grab all the observations from the project as well just by setting the &lt;code&gt;type&lt;/code&gt; as &amp;ldquo;observations&amp;rdquo;.  Then it&amp;rsquo;s easy to to get details about specific observations or users.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;eol_obs &amp;lt;- get_inat_obs_project(&amp;quot;state-flowers-of-the-united-states-eol-collection&amp;quot;,
    type = &amp;quot;observations&amp;quot;, raw = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## 204  Records
## 0-100-200-300
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## See just the first few details of an observation.
head(get_inat_obs_id(eol_obs$Id[1]))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $captive
## NULL
##
## $comments_count
## [1] 0
##
## $community_taxon_id
## [1] 48225
##
## $created_at
## [1] &amp;quot;2013-04-08T15:49:15-07:00&amp;quot;
##
## $delta
## [1] FALSE
##
## $description
## [1] &amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## See the first five species this user has recorded
head(get_inat_obs_user(as.character(eol_obs$User.login[1]), maxresults = 20))[,
    1]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Lynx rufus&amp;quot;              &amp;quot;Melanerpes formicivorus&amp;quot;
## [3] &amp;quot;Lontra canadensis&amp;quot;       &amp;quot;Buteo lineatus&amp;quot;
## [5] &amp;quot;Icteridae&amp;quot;               &amp;quot;Pelecanus occidentalis&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are many more details that you can get, like counts of observations by place ID (extracted from the project or observation, but not well exposed to users), the most common species by date, or by user.  There is almost no end to the details you can extract.  If you ever wanted to do a case study of a citizen science project, you could get data to answer almost any question you had about the iNaturalist project with &lt;code&gt;rinat&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Finally, what species occurrence package wouldn&amp;rsquo;t be complete without some basic mapping.  This function will generate a quick map for you based on a data frame of observations from &lt;code&gt;rinat&lt;/code&gt;. These can be from functions such as &lt;code&gt;get_inat_obs&lt;/code&gt;, or &lt;code&gt;get_inat_obs_project&lt;/code&gt;.  Let&amp;rsquo;s end by plotting all the observations from the EOL state flowers project.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;### Set plot to false so it returns a ggplot2 object, and that let&#39;s us modify
### it.
eol_map &amp;lt;- inat_map(eol_obs, plot = FALSE)
### Now we can modify the returned map
eol_map + borders(&amp;quot;state&amp;quot;) + theme_bw() + xlim(-125, -65) + ylim(25, 50)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-03-26-rinat/eol_plot.png&#34; alt=&#34;plot of chunk eol_plot&#34; /&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Species occurrence data</title>
      <link>https://ropensci.org/blog/2014/03/17/spocc/</link>
      <pubDate>Mon, 17 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/03/17/spocc/</guid>
      <description>
        
        

&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
UPDATE: mapping functions are in a separate package now (&lt;a href=&#34;https://cran.rstudio.com/web/packages/mapr&#34;&gt;mapr&lt;/a&gt;). Examples that do mapping below have been updated.
&lt;/div&gt;

&lt;p&gt;The rOpenSci projects aims to provide programmatic access to scientific data repositories on the web. A vast majority of the packages in our current suite retrieve some form of biodiversity or taxonomic data. Since several of these datasets have been georeferenced, it provides numerous opportunities for visualizing species distributions, building species distribution maps, and for using it analyses such as species distribution models. In an effort to streamline access to these data, we have developed a package called Spocc, which provides a unified API to all the biodiversity sources that we provide. The obvious advantage is that a user can interact with a common API and not worry about the nuances in syntax that differ between packages. As more data sources come online, users can access even more data without significant changes to their code. However, it is important to note that spocc will never replicate the full functionality that exists within specific packages. Therefore users with a strong interest in one of the specific data sources listed below would benefit from familiarising themselves with the inner working of the appropriate packages.&lt;/p&gt;

&lt;h2 id=&#34;data-sources&#34;&gt;Data Sources&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;spocc&lt;/code&gt; currently interfaces with five major biodiversity repositories. Many of these packages have been part of the rOpenSci suite:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Global Biodiversity Information Facility (&lt;code&gt;rgbif&lt;/code&gt;)
&lt;a href=&#34;http://www.gbif.org/&#34;&gt;GBIF&lt;/a&gt; is a government funded open data repository with several partner organizations with the express goal of providing access to data on Earth&amp;rsquo;s biodiversity. The data are made available by a network of member nodes, coordinating information from various participant organizations and government agencies.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://ecoengine.berkeley.edu/&#34;&gt;Berkeley Ecoengine&lt;/a&gt; (&lt;code&gt;ecoengine&lt;/code&gt;)
The ecoengine is an open API built by the &lt;a href=&#34;http://globalchange.berkeley.edu/&#34;&gt;Berkeley Initiative for Global Change Biology&lt;/a&gt;. The repository provides access to over 3 million specimens from various Berkeley natural history museums. These data span more than a century and provide access to georeferenced specimens, species checklists, photographs, vegetation surveys and resurveys and a variety of measurements from environmental sensors located at reserves across University of California&amp;rsquo;s natural reserve system. (&lt;a href=&#34;http://ropensci.org/blog/2014/01/30/ecoengine/&#34;&gt;related blog post&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;iNaturalist&lt;/strong&gt; (&lt;code&gt;rinat&lt;/code&gt;)
iNaturalist provides access to crowd sourced citizen science data on species observations.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://vertnet.org/index.php&#34;&gt;VertNet&lt;/a&gt; (&lt;code&gt;rvertnet&lt;/code&gt;)
Similar to &lt;code&gt;rgbif&lt;/code&gt;, ecoengine, and &lt;code&gt;rbison&lt;/code&gt; (see below), VertNet provides access to more than 80 million vertebrate records spanning a large number of institutions and museums primarly covering four major disciplines (mammology, herpetology, ornithology, and icthyology). &lt;strong&gt;Note that we don&amp;rsquo;t currenlty support VertNet data in this package, but we should soon&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://bison.usgs.ornl.gov/&#34;&gt;Biodiversity Information Serving Our Nation&lt;/a&gt; (&lt;code&gt;rbison&lt;/code&gt;)
Built by the US Geological Survey&amp;rsquo;s core science analytic team, BISON is a portal that provides access to species occurrence data from several participating institutions.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://ebird.org/content/ebird/&#34;&gt;eBird&lt;/a&gt; (&lt;code&gt;rebird&lt;/code&gt;)
ebird is a database developed and maintained by the Cornell Lab of Ornithology and the National Audubon Society. It provides real-time access to checklist data, data on bird abundance and distribution, and communtiy reports from birders.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://antweb.org&#34;&gt;AntWeb&lt;/a&gt; (&lt;code&gt;AntWeb&lt;/code&gt;)
AntWeb is the world&amp;rsquo;s largest online database of images, specimen records, and natural history information on ants. It is community driven and open to contribution from anyone with specimen records, natural history comments, or images. (&lt;a href=&#34;http://ropensci.org/blog/2014/02/18/antweb/&#34;&gt;related blog post&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; It&amp;rsquo;s important to keep in mind that several data providers interface with many of the above mentioned repositories. This means that occurence data obtained from BISON may be duplicates of data that are also available through GBIF. We do not have a way to resolve these duplicates or overlaps at this time but it is an issue we are hoping to address in future versions of the package.&lt;/p&gt;

&lt;h2 id=&#34;installing-the-package&#34;&gt;Installing the package&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;spocc&amp;quot;)
# or install the most recent version
devtools::install_github(&amp;quot;ropensci/spocc&amp;quot;)
library(spocc)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;spocc&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;searching-species-occurrence-data&#34;&gt;Searching species occurrence data&lt;/h2&gt;

&lt;p&gt;The main workhorse function of the package is called &lt;code&gt;occ&lt;/code&gt;. The function allows you to search for occurrence records on a single species or list of species and from particular sources of interest or several. The main input is a &lt;code&gt;query&lt;/code&gt; with sources specified under the argument &lt;code&gt;from&lt;/code&gt;. So to look at a really simply query:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;results &amp;lt;- occ(query = &#39;Accipiter striatus&#39;, from = &#39;gbif&#39;)
results
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; Searched: gbif
#&amp;gt; Occurrences - Found: 529,471, Returned: 500
#&amp;gt; Search type: Scientific
#&amp;gt;   gbif: Accipiter striatus (500)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This returns the results as an S3 class with a slot for each data source. Since we only requested data from &lt;code&gt;gbif&lt;/code&gt;, the remaining slots are empty. To view the data:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;results$gbif
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; Species [Accipiter striatus (500)]
#&amp;gt; First 10 rows of [Accipiter_striatus]
#&amp;gt;
#&amp;gt; Source: local data frame [500 x 117]
#&amp;gt;
#&amp;gt;                  name  longitude latitude  prov                 issues
#&amp;gt;                 &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                  &amp;lt;chr&amp;gt;
#&amp;gt; 1  Accipiter striatus  -97.94314 30.04580  gbif         cdround,gass84
#&amp;gt; 2  Accipiter striatus -122.40089 37.49201  gbif         cdround,gass84
#&amp;gt; 3  Accipiter striatus  -97.63810 30.24674  gbif    cdround,cudc,gass84
#&amp;gt; 4  Accipiter striatus  -81.85267 28.81852  gbif                 gass84
#&amp;gt; 5  Accipiter striatus -106.31531 31.71593  gbif         cdround,gass84
#&amp;gt; 6  Accipiter striatus  -97.81493 26.03150  gbif cdround,cucdmis,gass84
#&amp;gt; 7  Accipiter striatus  -95.50117 29.76086  gbif         cdround,gass84
#&amp;gt; 8  Accipiter striatus -116.67145 32.94147  gbif         cdround,gass84
#&amp;gt; 9  Accipiter striatus  -96.91463 32.82949  gbif         cdround,gass84
#&amp;gt; 10 Accipiter striatus  -75.65139 45.44557  gbif         cdround,gass84
#&amp;gt; ..                ...        ...      ...   ...                    ...
#&amp;gt; Variables not shown: key &amp;lt;int&amp;gt;, datasetKey &amp;lt;chr&amp;gt;, publishingOrgKey &amp;lt;chr&amp;gt;,
#&amp;gt;   publishingCountry &amp;lt;chr&amp;gt;, protocol &amp;lt;chr&amp;gt;, lastCrawled &amp;lt;chr&amp;gt;, lastParsed
#&amp;gt;   &amp;lt;chr&amp;gt;, extensions &amp;lt;chr&amp;gt;, basisOfRecord &amp;lt;chr&amp;gt;, taxonKey &amp;lt;int&amp;gt;, kingdomKey
#&amp;gt;   &amp;lt;int&amp;gt;, phylumKey &amp;lt;int&amp;gt;, classKey &amp;lt;int&amp;gt;, orderKey &amp;lt;int&amp;gt;, familyKey &amp;lt;int&amp;gt;,
#&amp;gt;   genusKey &amp;lt;int&amp;gt;, speciesKey &amp;lt;int&amp;gt;, scientificName &amp;lt;chr&amp;gt;, kingdom &amp;lt;chr&amp;gt;,
#&amp;gt;   phylum &amp;lt;chr&amp;gt;, order &amp;lt;chr&amp;gt;, family &amp;lt;chr&amp;gt;, genus &amp;lt;chr&amp;gt;, species &amp;lt;chr&amp;gt;,
#&amp;gt;   genericName &amp;lt;chr&amp;gt;, specificEpithet &amp;lt;chr&amp;gt;, taxonRank &amp;lt;chr&amp;gt;,
#&amp;gt;   dateIdentified &amp;lt;chr&amp;gt;, coordinateUncertaintyInMeters &amp;lt;dbl&amp;gt;, year &amp;lt;int&amp;gt;,
#&amp;gt;   month &amp;lt;int&amp;gt;, day &amp;lt;int&amp;gt;, eventDate &amp;lt;date&amp;gt;, modified &amp;lt;chr&amp;gt;,
#&amp;gt;   lastInterpreted &amp;lt;chr&amp;gt;, references &amp;lt;chr&amp;gt;, identifiers &amp;lt;chr&amp;gt;, facts &amp;lt;chr&amp;gt;,
#&amp;gt;   relations &amp;lt;chr&amp;gt;, geodeticDatum &amp;lt;chr&amp;gt;, class &amp;lt;chr&amp;gt;, countryCode &amp;lt;chr&amp;gt;,
#&amp;gt;   country &amp;lt;chr&amp;gt;, rightsHolder &amp;lt;chr&amp;gt;, identifier &amp;lt;chr&amp;gt;, informationWithheld
#&amp;gt;   &amp;lt;chr&amp;gt;, verbatimEventDate &amp;lt;chr&amp;gt;, datasetName &amp;lt;chr&amp;gt;, verbatimLocality
#&amp;gt;   &amp;lt;chr&amp;gt;, collectionCode &amp;lt;chr&amp;gt;, gbifID &amp;lt;chr&amp;gt;, occurrenceID &amp;lt;chr&amp;gt;, taxonID
#&amp;gt;   &amp;lt;chr&amp;gt;, license &amp;lt;chr&amp;gt;, catalogNumber &amp;lt;chr&amp;gt;, recordedBy &amp;lt;chr&amp;gt;,
#&amp;gt;   http...unknown.org.occurrenceDetails &amp;lt;chr&amp;gt;, institutionCode &amp;lt;chr&amp;gt;,
#&amp;gt;   rights &amp;lt;chr&amp;gt;, eventTime &amp;lt;chr&amp;gt;, identificationID &amp;lt;chr&amp;gt;, occurrenceRemarks
#&amp;gt;   &amp;lt;chr&amp;gt;, individualCount &amp;lt;int&amp;gt;, elevation &amp;lt;dbl&amp;gt;, elevationAccuracy &amp;lt;dbl&amp;gt;,
#&amp;gt;   continent &amp;lt;chr&amp;gt;, stateProvince &amp;lt;chr&amp;gt;, institutionID &amp;lt;chr&amp;gt;, county &amp;lt;chr&amp;gt;,
#&amp;gt;   identificationVerificationStatus &amp;lt;chr&amp;gt;, language &amp;lt;chr&amp;gt;, type &amp;lt;chr&amp;gt;,
#&amp;gt;   locationAccordingTo &amp;lt;chr&amp;gt;, preparations &amp;lt;chr&amp;gt;, identifiedBy &amp;lt;chr&amp;gt;,
#&amp;gt;   georeferencedDate &amp;lt;chr&amp;gt;, higherGeography &amp;lt;chr&amp;gt;, nomenclaturalCode &amp;lt;chr&amp;gt;,
#&amp;gt;   georeferencedBy &amp;lt;chr&amp;gt;, georeferenceProtocol &amp;lt;chr&amp;gt;, endDayOfYear &amp;lt;chr&amp;gt;,
#&amp;gt;   georeferenceVerificationStatus &amp;lt;chr&amp;gt;, locality &amp;lt;chr&amp;gt;,
#&amp;gt;   verbatimCoordinateSystem &amp;lt;chr&amp;gt;, otherCatalogNumbers &amp;lt;chr&amp;gt;, organismID
#&amp;gt;   &amp;lt;chr&amp;gt;, previousIdentifications &amp;lt;chr&amp;gt;, identificationQualifier &amp;lt;chr&amp;gt;,
#&amp;gt;   samplingProtocol &amp;lt;chr&amp;gt;, accessRights &amp;lt;chr&amp;gt;, higherClassification &amp;lt;chr&amp;gt;,
#&amp;gt;   georeferenceSources &amp;lt;chr&amp;gt;, sex &amp;lt;chr&amp;gt;, establishmentMeans &amp;lt;chr&amp;gt;,
#&amp;gt;   occurrenceStatus &amp;lt;chr&amp;gt;, disposition &amp;lt;chr&amp;gt;, startDayOfYear &amp;lt;chr&amp;gt;,
#&amp;gt;   dynamicProperties &amp;lt;chr&amp;gt;, infraspecificEpithet &amp;lt;chr&amp;gt;, georeferenceRemarks
#&amp;gt;   &amp;lt;chr&amp;gt;, and 12 more &amp;lt;...&amp;gt;.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you prefer data from more than one source, simply pass a vector of source names for the &lt;code&gt;from&lt;/code&gt; argument. Example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;occ(query = &#39;Accipiter striatus&#39;, from = c(&#39;ecoengine&#39;, &#39;gbif&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;#&amp;gt; Searched: ecoengine, gbif
#&amp;gt; Occurrences - Found: 530,224, Returned: 1,000
#&amp;gt; Search type: Scientific
#&amp;gt;   gbif: Accipiter striatus (500)
#&amp;gt;   ecoengine: Accipiter striatus (500)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can also search for multiple species across multiple engines.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;species_list &amp;lt;- c(&amp;quot;Accipiter gentilis&amp;quot;, &amp;quot;Accipiter poliogaster&amp;quot;, &amp;quot;Accipiter badius&amp;quot;)
res_set &amp;lt;- occ(species_list, from = c(&#39;gbif&#39;, &#39;ecoengine&#39;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similarly, we can search for data on the Sharp-shinned Hawk from other data sources too.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;occ(query = &#39;Accipiter striatus&#39;, from = &#39;ecoengine&#39;)
# or look for data on other species
occ(query = &#39;Danaus plexippus&#39;, from = &#39;inat&#39;)
occ(query = &#39;Bison bison&#39;, from = &#39;bison&#39;)
occ(query = &amp;quot;acanthognathus brevicornis&amp;quot;, from = &amp;quot;antweb&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;occ&lt;/code&gt; is also extremely flexible and can take package specific arguments for any source you might be querying. You can pass these as a list under &lt;code&gt;package_name_opts&lt;/code&gt; (e.g. &lt;code&gt;antweb_opts&lt;/code&gt;, &lt;code&gt;ecoengine_opts&lt;/code&gt;). See the help file for &lt;code&gt;?occ&lt;/code&gt; for more information.&lt;/p&gt;

&lt;h2 id=&#34;visualizing-biodiversity-data&#34;&gt;Visualizing biodiversity data&lt;/h2&gt;

&lt;p&gt;We provide several methods to visualize the resulting data. Current options include Leaflet.js, ggmap, a Mapbox implementation in a GitHub gist, or a static map.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mapping with Leaflet&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;UPDATE: mapping functions are in a separate package called &lt;code&gt;mapr&lt;/code&gt;. Eg below updated&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spp &amp;lt;- c(&amp;quot;Danaus plexippus&amp;quot;, &amp;quot;Accipiter striatus&amp;quot;, &amp;quot;Pinus contorta&amp;quot;)
dat &amp;lt;- occ(query = spp, from = &amp;quot;gbif&amp;quot;, has_coords = TRUE, limit = 50)
library(&amp;quot;mapr&amp;quot;)
map_leaflet(dat)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-03-17-spocc/leaflet_map.png&#34; alt=&#34;leaflet_map&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Render a geojson file automatically as a GitHub gist&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To have a map automatically posted as a gist, you&amp;rsquo;ll need to set up your GitHub credentials ahead of time. You can either pass these as variables &lt;code&gt;github.username&lt;/code&gt; and &lt;code&gt;github.password&lt;/code&gt;, or store them in your options (taking regular precautions as you would with passwords of course). If you don&amp;rsquo;t have these stored, you&amp;rsquo;ll be prompted to enter them before posting.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spp &amp;lt;- c(&amp;quot;Danaus plexippus&amp;quot;, &amp;quot;Accipiter striatus&amp;quot;, &amp;quot;Pinus contorta&amp;quot;)
dat &amp;lt;- occ(query = spp, from = &amp;quot;gbif&amp;quot;, has_coords = TRUE)
dat &amp;lt;- fixnames(dat)
library(&amp;quot;mapr&amp;quot;)
map_gist(dat, color = c(&amp;quot;#976AAE&amp;quot;, &amp;quot;#6B944D&amp;quot;, &amp;quot;#BD5945&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;script src=&#34;https://gist.github.com/sckott/daa7077cf80f2d2fbf2c5a41a9a00836.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Static maps&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If interactive maps aren&amp;rsquo;t your cup of tea, or you prefer to have one that you can embed in a paper, try one of our static map options. You can go with the more elegant &lt;code&gt;ggmap&lt;/code&gt; option or stick with something from base graphics.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ecoengine_data &amp;lt;- occ(query = &amp;quot;Lynx rufus californicus&amp;quot;, from = &amp;quot;ecoengine&amp;quot;, has_coords = TRUE)
map_ggplot(ecoengine_data, map = &amp;quot;usa&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-03-17-spocc/ggplot.png&#34; alt=&#34;ggplot_maps&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spnames &amp;lt;- c(&amp;quot;Accipiter striatus&amp;quot;, &amp;quot;Setophaga caerulescens&amp;quot;, &amp;quot;Spinus tristis&amp;quot;)
base_data &amp;lt;- occ(query = spnames, from = &amp;quot;gbif&amp;quot;, has_coords = TRUE)
map_plot(base_data, cex = 1, pch = 10)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-03-17-spocc/base_maps.png&#34; alt=&#34;base_maps&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;what-s-next&#34;&gt;What&amp;rsquo;s next?&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;As soon as we have an updated &lt;code&gt;rvertnet&lt;/code&gt; package, we&amp;rsquo;ll add the ability to query VertNet data from spocc.&lt;/li&gt;
&lt;li&gt;We will add &lt;code&gt;rCharts&lt;/code&gt; as an official import once the package is on CRAN (Eta end of March)&lt;/li&gt;
&lt;li&gt;We&amp;rsquo;re helping on a new package rMaps to make interactive maps using various Javascript mapping libraries, which will give access to a variety of awesome interactive maps. We will integrate rMaps once it&amp;rsquo;s on CRAN.&lt;/li&gt;
&lt;li&gt;We&amp;rsquo;ll add a function to make interactive maps using RStudio&amp;rsquo;s Shiny in a future version.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As always, &lt;a href=&#34;https://github.com/ropensci/spocc/issues?page=1&amp;amp;state=open&#34;&gt;issues&lt;/a&gt; or &lt;a href=&#34;https://github.com/ropensci/spocc/pulls&#34;&gt;pull requests&lt;/a&gt; are welcome directly on the &lt;a href=&#34;http://ropensci.org/spocc&#34;&gt;repo&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>rnoaa - Access to NOAA National Climatic Data Center data</title>
      <link>https://ropensci.org/blog/2014/03/13/rnoaa/</link>
      <pubDate>Thu, 13 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/03/13/rnoaa/</guid>
      <description>
        
        

&lt;p&gt;We recently pushed the first version of &lt;code&gt;rnoaa&lt;/code&gt; to CRAN - version 0.1. NOAA has a lot of data, some of which is provided via the &lt;a href=&#34;http://www.ncdc.noaa.gov/&#34;&gt;National Climatic Data Center&lt;/a&gt;, or NCDC. NOAA has provided access to NCDC climate data via a RESTful API - which is great because people like us can create clients for different programming languages to access their data programatically. If you are so inclined to write a bit of R code, this means you can get to NCDC data in the R environment where your workflow is reproducible, and you can connect data acquisition to a suite of tools for data manipulation (e.g., &lt;code&gt;plyr&lt;/code&gt;), visualization (e.g., &lt;code&gt;ggplot2&lt;/code&gt;), and statistics (e.g., &lt;code&gt;lme4&lt;/code&gt;, etc.).&lt;/p&gt;

&lt;p&gt;In addition to NCDC climate data, we have functions to access sea ice cover data via FTP, as well as the Severe Weather Data Inventory (SWDI) via API. We will continue to add in other data sources as we have time.&lt;/p&gt;

&lt;p&gt;Some notes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The docs for the API are live at the &lt;a href=&#34;http://www.ncdc.noaa.gov/cdo-web/webservices/v2&#34;&gt;NOAA NCDC website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GCHN Daily data is also available via &lt;a href=&#34;http://www.ncdc.noaa.gov/oa/climate/ghcn-daily/&#34;&gt;FTP&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The below examples uses the development version, but most things can be done with the CRAN version. Here&amp;rsquo;s a quick run down of some things you can do with &lt;code&gt;rnoaa&lt;/code&gt;:&lt;/p&gt;

&lt;h2 id=&#34;first-install-and-load-taxize&#34;&gt;First, install and load taxize&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;rnoaa&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;or development version from GitHub&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;devtools&amp;quot;)
library(devtools)
install_github(&amp;quot;rnoaa&amp;quot;, &amp;quot;ropensci&amp;quot;)
library(rnoaa)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rnoaa)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;api-keys-authentication&#34;&gt;API keys - authentication&lt;/h2&gt;

&lt;p&gt;You&amp;rsquo;ll need an API key to use this package (essentially a password). Go to the &lt;a href=&#34;http://www.ncdc.noaa.gov/cdo-web/token&#34;&gt;NCDC website&lt;/a&gt; to get one. &lt;em&gt;You can&amp;rsquo;t use this package without an API key.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Once you obtain a key, there are two ways to use it.&lt;/p&gt;

&lt;p&gt;a) Pass it inline with each function call (somewhat cumbersome and wordy)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa(datasetid = &amp;quot;PRECIP_HLY&amp;quot;, locationid = &amp;quot;ZIP:28801&amp;quot;, datatypeid = &amp;quot;HPCP&amp;quot;,
    limit = 5, token = &amp;quot;YOUR_TOKEN&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;b) Alternatively, you might find it easier to set this as an option, either by adding this line to the top of a script or somewhere in your &lt;code&gt;.Rprofile&lt;/code&gt; file&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;options(noaakey = &amp;quot;KEY_EMAILED_TO_YOU&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Specifically use the name &lt;em&gt;noaakey&lt;/em&gt; as the functions in the &lt;code&gt;rnoaa&lt;/code&gt; package are looking for a key by that name.&lt;/p&gt;

&lt;h2 id=&#34;fetch-list-of-city-locations-in-descending-order&#34;&gt;Fetch list of city locations in descending order&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_locs(locationcategoryid = &amp;quot;CITY&amp;quot;, sortfield = &amp;quot;name&amp;quot;, sortorder = &amp;quot;desc&amp;quot;,
    limit = 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 1654
##
## $meta$pageCount
## [1] 5
##
## $meta$offset
## [1] 1
##
##
## $data
##              id           name datacoverage    mindate    maxdate
## 1 CITY:NL000012     Zwolle, NL       1.0000 1892-08-01 2014-01-31
## 2 CITY:SZ000007     Zurich, SZ       1.0000 1901-01-01 2014-03-11
## 3 CITY:NG000004     Zinder, NG       0.8678 1906-01-01 1980-12-31
## 4 CITY:UP000025  Zhytomyra, UP       0.9726 1938-01-01 2014-03-11
## 5 CITY:KZ000017 Zhezkazgan, KZ       0.9279 1948-03-01 2014-03-10
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_locs&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;get-info-on-a-station-by-specifcying-a-dataset-locationtype-location-and-station&#34;&gt;Get info on a station by specifcying a dataset, locationtype, location, and station&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_stations(datasetid = &amp;quot;GHCND&amp;quot;, locationid = &amp;quot;FIPS:12017&amp;quot;, stationid = &amp;quot;GHCND:USC00084289&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## NULL
##
## $data
##                  id                  name datacoverage    mindate
## 1 GHCND:USC00084289 INVERNESS 3 SE, FL US            1 1899-02-01
##      maxdate
## 1 2014-03-12
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_stations&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;search-for-data&#34;&gt;Search for data&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out &amp;lt;- noaa(datasetid = &amp;quot;GHCND&amp;quot;, stationid = &amp;quot;GHCND:USW00014895&amp;quot;, datatypeid = &amp;quot;PRCP&amp;quot;,
    startdate = &amp;quot;2010-05-01&amp;quot;, enddate = &amp;quot;2010-10-31&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;see-a-data-frame&#34;&gt;See a data.frame&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(out$data)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##             station value attributes datatype                date
## 1 GHCND:USW00014895     0  T,,0,2400     PRCP 2010-05-01T00:00:00
## 2 GHCND:USW00014895    30   ,,0,2400     PRCP 2010-05-02T00:00:00
## 3 GHCND:USW00014895    51   ,,0,2400     PRCP 2010-05-03T00:00:00
## 4 GHCND:USW00014895     0  T,,0,2400     PRCP 2010-05-04T00:00:00
## 5 GHCND:USW00014895    18   ,,0,2400     PRCP 2010-05-05T00:00:00
## 6 GHCND:USW00014895    30   ,,0,2400     PRCP 2010-05-06T00:00:00
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;get-table-of-all-datasets&#34;&gt;Get table of all datasets&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;res &amp;lt;- noaa_datasets()
res$data
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##                     uid         id                    name datacoverage
## 1  gov.noaa.ncdc:C00040     ANNUAL        Annual Summaries         1.00
## 2  gov.noaa.ncdc:C00861      GHCND         Daily Summaries         1.00
## 3  gov.noaa.ncdc:C00841    GHCNDMS       Monthly Summaries         1.00
## 4  gov.noaa.ncdc:C00345    NEXRAD2         Nexrad Level II         0.95
## 5  gov.noaa.ncdc:C00708    NEXRAD3        Nexrad Level III         0.95
## 6  gov.noaa.ncdc:C00821 NORMAL_ANN Normals Annual/Seasonal         1.00
## 7  gov.noaa.ncdc:C00823 NORMAL_DLY           Normals Daily         1.00
## 8  gov.noaa.ncdc:C00824 NORMAL_HLY          Normals Hourly         1.00
## 9  gov.noaa.ncdc:C00822 NORMAL_MLY         Normals Monthly         1.00
## 10 gov.noaa.ncdc:C00505  PRECIP_15 Precipitation 15 Minute         0.25
## 11 gov.noaa.ncdc:C00313 PRECIP_HLY    Precipitation Hourly         1.00
##       mindate    maxdate
## 1  1831-02-01 2013-11-01
## 2  1763-01-01 2014-03-13
## 3  1763-01-01 2014-01-01
## 4  1991-06-05 2014-03-12
## 5  1994-05-20 2014-03-09
## 6  2010-01-01 2010-01-01
## 7  2010-01-01 2010-12-31
## 8  2010-01-01 2010-12-31
## 9  2010-01-01 2010-12-01
## 10 1970-05-12 2013-03-01
## 11 1900-01-01 2013-03-01
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;get-data-category-data-and-metadata&#34;&gt;Get data category data and metadata&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_datacats(locationid = &amp;quot;CITY:US390029&amp;quot;, limit = 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 37
##
## $meta$pageCount
## [1] 5
##
## $meta$offset
## [1] 1
##
##
## $data
##        id                 name
## 1  ANNAGR  Annual Agricultural
## 2   ANNDD   Annual Degree Days
## 3 ANNPRCP Annual Precipitation
## 4 ANNTEMP   Annual Temperature
## 5   AUAGR  Autumn Agricultural
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_datacats&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;plotting&#34;&gt;Plotting&lt;/h2&gt;

&lt;h3 id=&#34;plot-data-super-simple-but-it-s-a-start&#34;&gt;Plot data, super simple, but it&amp;rsquo;s a start&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out &amp;lt;- noaa(datasetid = &amp;quot;GHCND&amp;quot;, stationid = &amp;quot;GHCND:USW00014895&amp;quot;, datatypeid = &amp;quot;PRCP&amp;quot;,
    startdate = &amp;quot;2010-05-01&amp;quot;, enddate = &amp;quot;2010-10-31&amp;quot;, limit = 500)
noaa_plot(out, breaks = &amp;quot;1 month&amp;quot;, dateformat = &amp;quot;%d/%m&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-03-13-rnoaa/unnamed-chunk-12.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;more-plotting&#34;&gt;More plotting&lt;/h3&gt;

&lt;p&gt;You can pass many outputs from calls to the &lt;code&gt;noaa&lt;/code&gt; function in to the &lt;code&gt;noaa_plot&lt;/code&gt; function.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out1 &amp;lt;- noaa(datasetid = &amp;quot;GHCND&amp;quot;, stationid = &amp;quot;GHCND:USW00014895&amp;quot;, datatypeid = &amp;quot;PRCP&amp;quot;,
    startdate = &amp;quot;2010-03-01&amp;quot;, enddate = &amp;quot;2010-05-31&amp;quot;, limit = 500)
out2 &amp;lt;- noaa(datasetid = &amp;quot;GHCND&amp;quot;, stationid = &amp;quot;GHCND:USW00014895&amp;quot;, datatypeid = &amp;quot;PRCP&amp;quot;,
    startdate = &amp;quot;2010-09-01&amp;quot;, enddate = &amp;quot;2010-10-31&amp;quot;, limit = 500)
noaa_plot(out1, out2, breaks = &amp;quot;45 days&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-03-13-rnoaa/unnamed-chunk-13.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;sea-ice-cover-data&#34;&gt;Sea ice cover data&lt;/h2&gt;

&lt;p&gt;Get urls for ftp files&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;urls &amp;lt;- sapply(seq(1979, 1990, 1), function(x) seaiceeurls(yr = x, mo = &amp;quot;Feb&amp;quot;,
    pole = &amp;quot;S&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Call the &lt;code&gt;noaa_seaice&lt;/code&gt; function on each url, which downloads shape files, and reads them in to R as &lt;code&gt;sp&lt;/code&gt; objects&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out &amp;lt;- lapply(urls, noaa_seaice)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then plot&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(plyr)
library(ggplot2)
names(out) &amp;lt;- seq(1979, 1990, 1)
df &amp;lt;- ldply(out)
ggplot(df, aes(long, lat, group = group)) + geom_polygon(fill = &amp;quot;steelblue&amp;quot;) +
    theme_ice() + facet_wrap(~.id)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-03-13-rnoaa/unnamed-chunk-16.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;severe-weather-data&#34;&gt;Severe weather data&lt;/h2&gt;

&lt;h3 id=&#34;search-for-nx3tvs-data-from-5-may-2006-to-6-may-2006&#34;&gt;Search for nx3tvs data from 5 May 2006 to 6 May 2006&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_swdi(dataset = &amp;quot;nx3tvs&amp;quot;, startdate = &amp;quot;20060505&amp;quot;, enddate = &amp;quot;20060506&amp;quot;,
    limit = 3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 3
##
## $meta$totalTimeInSeconds
## [1] 0.004
##
##
## $data
##                  ztime wsr_id cell_id cell_type range azimuth max_shear
## 1 2006-05-05T00:05:50Z   KBMX      Q0       TVS     7     217       403
## 2 2006-05-05T00:10:02Z   KBMX      Q0       TVS     5     208       421
## 3 2006-05-05T00:12:34Z   KSJT      P2       TVS    49     106        17
##   mxdv
## 1  116
## 2  120
## 3   52
##
## $shape
##                                        shape
## 1 POINT (-86.8535716274277 33.0786326913943)
## 2 POINT (-86.8165772540846 33.0982820681588)
## 3 POINT (-99.5771091971025 31.1421609654838)
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_swdi&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get-all-plsr-within-the-bounding-box-91-30-90-31&#34;&gt;Get all &amp;lsquo;plsr&amp;rsquo; within the bounding box (-91,30,-90,31)&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_swdi(dataset = &amp;quot;plsr&amp;quot;, startdate = &amp;quot;20060505&amp;quot;, enddate = &amp;quot;20060510&amp;quot;, bbox = c(-91,
    30, -90, 31), limit = 3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 3
##
## $meta$totalTimeInSeconds
## [1] 0.015
##
##
## $data
##                  ztime     id        event magnitude         city
## 1 2006-05-09T02:20:00Z 427540         HAIL         1 5 E KENTWOOD
## 2 2006-05-09T02:40:00Z 427536         HAIL         1 MOUNT HERMAN
## 3 2006-05-09T02:40:00Z 427537 TSTM WND DMG     -9999 MOUNT HERMAN
##       county state          source
## 1 TANGIPAHOA    LA TRAINED SPOTTER
## 2 WASHINGTON    LA TRAINED SPOTTER
## 3 WASHINGTON    LA TRAINED SPOTTER
##
## $shape
##                  shape
## 1 POINT (-90.43 30.93)
## 2  POINT (-90.3 30.96)
## 3  POINT (-90.3 30.96)
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_swdi&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;get-all-nx3tvs-within-the-tile-102-1-32-6&#34;&gt;Get all &amp;lsquo;nx3tvs&amp;rsquo; within the tile -102.&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;32&lt;/sub&gt;.6&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_swdi(dataset = &amp;quot;nx3tvs&amp;quot;, startdate = &amp;quot;20060506&amp;quot;, enddate = &amp;quot;20060507&amp;quot;,
    tile = c(-102.12, 32.62), limit = 3)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 3
##
## $meta$totalTimeInSeconds
## [1] 0.021
##
##
## $data
##                  ztime wsr_id cell_id cell_type range azimuth max_shear
## 1 2006-05-06T00:41:29Z   KMAF      D9       TVS    37       6        39
## 2 2006-05-06T03:56:18Z   KMAF      N4       TVS    39       3        30
## 3 2006-05-06T03:56:18Z   KMAF      N4       TVS    42       4        20
##   mxdv
## 1   85
## 2   73
## 3   52
##
## $shape
##                                        shape
## 1 POINT (-102.112726356403 32.5574494581267)
## 2  POINT (-102.14873079873 32.5933553250156)
## 3 POINT (-102.131167022161 32.6426287452898)
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_swdi&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;counts&#34;&gt;Counts&lt;/h3&gt;

&lt;p&gt;Get number of &amp;lsquo;nx3tvs&amp;rsquo; within 15 miles of latitude = 32.7 and longitude = -102.0&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;noaa_swdi(dataset = &amp;quot;nx3tvs&amp;quot;, startdate = &amp;quot;20060505&amp;quot;, enddate = &amp;quot;20060516&amp;quot;,
    radius = 15, center = c(-102, 32.7), stat = &amp;quot;count&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$totalCount
## [1] 1
##
## $meta$totalTimeInSeconds
## [1] 0.02
##
##
## $data
## [1] &amp;quot;37&amp;quot;
##
## $shape
## data frame with 0 columns and 1 rows
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;noaa_swdi&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

      </description>
    </item>
    
    <item>
      <title>dvn - Sharing Reproducible Research from R</title>
      <link>https://ropensci.org/blog/2014/02/20/dvn-dataverse-network/</link>
      <pubDate>Thu, 20 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/02/20/dvn-dataverse-network/</guid>
      <description>
        
        

&lt;p&gt;Reproducible research involves the careful, annotated preservation of data, analysis code, and associated files, such that statistical procedures, output, and published results can be directly and fully replicated. As the push for reproducible research has grown, the R community has responded with an increasingly large set of tools for engaging in reproducible research practices (see, for example, the &lt;a href=&#34;http://cran.r-project.org/web/views/ReproducibleResearch.html&#34;&gt;ReproducibleResearch Task View&lt;/a&gt; on CRAN). Most of these tools focus on improving one&amp;rsquo;s own workflow through closer integration of data analysis and report generation. But reproducible research also requires the persistent - and perhaps indefinite - storage of research files so that they can be used to recreate or modify future analyses and reports.&lt;/p&gt;

&lt;p&gt;It is therefore critical that R include functionality for the persistent storage of reproducible research files. And I&amp;rsquo;m pleased to announce here that the &lt;strong&gt;dvn&lt;/strong&gt; package (&lt;a href=&#34;http://cran.r-project.org/web/packages/dvn/index.html&#34;&gt;CRAN&lt;/a&gt;, &lt;a href=&#34;http://ropensci.org/dvn.html&#34;&gt;GitHub&lt;/a&gt;) has now been integrated into the rOpenSci project. &lt;strong&gt;dvn&lt;/strong&gt; provides simple, programmatic access to &lt;a href=&#34;http://thedata.org/&#34;&gt;The Dataverse Network Project&lt;/a&gt;, an open-source data archive project created by Harvard University&amp;rsquo;s &lt;a href=&#34;http://www.iq.harvard.edu/&#34;&gt;Institute for Quantitative Social Science&lt;/a&gt;. Full details about &lt;strong&gt;dvn&lt;/strong&gt; are forthcoming in &lt;a href=&#34;http://journal.r-project.org/&#34;&gt;The R Journal&lt;/a&gt;, and this post provides a basic overview of the package&amp;rsquo;s core functionality.&lt;/p&gt;

&lt;p&gt;Note that rOpenSci has already created the rFigShare package (&lt;a href=&#34;http://cran.r-project.org/web/packages/rfigshare/index.html&#34;&gt;CRAN&lt;/a&gt;, &lt;a href=&#34;http://ropensci.org/rfigshare.html&#34;&gt;GitHub&lt;/a&gt;), which allows users to upload files to &lt;a href=&#34;http://figshare.com/&#34;&gt;fishare&lt;/a&gt;. Together, these packages give R users an array of tools to enhance the reproducible research workflow and extend it publicly and permanently for the benefit of future scientists.&lt;/p&gt;

&lt;h2 id=&#34;installing-the-package&#34;&gt;Installing the package&lt;/h2&gt;

&lt;p&gt;A stable version of the package (0.3.3) is now available on CRAN.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;dvn&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or you can install the latest development version from GitHub:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;devtools&amp;quot;)
install_github(&amp;quot;ropensci/dvn&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;creating-a-dataverse-and-archiving-files&#34;&gt;Creating a dataverse and archiving files&lt;/h2&gt;

&lt;p&gt;Creating a Dataverse Network account is simple. Just visit a Dataverse Network, such as &lt;a href=&#34;http://thedata.harvard.edu/dvn/&#34;&gt;The Harvard Dataverse Network&lt;/a&gt;, click &amp;ldquo;Create Account,&amp;rdquo; and open a personal dataverse. From there, one can easily create studies, populate them with metadata and files, and release them to the public.&lt;/p&gt;

&lt;p&gt;To get started, simply load &lt;strong&gt;dvn&lt;/strong&gt;, pick a Dataverse Network (the one you created an account through), and load your username and password.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;dvn&amp;quot;)
options(dvn = &#39;https://thedata.harvard.edu/dvn/&#39;)
options(dvn.user = &amp;quot;username&amp;quot;)
options(dvn.pwd = &amp;quot;password&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Creating a study requires supplying basic metadata that will allow users to find the study. At a minimum, this includes the title for the study, but many other fields are allowed (see &lt;code&gt;? dvBuildMetadata&lt;/code&gt;). The metadata need to be written in Dublin Core XML, so a helper function &lt;code&gt;dvBuildMetadata&lt;/code&gt; can be used to easily write metadata fields to an appropriate format:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m &amp;lt;- dvBuildMetadata(title = &amp;quot;My Study&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This metadata can then be used to create a new study within a named dataverse. When you initially create an account, you only have a personal dataverse but you can also create additional dataverses (through the web interface) for specific projects or institutions. Thus &lt;code&gt;dvCreateStudy&lt;/code&gt; requires you to supply the name of the dataverse where you want to create a study:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;s &amp;lt;- dvCreateStudy(&amp;quot;mydataverse&amp;quot;, m)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once a study is created, you simply need to add files, such as code, data, etc. using &lt;code&gt;dvAddFile&lt;/code&gt;. This can be done in a number of ways, including uploading all files in a .zip directory, uploading a vector of named files, or even uploading a dataframe that is currently open in R. An optional &lt;code&gt;category&lt;/code&gt; argument can be used to organize the uploaded files into categories.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# add files and release study using `objectid`
dvAddFile(s, &amp;quot;mydata.zip&amp;quot;, category=&amp;quot;Data&amp;quot;)

# or add multiple files:
dvAddFile(s, c(&amp;quot;analysis1.R&amp;quot;, &amp;quot;analysis2.R&amp;quot;), category=&amp;quot;Code&amp;quot;)

# or add R dataframes as files:
mydf &amp;lt;- data.frame(x = 1:10, y = 11:20)
dvAddFile(s, dataframe = &amp;quot;mydf&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With files uploaded, making the study publicly available is as easy as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dvReleaseStudy(s)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before releasing a study, it is possible to add (&lt;code&gt;dvAddFile&lt;/code&gt;) or delete files (&lt;code&gt;dvDeleteFile&lt;/code&gt;) or change the metadata associated with the file using &lt;code&gt;dvEditStudy&lt;/code&gt;. You can also delete the entire study using &lt;code&gt;dvDeleteStudy&lt;/code&gt;. Once released, the study is version-controlled. Any changes made after a release put the study in &amp;ldquo;DRAFT&amp;rdquo; mode and the study needs to be released again for those changes to be publicly visible. A released study cannot be deleted but public access to its contents can be revoked using &lt;code&gt;dvDeleteStudy&lt;/code&gt; (its DOI will point to a page noting the study was deaccessioned).&lt;/p&gt;

&lt;p&gt;At any point in the process, &lt;code&gt;dvStudyStatement&lt;/code&gt; can be used to retrieve a quick overview of the study&amp;rsquo;s status, metadata, and contents:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dvStudyStatement(&#39;hdl:1902.1/17864&#39;)
Study author:  James Druckman (Northwestern University); Jordan Fein (Northwestern University); Thomas Leeper (Northwestern University)
Study title:   Replication data for: A Source of Bias in Public Opinion Stability
ObjectId:      hdl:1902.1/17864
Study URI:     https://thedata.harvard.edu/dvn/api/data-deposit/v1/swordv2/edit/study/hdl:1902.1/17864
Last updated:  2013-07-27T10:54:30.200Z
Status:        RELEASED
Locked?        false
Files:
  src
1 https://thedata.harvard.edu/dvn/api/data-deposit/v1/swordv2/edit-media/file/2340116/Codebook2011-05-04.doc
2 https://thedata.harvard.edu/dvn/api/data-deposit/v1/swordv2/edit-media/file/2309028/Data.tab
3 https://thedata.harvard.edu/dvn/api/data-deposit/v1/swordv2/edit-media/file/2341890/Articles.doc
4 https://thedata.harvard.edu/dvn/api/data-deposit/v1/swordv2/edit-media/file/2341891/Questionnaire.doc
  type                      updated                  fileId
1 application/msword        2014-02-19T10:18:53.486Z 2340116
2 text/tab-separated-values 2014-02-19T10:18:53.487Z 2309028
3 application/msword        2014-02-19T10:18:53.488Z 2341890
4 application/msword        2014-02-19T10:18:53.489Z 2341891
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And &lt;code&gt;dvUserStudies&lt;/code&gt; can retrieve a listing of all studies in one&amp;rsquo;s dataverse:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dvUserStudies(&#39;leeper&#39;)
DV Title:      Thomas J. Leeper
DV name:       leeper
Released?      true
Generated by:  http://www.swordapp.org/ 2.0
Studies:
  title
1 Possible R ingest bug
2 Replication data for: A Source of Bias in Public Opinion Stability
3 Replication data for: The Informational Basis for Mass Polarization
4 Replication data for: Self-Interest and Attention to News among Issue Publics
5 Replication data for: Learning More from Political Communication Experiments: The Importance of Pretreatment Effects
6 Replication data for: Doing What Others Do:  Norms, Science, and Collective Action on Global Warming
7 Consequences of Selective Exposure for Political Engagement
  objectId
1 hdl:1902.1/LNEOX
2 hdl:1902.1/17864
3 hdl:1902.1/21964
4 hdl:1902.1/17863
5 hdl:1902.1/17218
6 hdl:1902.1/18249
7 hdl:1902.1/17865
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;search-for-archived-studies&#34;&gt;Search for archived studies&lt;/h2&gt;

&lt;p&gt;In addition to creating and managing dataverse studies, &lt;strong&gt;dvn&lt;/strong&gt; also allows users to search a Dataverse Network for existing studies and download metadata. We can search by a number of metadata fields (the allowed fields are retrievable via &lt;code&gt;dvSearchField&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# specify a Dataverse Network
options(dvn = &#39;https://thedata.harvard.edu/dvn/&#39;)

# search by author name
dvSearch(list(authorName = &amp;quot;leeper&amp;quot;))

# search by title using a boolean OR logic
dvSearch(list(title = &amp;quot;Denmark&amp;quot;, title = &amp;quot;Sweden&amp;quot;), boolean = &amp;quot;OR&amp;quot;)

# search all fields
dvSearch(&amp;quot;Tobacco&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A search returns a list of &lt;code&gt;objectId&lt;/code&gt; values, handles or DOIs that provide a global pointer to a particular study. Using an &lt;code&gt;objectId&lt;/code&gt; one can gather detailed study metadata in Data Documentation Initiative format (the default), Dublin Core, or possibly other formats (the list is exanding). Here&amp;rsquo;s an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# return DDI (by default)
dvMetadata(&amp;quot;hdl:1902.1/21964&amp;quot;)

# return Dublic Core
dvMetadata(&amp;quot;hdl:1902.1/21964&amp;quot;, format.type=&amp;quot;oai_dc&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In either case the result is an XML file, as a single character string. The metadata can be extensive, and are therefore better viewed outside of R. But a few wrapper functions allow one to view critical parts of the metadata, such the listing of files stored in a study:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;files &amp;lt;- dvExtractFileIds(dvMetadata(&amp;quot;hdl:1902.1/21964&amp;quot;))
files[, c(&#39;fileName&#39;, &#39;fileId&#39;)]
                          fileName  fileId
1    study2-replication-analysis.r 2341713
2    study1-replication-analysis.r 2341709
3                      coefpaste.r 2341888
4                     expResults.r 2341889
5            Study 2 Codebook.docx 2341712
6 study2-data-final-2012-06-08.csv 2341711
7 study1-data-final-2012-06-08.csv 2341710
8             Study 2 Webpages.zip 2341714
9             Study 1 Webpages.zip 2341715
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Generally, files cannot be directly downloaded into R because of Terms of Use restrictions currently placed on studies. In the future this may change, so &lt;strong&gt;dvn&lt;/strong&gt; provides forward-compatible functions &lt;code&gt;dvDownloadInfo&lt;/code&gt; and &lt;code&gt;dvDownload&lt;/code&gt; to check whether files can be downloaded and to perform the download if allowed, respectively.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>New features in the most recent taxize update, v0.2</title>
      <link>https://ropensci.org/blog/2014/02/19/taxize-update/</link>
      <pubDate>Wed, 19 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/02/19/taxize-update/</guid>
      <description>
        
        

&lt;p&gt;We just released a new version of &lt;code&gt;taxize&lt;/code&gt; - version 0.2.0. This release contains a number of new features, and bug fixes. Here is a run down of some of the changes:&lt;/p&gt;

&lt;h2 id=&#34;first-install-and-load-taxize&#34;&gt;First, install and load taxize&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;rgbif&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(taxize)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;new-things&#34;&gt;New things&lt;/h2&gt;

&lt;h3 id=&#34;new-functions-class2tree&#34;&gt;New functions: class2tree&lt;/h3&gt;

&lt;p&gt;Sometimes you just want to have a visual of the taxonomic relationships among taxa. If you don&amp;rsquo;t know how to build a molecular phylogeny, don&amp;rsquo;t have time, or there just isn&amp;rsquo;t molecular data, you can sorta build one using taxonomy. Building on our &lt;code&gt;classification&lt;/code&gt; function, you can get a bunch of taxonomic hierarchies from the &lt;code&gt;classification&lt;/code&gt; function, then pass them to the new function &lt;code&gt;class2tree&lt;/code&gt;. Like so:&lt;/p&gt;

&lt;p&gt;Define a species list&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spnames &amp;lt;- c(&amp;quot;Latania lontaroides&amp;quot;, &amp;quot;Randia cubana&amp;quot;, &amp;quot;Blumea brevipes&amp;quot;, &amp;quot;Commelina erecta&amp;quot;,
    &amp;quot;Miconia pyramidalis&amp;quot;, &amp;quot;Aquilegia moorcroftiana&amp;quot;, &amp;quot;Acridocarpus austrocaledonicus&amp;quot;,
    &amp;quot;Vaccinium wrightii&amp;quot;, &amp;quot;Riocreuxia flanaganii&amp;quot;, &amp;quot;Macroditassa adnata&amp;quot;, &amp;quot;Acianthera ochreata&amp;quot;,
    &amp;quot;Spathodea campanulata&amp;quot;, &amp;quot;Leucadendron salicifolium&amp;quot;, &amp;quot;Habenaria fluminensis&amp;quot;,
    &amp;quot;Platostoma siamense&amp;quot;, &amp;quot;Bulbophyllum hoehnei&amp;quot;, &amp;quot;Aspidosperma polyneuron&amp;quot;,
    &amp;quot;Rhynchospora fascicularis&amp;quot;, &amp;quot;Sida lonchitis&amp;quot;, &amp;quot;Ardisia cymosa&amp;quot;, &amp;quot;Morinda brachycalyx&amp;quot;,
    &amp;quot;Tetrastigma hypoglaucum&amp;quot;, &amp;quot;Paphiopedilum vietnamense&amp;quot;, &amp;quot;Goodenia glabra&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then collect taxonomic hierarchies for each taxon, and remove those with no results (those with no results are just &lt;code&gt;NA&lt;/code&gt;) (I&amp;rsquo;m setting &lt;code&gt;verbose=TRUE&lt;/code&gt; to suppress messages for this example)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out &amp;lt;- classification(spnames, db = &amp;quot;ncbi&amp;quot;, verbose = FALSE)
out &amp;lt;- out[!is.na(out)]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Use &lt;code&gt;class2tree&lt;/code&gt; to automagically convert the list of hierarchies to a ape &lt;code&gt;phylo&lt;/code&gt; object, then plot&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tr &amp;lt;- class2tree(out)
plot(tr, no.margin = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-02-19-taxize-update/unnamed-chunk-5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;new-functions-get-gbfid&#34;&gt;New functions: get_gbfid&lt;/h3&gt;

&lt;p&gt;The Global Biodiversity Information Facility (GBIF) has their own taxonomy. They allow programmatic access to their taxonomy, see &lt;a href=&#34;http://www.gbif.org/developer/summary&#34;&gt;here&lt;/a&gt; for details. Also see our &lt;a href=&#34;https://github.com/ropensci/rgbif&#34;&gt;&lt;code&gt;rgbif&lt;/code&gt; package&lt;/a&gt; that wraps all their API services.&lt;/p&gt;

&lt;p&gt;We added a similar function to our &lt;code&gt;get_tsn&lt;/code&gt;, &lt;code&gt;get_uid&lt;/code&gt;, etc. functions for various taxonomies, but for the GBIF taxonomy. Here are some example calls:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;get_gbifid(sciname = &amp;quot;Poa annua&amp;quot;, verbose = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##         1
## &amp;quot;2704179&amp;quot;
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;gbifid&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;get_gbifid(sciname = &amp;quot;Pinus contorta&amp;quot;, verbose = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##         1
## &amp;quot;5285750&amp;quot;
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;gbifid&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;get_gbifid(sciname = &amp;quot;Puma concolor&amp;quot;, verbose = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##         1
## &amp;quot;2435099&amp;quot;
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;gbifid&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;get_gbifid(c(&amp;quot;Poa annua&amp;quot;, &amp;quot;Pinus contorta&amp;quot;), verbose = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;2704179&amp;quot; &amp;quot;5285750&amp;quot;
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;gbifid&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This could be useful if you for example, want to have the exact IDs GBIF uses for your set of species to use at some later point - and at that later point you could use our &lt;code&gt;rgbif&lt;/code&gt; package and search for biodiversity occurrence data with the IDs you collected. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rgbif)
(id &amp;lt;- get_gbifid(sciname = &amp;quot;Puma concolor&amp;quot;, verbose = FALSE))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##         1
## &amp;quot;2435099&amp;quot;
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;gbifid&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;occ_search(id)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $meta
## $meta$offset
## [1] 0
##
## $meta$limit
## [1] 20
##
## $meta$endOfRecords
## [1] FALSE
##
## $meta$count
## [1] 8392
##
##
## $hierarchy
## $hierarchy[[1]]
##            name     key    rank
## 1      Animalia       1 kingdom
## 2      Chordata      44  phylum
## 3      Mammalia     359   clazz
## 4     Carnivora     732   order
## 5       Felidae    9703  family
## 6          Puma 2435098   genus
## 7 Puma concolor 2435099 species
##
##
## $data
##             name       key longitude latitude
## 1  Puma concolor 866527350   -110.58    31.85
## 2  Puma concolor 866545169   -103.60    29.16
## 3  Puma concolor 866495627   -106.39    35.13
## 4  Puma concolor 866498665    -89.43    20.31
## 5  Puma concolor 866508658   -105.04    19.47
## 6  Puma concolor 866523280   -118.24    34.06
## 7  Puma concolor 866526517   -104.45    29.92
## 8  Puma concolor 866530535   -118.30    34.07
## 9  Puma concolor 860790696    -77.35     2.77
## 10 Puma concolor        NA        NA       NA
## 11 Puma concolor        NA        NA       NA
## 12 Puma concolor        NA        NA       NA
## 13 Puma concolor 866525528   -123.83    40.13
## 14 Puma concolor 866531329   -123.83    40.13
## 15 Puma concolor 866519497   -118.90    34.54
## 16 Puma concolor 866601452   -122.52    38.45
## 17 Puma concolor 866547065   -110.30    41.88
## 18 Puma concolor 866562541   -123.83    40.13
## 19 Puma concolor 866562081   -123.82    40.13
## 20 Puma concolor 866558112   -103.13    29.65
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In addition, &lt;code&gt;get_ids&lt;/code&gt; now accepts &amp;lsquo;gbif&amp;rsquo; as an option for the &lt;code&gt;db&lt;/code&gt; parameter - &lt;code&gt;get_ids&lt;/code&gt; is our omnibus function to search for taxon ids across all sources available in &lt;code&gt;taxize&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;new-functions-rbind-and-cbind-for-classification&#34;&gt;New functions: rbind and cbind for classification&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;classification&lt;/code&gt; function gives back taxonomic hierarchies from a variety of sources, including NCBI, ITIS, Catalogue of Life, Tropicos, EOL, and now GBIF. If you pass in many taxonomic IDs or taxon names, you get back a list of hierarchies. We added two functions to make it convenient to mash these outputs together, &lt;code&gt;rbind&lt;/code&gt; for basically stacking hierarchies on top of one another, and &lt;code&gt;cbind&lt;/code&gt; for making a width-wise combination of hierarchies. Our &lt;code&gt;cbind&lt;/code&gt; doesn&amp;rsquo;t do exactly what your used to cbind doing for data.frame&amp;rsquo;s. The examples below are based on some changed code since the newest CRAN version, but you can install the development version with the changes from Github (see &lt;a href=&#34;https://github.com/ropensci/taxize#install-taxize&#34;&gt;here&lt;/a&gt; for instructions).&lt;/p&gt;

&lt;p&gt;From a call to &lt;code&gt;get_ids&lt;/code&gt;, then passed on to &lt;code&gt;classification&lt;/code&gt;, we get a object of class &lt;code&gt;classification_ids&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(out &amp;lt;- get_ids(names = &amp;quot;Puma concolor&amp;quot;, db = c(&amp;quot;ncbi&amp;quot;, &amp;quot;gbif&amp;quot;), verbose = FALSE))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $ncbi
## Puma concolor
##        &amp;quot;9696&amp;quot;
## attr(,&amp;quot;match&amp;quot;)
## [1] &amp;quot;found&amp;quot;
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;uid&amp;quot;
##
## $gbif
## Puma concolor
##     &amp;quot;2435099&amp;quot;
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;gbifid&amp;quot;
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;ids&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(cl &amp;lt;- classification(out, verbose = FALSE))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $ncbi
## $`9696`
##                    name         rank
## 1    cellular organisms      no rank
## 2             Eukaryota superkingdom
## 3          Opisthokonta      no rank
## 4               Metazoa      kingdom
## 5             Eumetazoa      no rank
## 6             Bilateria      no rank
## 7         Deuterostomia      no rank
## 8              Chordata       phylum
## 9              Craniata    subphylum
## 10           Vertebrata      no rank
## 11        Gnathostomata   superclass
## 12           Teleostomi      no rank
## 13         Euteleostomi      no rank
## 14        Sarcopterygii      no rank
## 15 Dipnotetrapodomorpha      no rank
## 16            Tetrapoda      no rank
## 17              Amniota      no rank
## 18             Mammalia        class
## 19               Theria      no rank
## 20             Eutheria      no rank
## 21        Boreoeutheria      no rank
## 22       Laurasiatheria   superorder
## 23            Carnivora        order
## 24           Feliformia     suborder
## 25              Felidae       family
## 26              Felinae    subfamily
## 27                 Puma        genus
## 28        Puma concolor      species
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;classification&amp;quot;
## attr(,&amp;quot;db&amp;quot;)
## [1] &amp;quot;ncbi&amp;quot;
##
## $gbif
## $`2435099`
##            name    rank
## 1      Animalia kingdom
## 2      Chordata  phylum
## 3      Mammalia   clazz
## 4     Carnivora   order
## 5       Felidae  family
## 6          Puma   genus
## 7 Puma concolor species
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;classification&amp;quot;
##
## attr(,&amp;quot;class&amp;quot;)
## [1] &amp;quot;classification_ids&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can bind width-wise&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cbind(cl)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##              no rank superkingdom  kingdom   phylum subphylum
## 1 cellular organisms    Eukaryota  Metazoa Chordata  Craniata
## 2               &amp;lt;NA&amp;gt;         &amp;lt;NA&amp;gt; Animalia Chordata      &amp;lt;NA&amp;gt;
##      superclass    class     superorder     order   suborder  family
## 1 Gnathostomata Mammalia Laurasiatheria Carnivora Feliformia Felidae
## 2          &amp;lt;NA&amp;gt;     &amp;lt;NA&amp;gt;           &amp;lt;NA&amp;gt; Carnivora       &amp;lt;NA&amp;gt; Felidae
##   subfamily genus       species    clazz
## 1   Felinae  Puma Puma concolor     &amp;lt;NA&amp;gt;
## 2      &amp;lt;NA&amp;gt;  Puma Puma concolor Mammalia
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or bind length-wise&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rbind(cl)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    source taxonid                 name         rank
## 1    ncbi    9696   cellular organisms      no rank
## 2    ncbi    9696            Eukaryota superkingdom
## 3    ncbi    9696         Opisthokonta      no rank
## 4    ncbi    9696              Metazoa      kingdom
## 5    ncbi    9696            Eumetazoa      no rank
## 6    ncbi    9696            Bilateria      no rank
## 7    ncbi    9696        Deuterostomia      no rank
## 8    ncbi    9696             Chordata       phylum
## 9    ncbi    9696             Craniata    subphylum
## 10   ncbi    9696           Vertebrata      no rank
## 11   ncbi    9696        Gnathostomata   superclass
## 12   ncbi    9696           Teleostomi      no rank
## 13   ncbi    9696         Euteleostomi      no rank
## 14   ncbi    9696        Sarcopterygii      no rank
## 15   ncbi    9696 Dipnotetrapodomorpha      no rank
## 16   ncbi    9696            Tetrapoda      no rank
## 17   ncbi    9696              Amniota      no rank
## 18   ncbi    9696             Mammalia        class
## 19   ncbi    9696               Theria      no rank
## 20   ncbi    9696             Eutheria      no rank
## 21   ncbi    9696        Boreoeutheria      no rank
## 22   ncbi    9696       Laurasiatheria   superorder
## 23   ncbi    9696            Carnivora        order
## 24   ncbi    9696           Feliformia     suborder
## 25   ncbi    9696              Felidae       family
## 26   ncbi    9696              Felinae    subfamily
## 27   ncbi    9696                 Puma        genus
## 28   ncbi    9696        Puma concolor      species
## 29   gbif 2435099             Animalia      kingdom
## 30   gbif 2435099             Chordata       phylum
## 31   gbif 2435099             Mammalia        clazz
## 32   gbif 2435099            Carnivora        order
## 33   gbif 2435099              Felidae       family
## 34   gbif 2435099                 Puma        genus
## 35   gbif 2435099        Puma concolor      species
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or we can do the same thing on the class &lt;code&gt;classification&lt;/code&gt; that we get back from a call to one of &lt;code&gt;get_colid&lt;/code&gt;, &lt;code&gt;get_tsn&lt;/code&gt;, &lt;code&gt;get_eolid&lt;/code&gt;, &lt;code&gt;get_tpsid&lt;/code&gt;, &lt;code&gt;get_gbifid&lt;/code&gt;, or &lt;code&gt;get_uid&lt;/code&gt;, that&amp;rsquo;s then passed on to &lt;code&gt;classification&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cl_col &amp;lt;- classification(get_colid(c(&amp;quot;Puma concolor&amp;quot;, &amp;quot;Accipiter striatus&amp;quot;),
    verbose = FALSE))
rbind(cl_col)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    source  taxonid            name    rank
## 1     col  6862841        Animalia Kingdom
## 2     col  6862841        Chordata  Phylum
## 3     col  6862841        Mammalia   Class
## 4     col  6862841       Carnivora   Order
## 5     col  6862841         Felidae  Family
## 6     col  6862841            Puma   Genus
## 7     col 11909487        Animalia Kingdom
## 8     col 11909487        Chordata  Phylum
## 9     col 11909487            Aves   Class
## 10    col 11909487 Accipitriformes   Order
## 11    col 11909487    Accipitridae  Family
## 12    col 11909487       Accipiter   Genus
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cbind(cl_col)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    kingdom   phylum    class           order       family     genus
## 1 Animalia Chordata Mammalia       Carnivora      Felidae      Puma
## 2 Animalia Chordata     Aves Accipitriformes Accipitridae Accipiter
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Read more about changes in v0.2 &lt;a href=&#34;https://github.com/ropensci/taxize/releases/tag/v0.2.0&#34;&gt;at Github&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Changed and new things in the new version of rgbif, v0.5</title>
      <link>https://ropensci.org/blog/2014/02/17/rgbif-update/</link>
      <pubDate>Mon, 17 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/02/17/rgbif-update/</guid>
      <description>
        
        

&lt;p&gt;&lt;code&gt;rgbif&lt;/code&gt; is an R package to search and retrieve data from the Global Biodiverity Information Facilty (GBIF). &lt;code&gt;rgbif&lt;/code&gt; wraps R code around the [GBIF API][gbifapi] to allow you to talk to GBIF from R.&lt;/p&gt;

&lt;p&gt;We just pushed a new verion of &lt;code&gt;rgbif&lt;/code&gt; to cran - v0.5.0.  Source and binary files are now available on CRAN.&lt;/p&gt;

&lt;p&gt;There are a few new functions: &lt;code&gt;count_facet&lt;/code&gt;, &lt;code&gt;elevation&lt;/code&gt;, and &lt;code&gt;installations&lt;/code&gt;.  These are described, with examples, below.&lt;/p&gt;

&lt;p&gt;Functions to work with the old GBIF API remain in the package, but will be removed as soon as the old API is no longer supported by GBIF. See &lt;code&gt;rgbif-deprecated&lt;/code&gt; in the help for the package.&lt;/p&gt;

&lt;p&gt;Note: you can see a detailed list of all changes in new versions on the releases page for &lt;code&gt;rgbif&lt;/code&gt; on Githb here: &lt;a href=&#34;https://github.com/ropensci/rgbif/releases&#34;&gt;https://github.com/ropensci/rgbif/releases&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;install-rgbif-and-dependencies&#34;&gt;Install rgbif and dependencies&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;rgbif&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;load-rgbif-and-dependencies&#34;&gt;Load rgbif and dependencies&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(rgbif)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;new-functions&#34;&gt;New functions&lt;/h2&gt;

&lt;h3 id=&#34;new-function-count-facet&#34;&gt;New function: count_facet&lt;/h3&gt;

&lt;p&gt;Does facetted count searches, as GBIF doesn&amp;rsquo;t allow faceted searches against the count API. In this example, we have a set of species names, and we want counts by each of a set of 20 countries for each species. This function wraps up some code to essentially give you faceted search capability for the count service - of course this is much slower than if it was done server side.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spplist &amp;lt;- c(&amp;quot;Geothlypis trichas&amp;quot;, &amp;quot;Tiaris olivacea&amp;quot;, &amp;quot;Pterodroma axillaris&amp;quot;,
    &amp;quot;Calidris ferruginea&amp;quot;, &amp;quot;Pterodroma macroptera&amp;quot;, &amp;quot;Gallirallus australis&amp;quot;,
    &amp;quot;Falco cenchroides&amp;quot;, &amp;quot;Telespiza cantans&amp;quot;, &amp;quot;Oreomystis bairdi&amp;quot;, &amp;quot;Cistothorus palustris&amp;quot;)
keys &amp;lt;- sapply(spplist, function(x) name_backbone(x, rank = &amp;quot;species&amp;quot;)$usageKey)
library(plyr)
keys &amp;lt;- compact(keys)
count_facet(by = &amp;quot;country&amp;quot;, countries = 20, removezeros = TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##                 country       V1
## 1               ANDORRA    96379
## 2  UNITED_ARAB_EMIRATES   273098
## 3           AFGHANISTAN    64020
## 4       ANTIGUA_BARBUDA    12090
## 5              ANGUILLA    13188
## 6               ALBANIA     8202
## 7               ARMENIA    26253
## 8                ANGOLA   168412
## 9            ANTARCTICA  1068590
## 10            ARGENTINA  1155372
## 11       AMERICAN_SAMOA    12248
## 12              AUSTRIA  2702533
## 13            AUSTRALIA 38729449
## 14                ARUBA     8178
## 15        ALAND_ISLANDS      566
## 16           AZERBAIJAN    17622
## 17   BOSNIA_HERZEGOVINA    10050
## 18             BARBADOS    21683
## 19           BANGLADESH    24255
## 20              BELGIUM  5167393
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;new-function-elevation&#34;&gt;New function: elevation&lt;/h3&gt;

&lt;p&gt;Gets elevation data for a &lt;code&gt;data.frame&lt;/code&gt; of lat/long points, or a list of lat/long points. This function uses the Google Elevation API.&lt;/p&gt;

&lt;p&gt;You can get elevation/altitude data back from the GBIF API, but that data is often missing. See the &lt;code&gt;altitude&lt;/code&gt; column in data output from &lt;code&gt;occ_search&lt;/code&gt; - you need to set the fields parameter to &lt;em&gt;all&lt;/em&gt; or ask for &lt;em&gt;altitude&lt;/em&gt; explicitly.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;key &amp;lt;- name_backbone(name = &amp;quot;Puma concolor&amp;quot;, kingdom = &amp;quot;plants&amp;quot;)$speciesKey
dat &amp;lt;- occ_search(taxonKey = key, return = &amp;quot;data&amp;quot;, limit = 10, georeferenced = TRUE)
head(dat)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##            name       key longitude latitude
## 1 Puma concolor 866527350   -110.58    31.85
## 2 Puma concolor 866545169   -103.60    29.16
## 3 Puma concolor 866495627   -106.39    35.13
## 4 Puma concolor 866498665    -89.43    20.31
## 5 Puma concolor 866508658   -105.04    19.47
## 6 Puma concolor 866523280   -118.24    34.06
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Attach elevation data to the &lt;code&gt;data.frame&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(elevation(dat))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##            name       key longitude latitude elevation
## 1 Puma concolor 866527350   -110.58    31.85   1294.62
## 2 Puma concolor 866545169   -103.60    29.16    665.03
## 3 Puma concolor 866495627   -106.39    35.13   2250.25
## 4 Puma concolor 866498665    -89.43    20.31     29.05
## 5 Puma concolor 866508658   -105.04    19.47     69.82
## 6 Puma concolor 866523280   -118.24    34.06     93.25
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;new-function-installations&#34;&gt;New function: installations&lt;/h3&gt;

&lt;p&gt;Gets metdata on installations via the &lt;a href=&#34;http://www.gbif.org/developer/registry#installations&#34;&gt;installations API&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This example requests data for installations with the query terms &amp;lsquo;france&amp;rsquo; in the metadata. We&amp;rsquo;ll just look at the first result, and just the description and its first contact.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df &amp;lt;- installations(query = &amp;quot;france&amp;quot;)
df$results[[1]]$description
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Natural Science Collections from the University of Alberta&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df$results[[1]]$contacts[[1]]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## $key
## [1] 18037
##
## $type
## [1] &amp;quot;TECHNICAL_POINT_OF_CONTACT&amp;quot;
##
## $primary
## [1] TRUE
##
## $firstName
## [1] &amp;quot;Jim Whittome&amp;quot;
##
## $email
## [1] &amp;quot;jim.whittome@ualberta.ca&amp;quot;
##
## $createdBy
## [1] &amp;quot;registry-migration.gbif.org&amp;quot;
##
## $modifiedBy
## [1] &amp;quot;registry-migration.gbif.org&amp;quot;
##
## $created
## [1] &amp;quot;2013-02-26T22:15:50.000+0000&amp;quot;
##
## $modified
## [1] &amp;quot;2013-03-18T16:17:46.000+0000&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Another example, just requesting contact data for an installation identifier (i.e. uuid).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;installations(data = &amp;quot;contact&amp;quot;, uuid = &amp;quot;2e029a0c-87af-42e6-87d7-f38a50b78201&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;## [[1]]
## [[1]]$key
## [1] 19952
##
## [[1]]$type
## [1] &amp;quot;TECHNICAL_POINT_OF_CONTACT&amp;quot;
##
## [[1]]$primary
## [1] TRUE
##
## [[1]]$firstName
## [1] &amp;quot;Biodiversity Informatics Manager&amp;quot;
##
## [[1]]$email
## [1] &amp;quot;bdim@ansp.org&amp;quot;
##
## [[1]]$createdBy
## [1] &amp;quot;registry-migration.gbif.org&amp;quot;
##
## [[1]]$modifiedBy
## [1] &amp;quot;2e029a0c-87af-42e6-87d7-f38a50b78201&amp;quot;
##
## [[1]]$created
## [1] &amp;quot;2013-07-22T18:17:06.000+0000&amp;quot;
##
## [[1]]$modified
## [1] &amp;quot;2014-01-10T20:03:03.867+0000&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;minor-changes&#34;&gt;Minor changes&lt;/h2&gt;

&lt;h3 id=&#34;sapply-vapply&#34;&gt;sapply -&amp;gt; vapply&lt;/h3&gt;

&lt;p&gt;We replaced &lt;code&gt;sapply&lt;/code&gt; with &lt;code&gt;vapply&lt;/code&gt; as &lt;code&gt;vapply&lt;/code&gt; can be faster than &lt;code&gt;sapply&lt;/code&gt;, and with &lt;code&gt;vapply&lt;/code&gt; you can include a check in the function call to make sure that the returned data elements are of the correct type.&lt;/p&gt;

&lt;h3 id=&#34;other-minor-changes&#34;&gt;Other minor changes&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Changed name of &lt;code&gt;country_codes&lt;/code&gt; function to &lt;code&gt;gbif_country_codes&lt;/code&gt; to avoid conflicts with other packages.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gbifmap&lt;/code&gt; now plots a map with &lt;code&gt;ggplot2::coord_fixed(ratio=1)&lt;/code&gt; so that you don&amp;rsquo;t get wonky maps.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;occ_count&lt;/code&gt; now accepts a call to query publishingCountry with a single parameter (country), to list occurrence counts by publishing country.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;occ_get&lt;/code&gt; and &lt;code&gt;occ_search&lt;/code&gt; lose parameter minimal, and in its place gains parameter fields, in which you can request fields=&amp;lsquo;minimal&amp;rsquo; to get just name, taxon key, lat and long. Or set to &amp;lsquo;all&amp;rsquo; to get all fields, or selection the fields you want by passing in a vector of field names.&lt;/li&gt;
&lt;li&gt;Updated base url for the GIBF parser function &lt;code&gt;parsenames&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;isocodes dataset now with documentation.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Caching Encyclopedia of Life API calls</title>
      <link>https://ropensci.org/blog/2014/02/12/caching-with-api/</link>
      <pubDate>Wed, 12 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/02/12/caching-with-api/</guid>
      <description>
        
        &lt;p&gt;In &lt;a href=&#34;http://ropensci.org/blog/2014/02/03/caching-offline/&#34;&gt;a recent blog post&lt;/a&gt; we discussed caching calls to the web offline, on your own computer. Just like you can cache data on your own computer, a data provider can do the same thing. Most of the data providers we work with do not provide caching. However, at least one does: &lt;a href=&#34;http://eol.org/&#34;&gt;EOL&lt;/a&gt;, or Encyclopedia of Life. EOL allows you to set the amount of time (in seconds) that the call is cached, within which time you can make the same call and get the data back faster. We have a number of functions to interface with EOL in our &lt;code&gt;taxize&lt;/code&gt; package.&lt;/p&gt;

&lt;p&gt;Install and load &lt;code&gt;taxize&lt;/code&gt; and &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(c(&amp;quot;taxize&amp;quot;, &amp;quot;ggplot2&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(taxize)
library(ggplot2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To easily visualize the benefit of using EOL&amp;rsquo;s caching, let&amp;rsquo;s define a function to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Make a call to the EOL API search service (via the &lt;code&gt;eol_search&lt;/code&gt; function in &lt;code&gt;taxize&lt;/code&gt;) with caching set to X seconds (which means the cached result will be available for X seconds). This first call caches the query on their servers. Note that in the &lt;code&gt;eol_search&lt;/code&gt; function below, we are using the &lt;code&gt;cache_ttl&lt;/code&gt; parameter to set the number of seconds to cache the request.&lt;/li&gt;
&lt;li&gt;The second call is done before X seconds pass, so should be faster as the first one was cached.&lt;/li&gt;
&lt;li&gt;Sleep for a period, a bit longer than the amount of time the call is cached.&lt;/li&gt;
&lt;li&gt;The third call occurs after the cached call should be gone on the EOL servers.&lt;/li&gt;
&lt;li&gt;Plot the times each request took.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;testcache &amp;lt;- function(terms, cache){
  first &amp;lt;- system.time( eol_search(terms=terms, cache_ttl = cache) )
  second &amp;lt;- system.time( eol_search(terms=terms, cache_ttl = cache) )
  Sys.sleep(cache+2)
  third &amp;lt;- system.time( eol_search(terms=terms, cache_ttl = cache) )

  df &amp;lt;- data.frame(labs=c(&#39;nocache&#39;,&#39;withcache&#39;,&#39;cachetimedout&#39;),
                   vals=c(first[[3]], second[[3]], third[[3]]))
  df$labs &amp;lt;- factor(df$labs, levels = c(&#39;nocache&#39;,&#39;withcache&#39;,&#39;cachetimedout&#39;))
  ggplot(df, aes(labs, vals)) +
    geom_bar(stat=&#39;identity&#39;) +
    theme_grey(base_size = 20) +
    ggtitle(sprintf(&amp;quot;search term: &#39;%s&#39;\n&amp;quot;, terms)) +
    labs(y=&#39;Time to get data\n&#39;, x=&#39;&#39;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Search for the term &lt;em&gt;lion&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;testcache(terms = &amp;quot;lion&amp;quot;, cache = 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-02-12-caching-with-api/unnamed-chunk-4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Search for the term &lt;em&gt;beetle&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;testcache(terms = &amp;quot;beetle&amp;quot;, cache = 10)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ropensci.org/assets/blog-images/2014-02-12-caching-with-api/unnamed-chunk-5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Caching works the same way with the &lt;code&gt;eol_pages&lt;/code&gt; function. No other API services and associated functions in &lt;code&gt;taxize&lt;/code&gt; support caching on the server side by the data provider. Of course you can do your own caching using &lt;code&gt;knitr&lt;/code&gt; or other methods - some of which we discussed in &lt;a href=&#34;http://ropensci.org/blog/2014/02/03/caching-offline/&#34;&gt;an earlier post&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Caching API calls offline</title>
      <link>https://ropensci.org/blog/2014/02/03/caching-offline/</link>
      <pubDate>Mon, 03 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/02/03/caching-offline/</guid>
      <description>
        
        &lt;p&gt;I&amp;rsquo;ve recently heard the idea of &amp;ldquo;offline first&amp;rdquo; via especially &lt;a href=&#34;http://hood.ie/&#34;&gt;Hood.ie&lt;/a&gt;. We of course don&amp;rsquo;t do web development, but primarily build R interfaces to data on the web. Internet availablility is increasinghly ubiqutous, but there still are times and places where you don&amp;rsquo;t have internet, but need to get work done.&lt;/p&gt;

&lt;p&gt;In the R packages we write there are generally two steps to every workflow:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Make a call to the web to request data and collect data&lt;/li&gt;
&lt;li&gt;Rearrange the result as some sort of R object (e.g., an R &lt;code&gt;data.frame&lt;/code&gt;), then visualize, analyze, etc.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first process is not possible if you don&amp;rsquo;t have an internet connection - making the second step fail as a result.&lt;/p&gt;

&lt;p&gt;We often run our code many many times over. Given that rule, when we use packages that make calls to the web in our workflows, wouldn&amp;rsquo;t it be nice if those calls were cached locally so that if you are offline, and you have run the code previously while online, you can still run the code?&lt;/p&gt;

&lt;p&gt;This is possible if we use caching which isn&amp;rsquo;t a new concept. In fact, if you use &lt;code&gt;knitr&lt;/code&gt;, you can optionally cache each code chunk so that you could still run code offline if the code has been run previously while online.&lt;/p&gt;

&lt;p&gt;However, I personally don&amp;rsquo;t start out every analysis in a &lt;code&gt;.Rmd&lt;/code&gt; or &lt;code&gt;.Rnw&lt;/code&gt; document with caching turned on, so what is an alternate solution?&lt;/p&gt;

&lt;p&gt;Enter &lt;code&gt;mocker&lt;/code&gt;. &lt;code&gt;mocker&lt;/code&gt; is an R package that attemps to abstract away the details of caching calls to the web, while allowing those interested fine grained control. In plain english, this means, it tries to make caching super easy, but let more technical people do more sophisticated caching.&lt;/p&gt;

&lt;p&gt;There is a tradeoff between speed and utility in caching. There is straightup caching (using e.g., &lt;code&gt;saveRDS&lt;/code&gt; or &lt;code&gt;R.cache&lt;/code&gt;) to a file on your machine, which is fast, but of course then you simply have a bunch of files. If you use a key-value store (Redis via &lt;code&gt;rredis&lt;/code&gt;), the act of caching is a bit slower, but you gain the ability to do more things with your key-value store than just retrieving your object. Last, you can use a NoSQL document database like CouchDB (via my own &lt;code&gt;sofa&lt;/code&gt; or &lt;code&gt;R4CouchDB&lt;/code&gt;), which offers even more flexibility, but is even slower than the first two options.&lt;/p&gt;

&lt;p&gt;The goal of &lt;code&gt;mocker&lt;/code&gt; is to make this all easy. Beginners can get the benefits of offline data availability by using default options, which writes to a local file (e.g., using &lt;code&gt;R.cache&lt;/code&gt;), but advanced users can use the Redis option (via &lt;code&gt;rredis&lt;/code&gt;) to then later access their data for another context if they so choose.&lt;/p&gt;

&lt;p&gt;To demonstrate, I&amp;rsquo;ll use the PLOS search API. I wrote a little function that mimics what an actual function may be. The function takes in a query term, and asks for id, author, and abstract fields back (with the &lt;code&gt;fl&lt;/code&gt; parameter), only full articles (with the &lt;code&gt;fq&lt;/code&gt; parameter), data type json (with the &lt;code&gt;wt&lt;/code&gt; parameter), and limits to 100 results.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cachefxn &amp;lt;- function(q=&amp;quot;*:*&amp;quot;, db=NULL, cache=FALSE, backend=&#39;local&#39;, path)
{
  # get api query ready
  url = &amp;quot;http://api.plos.org/search&amp;quot;
  args &amp;lt;- list(q=q, fl=&#39;id,author,abstract&#39;, fq=&#39;doc_type:full&#39;, wt=&#39;json&#39;, limit=100)

  # create a key
  cachekey &amp;lt;- make_key(url, args)

  # if cache=TRUE, check for data in backend using key, if cache=FALSE, returns NULL
  out &amp;lt;- cache_get(cache, cachekey, backend, path, db=db)

  # if out=NULL, proceed to make call to web
  if(!is.null(out)){ out } else
  {
    tt &amp;lt;- GET(url, query = args)
    stop_for_status(tt)
    temp &amp;lt;- content(tt, as = &amp;quot;text&amp;quot;)
    # If cache=TRUE, cache key and value in chosen backend
    cache_save(cache, cachekey, temp, backend, path, db = db)
    return( temp )
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;ll define a query term &lt;code&gt;q&lt;/code&gt; that we&amp;rsquo;ll pass in to the &lt;code&gt;cachefxn&lt;/code&gt; function each time.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(mocker)
q &amp;lt;- &amp;quot;cell biology&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first and fastest option (at least in my testing) is local storage via &lt;code&gt;saveRDS&lt;/code&gt;. This is the default option. The 1st run with &lt;code&gt;cache=TRUE&lt;/code&gt; is the same speed as &lt;code&gt;cache=FALSE&lt;/code&gt;. Then, then 2nd time the function is called with &lt;code&gt;cache=TRUE&lt;/code&gt;, the call is much, much faster as your simply calling the data from local storage. Internally, the url constructed for the particular base URL and query terms is used as a key to store the data with, or converted to a hash and then stored, and then searched for in your chosen &lt;code&gt;backend&lt;/code&gt;. If it is found then the value is returned. If it is not found, then the function proceeeds to send the query to the web.&lt;/p&gt;

&lt;p&gt;Here, local storage is much faster than calling from the web. The first call goes to the web, while the second returns data via &lt;code&gt;readRDS&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;system.time(cachefxn(q = q, cache = TRUE, path = &amp;quot;~/scottscache/&amp;quot;, backend = &amp;quot;local&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    user  system elapsed
##   0.020   0.001   1.609
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;system.time(cachefxn(q = q, cache = TRUE, path = &amp;quot;~/scottscache/&amp;quot;, backend = &amp;quot;local&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    user  system elapsed
##   0.003   0.001   0.003
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;R.cache&lt;/code&gt; works about the same way, so I won&amp;rsquo;t go over that.&lt;/p&gt;

&lt;p&gt;Redis is an interesting option as it is not much slower than local storage, but offers more flexibility. For example, your data stored in Redis can be pushed up to a cloud backed instance of Redis, and you&amp;rsquo;re probably less likley to delete your data in Redis relative to local files stored in the above method. First, startup Redis in your shell&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;redis-server
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then choose &lt;code&gt;backend=&#39;redis&#39;&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;system.time(cachefxn(q = q, cache = TRUE, backend = &amp;quot;redis&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    user  system elapsed
##   0.023   0.002   1.973
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;system.time(cachefxn(q = q, cache = TRUE, backend = &amp;quot;redis&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;##    user  system elapsed
##   0.004   0.001   0.004
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here&amp;rsquo;s some benchmarking to show all methods together:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(microbenchmark)
microbenchmark(
 saveRDS=cachefxn(q=q, cache=TRUE, path=&amp;quot;~/scottscache/&amp;quot;),
 R.cache=cachefxn(q=q, cache=TRUE, backend=&amp;quot;rcache&amp;quot;),
 Redis=cachefxn(q=q, cache=TRUE, backend=&amp;quot;redis&amp;quot;),
 SQLite=cachefxn(q=q, cache=TRUE, backend=&amp;quot;sqlite&amp;quot;, db=sqldb),
 CouchDB=cachefxn(q=q, cache=TRUE, backend=&amp;quot;couchdb&amp;quot;, db=cdb),
 times=50
)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Unit: milliseconds
    expr       min        lq    median        uq       max neval
   local  4.007978  4.278275  4.362870  4.816612  6.675667    50
  R.cache  4.461892  4.824427  5.038775  5.801503  8.543470    50
   redis  5.624845  6.146504  6.401435  7.075442  9.408585    50
  sqlite 10.074079 10.652784 11.210765 12.425844 18.450480    50
 couchdb 25.964903 27.661443 29.219574 32.668773 36.355845    50
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is all moot if you do all your coding within a &lt;code&gt;knitr&lt;/code&gt; context (latex or markdown), and can easily then cache everything. However, I think this approach may be useful in that it can make it seem as though you have a live internet connection when in fact there isn&amp;rsquo;t one. Let&amp;rsquo;s say you&amp;rsquo;re on a flight where internet costs $10 for 2 hours. You&amp;rsquo;re a grad student so of course you don&amp;rsquo;t pay for it. But not to worry! If you&amp;rsquo;ve executed the code previously with caching on, then the data acquisition step is okay, and you can continue to work on any downstream data manipulation and analyses steps.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>solr - an R interface to Solr</title>
      <link>https://ropensci.org/blog/2014/01/27/solr/</link>
      <pubDate>Mon, 27 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://ropensci.org/blog/2014/01/27/solr/</guid>
      <description>
        
        

&lt;p&gt;A number of the APIs we interact with (e.g., PLOS full text API, and USGS&amp;rsquo;s BISON API in &lt;a href=&#34;http://cran.r-project.org/web/packages/rplos/index.html&#34;&gt;rplos&lt;/a&gt; and &lt;a href=&#34;http://cran.r-project.org/web/packages/rbison/index.html&#34;&gt;rbison&lt;/a&gt;, respectively) expose &lt;a href=&#34;http://lucene.apache.org/solr/&#34;&gt;Solr&lt;/a&gt; endpoints. &lt;a href=&#34;http://lucene.apache.org/solr/&#34;&gt;Solr&lt;/a&gt; is an Apache hosted project - it is a powerful search server.  Given that at least two, and possibly more in the future, of the data providers we interact with provide Solr endpoints, it made sense to create an R package to make robust functions to interact with Solr that work across any Solr endpoint. This is then useful to us, and hopefully others.&lt;/p&gt;

&lt;p&gt;The following are a few examples covering some of things you can do in Solr that fall in to six categories:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Search: via &lt;code&gt;solr_search&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Grouping: via &lt;code&gt;solr_group&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Faceting: via &lt;code&gt;solr_facet&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Highlighting: via &lt;code&gt;solr_highlight&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Stats: via &lt;code&gt;solr_stats&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;More like this: via &lt;code&gt;solr_mlt&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;code&gt;solr&lt;/code&gt; package generally has two steps for any query: a) send the request given your inputs, and b) parse the output into a useful R data structure. Part a) is quite easy. However, part b) is harder. We are working hard on making parsers that are as general as possible for each of the data formats that are returned by group, facet, highlight, etc., but of course we will still definitely fail in many cases. Please do submit bug reports to &lt;a href=&#34;https://github.com/ropensci/solr/issues?state=open&#34;&gt;our issue tracker&lt;/a&gt; so we can make the parsers work better.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;solr&lt;/code&gt; is on CRAN, so you can install the more stable version there, and some dependencies.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;solr&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can install the development version from Github as follows.  Below we&amp;rsquo;ll use the Github version - most of below is available in the CRAN version too, except &lt;code&gt;solr_group&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;devtools&amp;quot;)
devtools::install_github(&amp;quot;ropensci/solr&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Load the library&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;solr&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;define-url-endpoint-and-key&#34;&gt;Define url endpoint and key&lt;/h2&gt;

&lt;p&gt;As &lt;code&gt;solr&lt;/code&gt; is a general interface to Solr endpoints, you need to define the url. Here, we&amp;rsquo;ll work with the Public Library of Science full text search API (docs &lt;a href=&#34;http://api.plos.org/&#34;&gt;here&lt;/a&gt;). Some Solr endpoints will require authentication - I should note that we don&amp;rsquo;t yet handle authentication schemes other than passing in a key in the url, but that&amp;rsquo;s on the to do list.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;url &amp;lt;- &#39;http://api.plos.org/search&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;search&#34;&gt;Search&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_search(q=&#39;*:*&#39;, rows=2, fl=&#39;id&#39;, base=url)
#&amp;gt;                                                              id
#&amp;gt; 1       10.1371/annotation/c313df3a-52bd-4cbe-af14-6676480d1a43
#&amp;gt; 2 10.1371/annotation/c313df3a-52bd-4cbe-af14-6676480d1a43/title
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Search for words &amp;ldquo;sports&amp;rdquo; and &amp;ldquo;alcohol&amp;rdquo; within seven words of each other&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_search(q=&#39;everything:&amp;quot;sports alcohol&amp;quot;~7&#39;, fl=&#39;title&#39;, rows=3, base=url)
#&amp;gt;                                                                                                                                                                         title
#&amp;gt; 1                                      Alcohol Ingestion Impairs Maximal Post-Exercise Rates of Myofibrillar Protein Synthesis following a Single Bout of Concurrent Training
#&amp;gt; 2 “Like Throwing a Bowling Ball at a Battle Ship” Audience Responses to Australian News Stories about Alcohol Pricing and Promotion Policies: A Qualitative Focus Group Study
#&amp;gt; 3                                            Development and Validation of a Risk Score Predicting Substantial Weight Gain over 5 Years in Middle-Aged European Men and Women
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;groups&#34;&gt;Groups&lt;/h2&gt;

&lt;p&gt;Most recent publication by journal&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_group(q=&#39;*:*&#39;, group.field=&#39;journal&#39;, rows=5, group.limit=1, group.sort=&#39;publication_date desc&#39;, fl=&#39;publication_date, score&#39;, base=url)
#&amp;gt;       groupValue numFound start     publication_date score
#&amp;gt; 1       plos one   931323     0 2014-11-24T00:00:00Z     1
#&amp;gt; 2  plos genetics    40603     0 2014-11-20T00:00:00Z     1
#&amp;gt; 3  plos medicine    18514     0 2014-11-18T00:00:00Z     1
#&amp;gt; 4 plos pathogens    35497     0 2014-11-24T00:00:00Z     1
#&amp;gt; 5   plos biology    26133     0 2014-11-18T00:00:00Z     1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;First publication by journal&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_group(q=&#39;*:*&#39;, group.field=&#39;journal&#39;, group.limit=1, group.sort=&#39;publication_date asc&#39;, fl=&#39;publication_date, score&#39;, fq=&amp;quot;publication_date:[1900-01-01T00:00:00Z TO *]&amp;quot;, base=url)
#&amp;gt;                          groupValue numFound start     publication_date
#&amp;gt; 1                          plos one   931323     0 2006-12-01T00:00:00Z
#&amp;gt; 2                     plos genetics    40603     0 2005-06-17T00:00:00Z
#&amp;gt; 3                     plos medicine    18514     0 2004-09-07T00:00:00Z
#&amp;gt; 4                    plos pathogens    35497     0 2005-07-22T00:00:00Z
#&amp;gt; 5                      plos biology    26133     0 2003-08-18T00:00:00Z
#&amp;gt; 6                              none    57566     0 2005-08-23T00:00:00Z
#&amp;gt; 7        plos computational biology    29838     0 2005-06-24T00:00:00Z
#&amp;gt; 8  plos neglected tropical diseases    25119     0 2007-08-30T00:00:00Z
#&amp;gt; 9              plos clinical trials      521     0 2006-04-21T00:00:00Z
#&amp;gt; 10                     plos medicin        9     0 2012-04-17T00:00:00Z
#&amp;gt;    score
#&amp;gt; 1      1
#&amp;gt; 2      1
#&amp;gt; 3      1
#&amp;gt; 4      1
#&amp;gt; 5      1
#&amp;gt; 6      1
#&amp;gt; 7      1
#&amp;gt; 8      1
#&amp;gt; 9      1
#&amp;gt; 10     1
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;facet&#34;&gt;Facet&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_facet(q=&#39;*:*&#39;, facet.field=&#39;journal&#39;, facet.query=&#39;cell,bird&#39;, base=url)
#&amp;gt; $facet_queries
#&amp;gt;        term value
#&amp;gt; 1 cell,bird    17
#&amp;gt;
#&amp;gt; $facet_fields
#&amp;gt; $facet_fields$journal
#&amp;gt;                                 X1     X2
#&amp;gt; 1                         plos one 931323
#&amp;gt; 2                    plos genetics  40603
#&amp;gt; 3                   plos pathogens  35497
#&amp;gt; 4       plos computational biology  29838
#&amp;gt; 5                     plos biology  26133
#&amp;gt; 6 plos neglected tropical diseases  25119
#&amp;gt; 7                    plos medicine  18514
#&amp;gt; 8             plos clinical trials    521
#&amp;gt; 9                     plos medicin      9
#&amp;gt;
#&amp;gt;
#&amp;gt; $facet_dates
#&amp;gt; NULL
#&amp;gt;
#&amp;gt; $facet_ranges
#&amp;gt; NULL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Range faceting with &amp;gt; 1 field&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head( solr_facet(q=&#39;*:*&#39;, base=url, facet.range=&#39;alm_twitterCount&#39;, facet.range.start=5, facet.range.end=1000, facet.range.gap=10)$facet_ranges$alm_twitterCount )
#&amp;gt;   X1    X2
#&amp;gt; 1  5 60938
#&amp;gt; 2 15 13668
#&amp;gt; 3 25  6379
#&amp;gt; 4 35  2952
#&amp;gt; 5 45  2297
#&amp;gt; 6 55  1497
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;highlight&#34;&gt;Highlight&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_highlight(q=&#39;alcohol&#39;, hl.fl = &#39;abstract&#39;, rows=2, base = url)
#&amp;gt; $`10.1371/journal.pmed.0040151`
#&amp;gt; $`10.1371/journal.pmed.0040151`$abstract
#&amp;gt; [1] &amp;quot;Background: &amp;lt;em&amp;gt;Alcohol&amp;lt;/em&amp;gt; consumption causes an estimated 4% of the global disease burden, prompting&amp;quot;
#&amp;gt;
#&amp;gt;
#&amp;gt; $`10.1371/journal.pone.0027752`
#&amp;gt; $`10.1371/journal.pone.0027752`$abstract
#&amp;gt; [1] &amp;quot;Background: The negative influences of &amp;lt;em&amp;gt;alcohol&amp;lt;/em&amp;gt; on TB management with regard to delays in seeking&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;stats&#34;&gt;Stats&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_stats(q=&#39;ecology&#39;, stats.field=&#39;alm_twitterCount&#39;, stats.facet=c(&#39;journal&#39;,&#39;volume&#39;), base=url)
#&amp;gt;   min  max count missing    sum sumOfSquares     mean   stddev
#&amp;gt; 1   0 1624 24326       0 113589     19746631 4.669448 28.10656
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;more-like-this&#34;&gt;More like this&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;solr_mlt&lt;/code&gt; is a function to return similar documents to the ones searched for.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;out &amp;lt;- solr_mlt(q=&#39;title:&amp;quot;ecology&amp;quot; AND body:&amp;quot;cell&amp;quot;&#39;, mlt.fl=&#39;title&#39;, mlt.mindf=1, mlt.mintf=1, fl=&#39;counter_total_all&#39;, rows=5, base=url)
out$docs
#&amp;gt;                             id counter_total_all
#&amp;gt; 1 10.1371/journal.pbio.1001805             10102
#&amp;gt; 2 10.1371/journal.pbio.0020440             16630
#&amp;gt; 3 10.1371/journal.pone.0087217              2922
#&amp;gt; 4 10.1371/journal.pone.0040117              2514
#&amp;gt; 5 10.1371/journal.pone.0072525              1112
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;raw-data&#34;&gt;Raw data?&lt;/h2&gt;

&lt;p&gt;You can optionally get back raw &lt;code&gt;json&lt;/code&gt; or &lt;code&gt;xml&lt;/code&gt; from all functions by setting parameter &lt;code&gt;raw=TRUE&lt;/code&gt;. You can then parse after the fact with &lt;code&gt;solr_parse&lt;/code&gt;, or just process as you wish. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;(out &amp;lt;- solr_highlight(q=&#39;alcohol&#39;, hl.fl = &#39;abstract&#39;, rows=2, base = url, raw=TRUE))
#&amp;gt; [1] &amp;quot;{\&amp;quot;response\&amp;quot;:{\&amp;quot;numFound\&amp;quot;:15301,\&amp;quot;start\&amp;quot;:0,\&amp;quot;docs\&amp;quot;:[{},{}]},\&amp;quot;highlighting\&amp;quot;:{\&amp;quot;10.1371/journal.pmed.0040151\&amp;quot;:{\&amp;quot;abstract\&amp;quot;:[\&amp;quot;Background: &amp;lt;em&amp;gt;Alcohol&amp;lt;/em&amp;gt; consumption causes an estimated 4% of the global disease burden, prompting\&amp;quot;]},\&amp;quot;10.1371/journal.pone.0027752\&amp;quot;:{\&amp;quot;abstract\&amp;quot;:[\&amp;quot;Background: The negative influences of &amp;lt;em&amp;gt;alcohol&amp;lt;/em&amp;gt; on TB management with regard to delays in seeking\&amp;quot;]}}}\n&amp;quot;
#&amp;gt; attr(,&amp;quot;class&amp;quot;)
#&amp;gt; [1] &amp;quot;sr_high&amp;quot;
#&amp;gt; attr(,&amp;quot;wt&amp;quot;)
#&amp;gt; [1] &amp;quot;json&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then parse&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_parse(out, &#39;df&#39;)
#&amp;gt;                          names
#&amp;gt; 1 10.1371/journal.pmed.0040151
#&amp;gt; 2 10.1371/journal.pone.0027752
#&amp;gt;                                                                                                    abstract
#&amp;gt; 1   Background: &amp;lt;em&amp;gt;Alcohol&amp;lt;/em&amp;gt; consumption causes an estimated 4% of the global disease burden, prompting
#&amp;gt; 2 Background: The negative influences of &amp;lt;em&amp;gt;alcohol&amp;lt;/em&amp;gt; on TB management with regard to delays in seeking
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;verbosity&#34;&gt;Verbosity&lt;/h2&gt;

&lt;p&gt;As you have noticed, we include in each function the acutal call to the Solr endpoint made so you know exactly what was submitted to the remote or local Solr instance. You can suppress the message with &lt;code&gt;verbose=FALSE&lt;/code&gt;. This message isn&amp;rsquo;t in the CRAN version.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;advanced-function-queries&#34;&gt;Advanced: Function Queries&lt;/h2&gt;

&lt;p&gt;Function Queries allow you to query on actual numeric fields in the SOLR database, and do addition, multiplication, etc on one or many fields to stort results. For example, here, we search on the product of counter_total_all and alm_twitterCount, using a new temporary field &amp;ldquo;&lt;em&gt;val&lt;/em&gt;&amp;ldquo;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_search(q=&#39;_val_:&amp;quot;product(counter_total_all,alm_twitterCount)&amp;quot;&#39;, rows=5, fl=&#39;id,title&#39;, fq=&#39;doc_type:full&#39;, base=url)
#&amp;gt;                             id
#&amp;gt; 1 10.1371/journal.pmed.0020124
#&amp;gt; 2 10.1371/journal.pone.0105948
#&amp;gt; 3 10.1371/journal.pone.0046362
#&amp;gt; 4 10.1371/journal.pone.0069841
#&amp;gt; 5 10.1371/journal.pbio.1001535
#&amp;gt;                                                                                                title
#&amp;gt; 1                                                     Why Most Published Research Findings Are False
#&amp;gt; 2 Sliding Rocks on Racetrack Playa, Death Valley National Park: First Observation of Rocks in Motion
#&amp;gt; 3 The Power of Kawaii: Viewing Cute Images Promotes a Careful Behavior and Narrows Attentional Focus
#&amp;gt; 4                            Facebook Use Predicts Declines in Subjective Well-Being in Young Adults
#&amp;gt; 5                                                     An Introduction to Social Media for Scientists
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, we search for the papers with the most citations&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_search(q=&#39;_val_:&amp;quot;max(counter_total_all)&amp;quot;&#39;, rows=5, fl=&#39;id,counter_total_all&#39;, fq=&#39;doc_type:full&#39;, base=url)
#&amp;gt;                             id counter_total_all
#&amp;gt; 1 10.1371/journal.pmed.0020124           1002083
#&amp;gt; 2 10.1371/journal.pmed.0050045            324559
#&amp;gt; 3 10.1371/journal.pone.0007595            315117
#&amp;gt; 4 10.1371/journal.pone.0033288            305965
#&amp;gt; 5 10.1371/journal.pone.0069841            277609
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or with the most tweets&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solr_search(q=&#39;_val_:&amp;quot;max(alm_twitterCount)&amp;quot;&#39;, rows=5, fl=&#39;id,alm_twitterCount&#39;, fq=&#39;doc_type:full&#39;, base=url)
#&amp;gt;                             id alm_twitterCount
#&amp;gt; 1 10.1371/journal.pone.0061981             2298
#&amp;gt; 2 10.1371/journal.pmed.0020124             1700
#&amp;gt; 3 10.1371/journal.pbio.1001535             1624
#&amp;gt; 4 10.1371/journal.pone.0046362             1368
#&amp;gt; 5 10.1371/journal.pmed.1001747             1361
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;further-reading-on-solr&#34;&gt;Further reading on Solr&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://lucene.apache.org/solr/&#34;&gt;Solr home page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://wiki.apache.org/solr/HighlightingParameters&#34;&gt;Highlighting help&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://wiki.apache.org/solr/SimpleFacetParameters&#34;&gt;Faceting help&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://wiki.apache.org/solr/StatsComponent&#34;&gt;Solr stats&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://wiki.apache.org/solr/MoreLikeThis&#34;&gt;&amp;lsquo;More like this&amp;rsquo; searches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://wiki.apache.org/solr/FieldCollapsing&#34;&gt;Grouping/Feild collapsing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://ramlev.dk/blog/2012/06/02/install-apache-solr-on-your-mac/&#34;&gt;Installing Solr on Mac using homebrew&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://risnandar.wordpress.com/2013/09/08/how-to-install-and-setup-apache-lucene-solr-in-osx/&#34;&gt;Install and Setup SOLR in OSX, including running Solr&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
